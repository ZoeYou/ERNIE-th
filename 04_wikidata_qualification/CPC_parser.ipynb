{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zuoyou/opt/anaconda3/lib/python3.7/site-packages/spacy/displacy/__init__.py:97: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"21d9accfd57c45d7842b308dae4b298e-0\" class=\"displacy\" width=\"2150\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">adapting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">or</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">protecting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">infrastructure</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">or</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">their</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">operation</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">transportation</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">roads,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">waterways</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">or</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\">railways</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-0\" stroke-width=\"2px\" d=\"M62,302.0 62,277.0 191.0,277.0 191.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M191.0,304.0 L195.0,296.0 187.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-1\" stroke-width=\"2px\" d=\"M62,302.0 62,252.0 344.0,252.0 344.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M344.0,304.0 L348.0,296.0 340.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-2\" stroke-width=\"2px\" d=\"M362,302.0 362,277.0 491.0,277.0 491.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M491.0,304.0 L495.0,296.0 487.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-3\" stroke-width=\"2px\" d=\"M512,302.0 512,277.0 641.0,277.0 641.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M641.0,304.0 L645.0,296.0 637.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-4\" stroke-width=\"2px\" d=\"M812,302.0 812,277.0 941.0,277.0 941.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M812,304.0 L808,296.0 816,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-5\" stroke-width=\"2px\" d=\"M512,302.0 512,227.0 947.0,227.0 947.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M947.0,304.0 L951.0,296.0 943.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-6\" stroke-width=\"2px\" d=\"M362,302.0 362,202.0 1100.0,202.0 1100.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,304.0 L1104.0,296.0 1096.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-7\" stroke-width=\"2px\" d=\"M1112,302.0 1112,277.0 1241.0,277.0 1241.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1241.0,304.0 L1245.0,296.0 1237.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-8\" stroke-width=\"2px\" d=\"M1262,302.0 1262,277.0 1391.0,277.0 1391.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1391.0,304.0 L1395.0,296.0 1387.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-9\" stroke-width=\"2px\" d=\"M1412,302.0 1412,277.0 1541.0,277.0 1541.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1541.0,304.0 L1545.0,296.0 1537.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-10\" stroke-width=\"2px\" d=\"M1562,302.0 1562,277.0 1691.0,277.0 1691.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1691.0,304.0 L1695.0,296.0 1687.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-11\" stroke-width=\"2px\" d=\"M1712,302.0 1712,277.0 1841.0,277.0 1841.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1841.0,304.0 L1845.0,296.0 1837.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-21d9accfd57c45d7842b308dae4b298e-0-12\" stroke-width=\"2px\" d=\"M1712,302.0 1712,252.0 1994.0,252.0 1994.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-21d9accfd57c45d7842b308dae4b298e-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1994.0,304.0 L1998.0,296.0 1990.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "def custom_tokenizer(nlp):\n",
    "    inf = list(nlp.Defaults.infixes)               # Default infixes\n",
    "    inf.remove(r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\")    # Remove the generic op between numbers or between a number and a -\n",
    "    inf = tuple(inf)                               # Convert inf to tuple\n",
    "    infixes = inf + tuple([r\"(?<=[0-9])[+*^](?=[0-9-])\", r\"(?<=[0-9])-(?=-)\"])  # Add the removed rule after subtracting (?<=[0-9])-(?=[0-9]) pattern\n",
    "    infixes = [x for x in infixes if '-|–|—|--|---|——|~' not in x] # Remove - between letters rule\n",
    "    infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "\n",
    "    return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
    "                                suffix_search=nlp.tokenizer.suffix_search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=nlp.tokenizer.token_match,\n",
    "                                rules=nlp.Defaults.tokenizer_exceptions)\n",
    "\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "doc = nlp('adapting or protecting infrastructure or their operation in transportation on roads, waterways or railways')\n",
    "options = {\"compact\": True, \"bg\": \"#09a3d5\",\n",
    "           \"color\": \"white\", \"font\": \"Source Sans Pro\"}\n",
    "displacy.serve(doc, style=\"dep\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapting\tROOT\tadapting\tVERB\t [or, protecting]\n",
      "or\tcc\tadapting\tVERB\t []\n",
      "protecting\tconj\tadapting\tVERB\t [infrastructure, in]\n",
      "infrastructure\tdobj\tprotecting\tVERB\t [or, operation]\n",
      "or\tcc\tinfrastructure\tNOUN\t []\n",
      "their\tposs\toperation\tNOUN\t []\n",
      "operation\tconj\tinfrastructure\tNOUN\t [their]\n",
      "in\tprep\tprotecting\tVERB\t [transportation]\n",
      "transportation\tpobj\tin\tADP\t [on]\n",
      "on\tprep\ttransportation\tNOUN\t [roads]\n",
      "roads\tpobj\ton\tADP\t [,, waterways]\n",
      ",\tpunct\troads\tNOUN\t []\n",
      "waterways\tconj\troads\tNOUN\t [or, railways]\n",
      "or\tcc\twaterways\tNOUN\t []\n",
      "railways\tconj\twaterways\tNOUN\t []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text + '\\t' + token.dep_ + '\\t' + token.head.text + '\\t' + token.head.pos_ + '\\t',\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import NOUN,VERB,ADJ\n",
    "import itertools\n",
    "\n",
    "def insert_before(list_, ele, target):\n",
    "    for i in range(len(list_)):\n",
    "        if list_[i] == target:\n",
    "            list_.insert(i, ele)\n",
    "    return list_\n",
    "\n",
    "\n",
    "def resume_dict(root, dict_=[]):  \n",
    "    if dict_ == []:\n",
    "        return [] \n",
    "    elif dict_ == {'compound': [], 'prep': [], 'pobj': [], 'dobj': []}:\n",
    "        return [root]    \n",
    "    \n",
    "    if isinstance(dict_['pobj'], dict):\n",
    "        dict_['pobj'] = [dict_['pobj']]          \n",
    "    if isinstance(dict_['dobj'], dict):\n",
    "        dict_['dobj'] = [dict_['dobj']]\n",
    "     \n",
    "    if root.pos == ADJ:\n",
    "        line = [root] + dict_['compound'] + dict_['prep'] + dict_['pobj']\n",
    "    else:\n",
    "        line = dict_['compound'] + [root] + dict_['dobj'] + dict_['prep'] + dict_['pobj']\n",
    "    return line \n",
    "\n",
    "\n",
    "def dive_line(line, to_dive):\n",
    "    res = []\n",
    "    for i in to_dive:\n",
    "        dict_ = line[i]\n",
    "        temp = []\n",
    "        for key,val in dict_.items():\n",
    "            res_undict = resume_dict(key,val) # a list 1D\n",
    "            \n",
    "            # check whether there is still dict in res_undict\n",
    "            to_dive = []\n",
    "            for j in range(len(res_undict)):\n",
    "                if isinstance(res_undict[j],dict):\n",
    "                    to_dive.append(j)\n",
    "            if to_dive:\n",
    "                l_split = iter(dive_line(res_undict, to_dive))\n",
    "                \n",
    "            for k in to_dive:\n",
    "                res_undict[k] = next(l_split)\n",
    "                        \n",
    "            temp.append(res_undict)       \n",
    "        res.append(temp)\n",
    "  \n",
    "    return res\n",
    "\n",
    "\n",
    "def decarde_concat_right(l1, l2):      \n",
    "    if not l2:\n",
    "        return l1 \n",
    "    if not l1:\n",
    "        return l2\n",
    "    \n",
    "    if not isinstance(l1, list):  \n",
    "        l1 = [l1]\n",
    "    elif isinstance(l1, list) and len(l1) == 1 and isinstance(l1[0], list) and len(l1[0]) == 1:\n",
    "        l1 = l1[0]\n",
    "        \n",
    "    return [l1 + e2 for e2 in l2]\n",
    "\n",
    "def decarde_concat_left(l1, l2):      \n",
    "    if not l2:\n",
    "        return l1 \n",
    "    if not l1:\n",
    "        return l2\n",
    "    \n",
    "    if not isinstance(l2, list):  \n",
    "        l2 = [l2]\n",
    "    elif isinstance(l2, list) and len(l2) == 1 and isinstance(l2[0], list) and len(l2[0]) == 1:\n",
    "        l2 = l2[0]\n",
    "        \n",
    "    return [e1 + l2 for e1 in l1]\n",
    "\n",
    "def decarde_concat(l1, l2):   \n",
    "    res = []\n",
    "    if not l2:\n",
    "        return l1 \n",
    "    if not l1:\n",
    "        return l2\n",
    "            \n",
    "    try:\n",
    "        return [e1 + e2 for e1 in l1 for e2 in l2]\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return decarde_concat_right(l1,l2)\n",
    "        except TypeError:\n",
    "            return decarde_concat_left(l1,l2)\n",
    "        \n",
    "\n",
    "\n",
    "def unlist(line): # given a line ls(list with lists in it), returns a list of 1D list\n",
    "    if not line:\n",
    "        return \n",
    "    elif not isinstance(line, list):\n",
    "        return line\n",
    "    elif isinstance(line, list) and len(line) == 1 and isinstance(line[0], list) and len(line[0]) == 1:\n",
    "        return line[0]\n",
    "    else:      \n",
    "        for i in range(len(line)):\n",
    "            token = line[i]\n",
    "            if isinstance(token, list):\n",
    "                len_ = len(token)\n",
    "                if len_ > 1:                   \n",
    "                    lines = decarde_concat_right(line[:i], line[i])\n",
    "                    if i < len(line)-1:\n",
    "                        lines = decarde_concat(lines, unlist(line[i+1:]))\n",
    "               \n",
    "                    return lines \n",
    "                else: # list with length 1\n",
    "                    return token[0]              \n",
    "        return line  \n",
    "    \n",
    "    \n",
    "\n",
    "def extract_CP(doc, co_hypo):\n",
    "    res = {}\n",
    "    for hypo in co_hypo:\n",
    "        res[hypo] = {'compound': [], 'prep': [], 'pobj': [], 'dobj': []}\n",
    "    \n",
    "    # find elements if possible\n",
    "    for token in co_hypo:\n",
    "        for child in token.children:\n",
    "            if child.dep_ in ['compound', 'amod']:\n",
    "                res[token]['compound'].append(child)\n",
    "                for ttoken in doc:\n",
    "                    if ttoken.dep_ in ['compound', 'amod'] and ttoken.head == child:\n",
    "                        # insert just before the final token\n",
    "                        res[token]['compound'] = insert_before(res[token]['compound'], ttoken, child)\n",
    "                        \n",
    "            elif child.dep_ in ['prep', 'acl']:\n",
    "                res[token]['prep'].append(child)\n",
    "                for gchild in child.children:\n",
    "                    if (child.dep_ == 'prep' and gchild.dep_ == 'pobj'):\n",
    "                        res[token]['pobj'].append(gchild)\n",
    "                        # complete compound for pobj\n",
    "                        for ttoken in doc:\n",
    "                            if ttoken.dep_ in ['compound', 'amod'] and ttoken.head == gchild:\n",
    "                                res[token]['pobj'] = insert_before(res[token]['pobj'], ttoken, gchild)\n",
    "                    elif (child.dep_ == 'acl' and gchild.dep_ == 'dobj'):\n",
    "                        res[token]['dobj'].append(gchild)\n",
    "                                \n",
    "            elif token.pos == VERB and child.dep_ == 'dobj':\n",
    "                res[token]['dobj'].append(child)\n",
    "                # complete compound for dobj\n",
    "                for ttoken in doc:\n",
    "                    if ttoken.dep_ in ['compound', 'amod'] and ttoken.head == child:\n",
    "                        res[token]['dobj'] = insert_before(res[token]['dobj'], ttoken, child)\n",
    "    \n",
    "    # complete elements for co-hypo\n",
    "    for dep in ['compound', 'prep', 'pobj', 'dobj']:\n",
    "        for token in co_hypo:\n",
    "            if token.head == co_hypo[0] and not res[token][dep]:\n",
    "                res[token][dep] = res[co_hypo[0]][dep]\n",
    "                \n",
    "    # if elements of head is empty \n",
    "    if res[co_hypo[0]] == {'compound': [], 'prep': [], 'pobj': [], 'dobj': []}:\n",
    "        for hypo in co_hypo[1:]:\n",
    "            if res[hypo] != {'compound': [], 'prep': [], 'pobj': [], 'dobj': []}:\n",
    "                res[co_hypo[0]] = res[hypo]   \n",
    "#====================================================================================================================#    \n",
    "#====================================================================================================================#\n",
    "    # if all pobj have only compounds as children then return \n",
    "    for hypo, dic in res.items(): \n",
    "        pobj = dic['pobj'] # pobj in each co-hyponym\n",
    "        if pobj and isinstance(pobj,list):            \n",
    "            all_conj = True\n",
    "            for ppobj in pobj: \n",
    "                 if ppobj.dep_ != 'conj': \n",
    "                        all_conj = False\n",
    "                        break            \n",
    "            if len(pobj) > 1: \n",
    "                if all_conj:\n",
    "                    pobj_cohypo = pobj\n",
    "                else:\n",
    "                    pobj = pobj[-1] \n",
    "                    pobj_cohypo = [pobj]\n",
    "            else:                     \n",
    "                pobj = pobj[0]\n",
    "                pobj_cohypo = [pobj]\n",
    "\n",
    "            # extract other potential co-hypo            \n",
    "            for token in doc:\n",
    "                if token.dep_ == 'conj' and token not in pobj_cohypo and token.head in pobj_cohypo:\n",
    "                    pobj_cohypo.append(token)\n",
    "            has_prep = False\n",
    "            for child in pobj.children:\n",
    "                if child.dep_ in ['prep','acl']: \n",
    "                    has_prep = True\n",
    "                    break\n",
    "\n",
    "            if has_prep or len(pobj_cohypo) > 1:\n",
    "                res[hypo]['pobj'] = extract_CP(doc, pobj_cohypo)\n",
    "\n",
    "        elif pobj and isinstance(pobj,dict): # if pobj is dict\n",
    "            for item, item_dic in pobj.items():\n",
    "                item_pobj = item_dic['pobj']\n",
    "                if item_pobj and isinstance(item_pobj,dict):\n",
    "                    pobj_cohypo = [pobj for pobj in item_pobj.keys()]\n",
    "                    # extract other potential co-hypo\n",
    "                    for token in doc:\n",
    "                        if token.dep_ == 'conj' and token not in pobj_cohypo and token.head in pobj_cohypo:\n",
    "                            pobj_cohypo.append(token)\n",
    "                    if len(pobj_cohypo) > 1:\n",
    "                        res[hypo]['pobj'] = extract_CP(doc, pobj_cohypo)\n",
    "                        break\n",
    "\n",
    "\n",
    "                elif item_pobj and isinstance(item_pobj, list):\n",
    "                    if len(item_pobj) > 1:                      \n",
    "                        item_pobj = item_pobj[-1] \n",
    "                    else: \n",
    "                        item_pobj = item_pobj[0]\n",
    "\n",
    "                    has_prep = False\n",
    "                    pobj_cohypo = [item_pobj]\n",
    "\n",
    "                    # extract other potential co-hypo\n",
    "                    for token in doc:\n",
    "                        if token.dep_ == 'conj' and token not in pobj_cohypo and token.head in pobj_cohypo:\n",
    "                            pobj_cohypo.append(token)\n",
    "                    for child in item_pobj.children:\n",
    "                        if child.dep_ in ['prep','acl']: \n",
    "                            has_prep = True\n",
    "                            break\n",
    "\n",
    "                    if has_prep or len(pobj_cohypo) > 1:\n",
    "                        res[hypo]['pobj'] = extract_CP(doc, pobj_cohypo)\n",
    "\n",
    "#====================================================================================================================#\n",
    "#====================================================================================================================#\n",
    "\n",
    "    # same process for dobj\n",
    "    for hypo, dic in res.items(): \n",
    "        dobj = dic['dobj'] # dobj in each co-hyponym\n",
    "\n",
    "        if dobj and isinstance(dobj,list):            \n",
    "            all_conj = True\n",
    "            for ddobj in dobj: \n",
    "                 if ddobj.dep_ != 'conj': \n",
    "                        all_conj = False\n",
    "                        break            \n",
    "            if len(dobj) > 1: \n",
    "                if all_conj:\n",
    "                    dobj_cohypo = dobj\n",
    "                else:\n",
    "                    dobj = dobj[-1] \n",
    "                    dobj_cohypo = [dobj]\n",
    "            else:                     \n",
    "                dobj = dobj[0]\n",
    "                dobj_cohypo = [dobj]\n",
    "            has_prep = False\n",
    "\n",
    "            \n",
    "            # extract other potential co-hypo            \n",
    "            for token in doc:\n",
    "                if token.dep_ == 'conj' and token not in dobj_cohypo and token.head in dobj_cohypo:\n",
    "                    dobj_cohypo.append(token)\n",
    "\n",
    "            for child in dobj.children:\n",
    "                if child.dep_ in ['prep','acl']: \n",
    "                    has_prep = True\n",
    "                    break\n",
    "\n",
    "            if has_prep or len(dobj_cohypo) > 1:\n",
    "                res[hypo]['dobj'] = extract_CP(doc, dobj_cohypo)\n",
    "\n",
    "        elif dobj and isinstance(dobj,dict): # if dobj is dict\n",
    "            for item, item_dic in dobj.items():\n",
    "                item_dobj = item_dic['dobj']\n",
    "                if item_dobj and isinstance(item_dobj,dict):\n",
    "                    dobj_cohypo = [dobj for dobj in item_dobj.keys()]\n",
    "                    # extract other potential co-hypo\n",
    "                    for token in doc:\n",
    "                        if token.dep_ == 'conj' and token not in dobj_cohypo and token.head in dobj_cohypo:\n",
    "                            dobj_cohypo.append(token)\n",
    "                    if len(dobj_cohypo) > 1:\n",
    "                        res[hypo]['dobj'] = extract_CP(doc, dobj_cohypo)\n",
    "                        break\n",
    "\n",
    "\n",
    "                elif item_dobj and isinstance(item_dobj, list):\n",
    "                    if len(item_dobj) > 1:                      \n",
    "                        item_dobj = item_dobj[-1] \n",
    "                    else: \n",
    "                        item_dobj = item_dobj[0]\n",
    "\n",
    "                    has_prep = False\n",
    "                    dobj_cohypo = [item_dobj]\n",
    "\n",
    "                    # extract other potential co-hypo\n",
    "                    for token in doc:\n",
    "                        if token.dep_ == 'conj' and token not in dobj_cohypo and token.head in dobj_cohypo:\n",
    "                            dobj_cohypo.append(token)\n",
    "                    for child in item_dobj.children:\n",
    "                        if child.dep_ in ['prep','acl']: \n",
    "                            has_prep = True\n",
    "                            break\n",
    "\n",
    "                    if has_prep or len(dobj_cohypo) > 1:\n",
    "                        res[hypo]['dobj'] = extract_CP(doc, dobj_cohypo)\n",
    "#====================================================================================================================#\n",
    "#====================================================================================================================#                          \n",
    "    return res\n",
    "\n",
    "\n",
    "                                \n",
    "def parsing(phrase, model=nlp):\n",
    "    doc = model(phrase)\n",
    "    \n",
    "    # add root term\n",
    "    main_principle = []\n",
    "    co_hypo = []\n",
    "    for token in doc:\n",
    "        # find root and co-hyponyms\n",
    "        if token.pos in [NOUN, VERB, ADJ] and token.dep_ == 'ROOT':\n",
    "            main_principle.append(token) \n",
    "            for child in token.children:\n",
    "                if child.dep_ == 'conj':\n",
    "                    co_hypo.append(child)\n",
    "                    # find conj of conj\n",
    "                    for gchild in child.children:\n",
    "                        if gchild.dep_ == 'conj':\n",
    "                            co_hypo.append(gchild)\n",
    "     \n",
    "    co_hypo = main_principle+(co_hypo) # usually the first being the root node   \n",
    "    res_dict = extract_CP(doc, co_hypo) \n",
    "\n",
    "    temp = []\n",
    "    for co_hypo, decorations in res_dict.items():\n",
    "        # if the co-hypo is an ADJ\n",
    "        if co_hypo.pos == ADJ:\n",
    "            decorations = {'compound': [], 'prep': [], 'pobj': [], 'dobj': []}\n",
    "            for child in co_hypo.children:\n",
    "                if child.dep_ == 'conj':\n",
    "                    if len(res_dict[child]['compound'])>1:\n",
    "                        decorations['compound'] = res_dict[child]['compound'][1:]\n",
    "                    decorations['compound'].append(child)\n",
    "                    decorations['prep'] = res_dict[child]['prep']\n",
    "                    decorations['pobj'] = res_dict[child]['pobj']\n",
    "                    temp.append(resume_dict(co_hypo, decorations))\n",
    "                                    \n",
    "        else:\n",
    "            temp.append(resume_dict(co_hypo, decorations))     \n",
    "\n",
    "    res = []\n",
    "\n",
    "\n",
    "    for line in temp: # results with pobj as dictionary ==> transfor then into list\n",
    "        to_dive = []\n",
    "        for i in range(len(line)):\n",
    "            if isinstance(line[i],dict):\n",
    "                to_dive.append(i)\n",
    "\n",
    "        if to_dive: \n",
    "            l_split = iter(dive_line(line, to_dive))\n",
    "            for i in to_dive:\n",
    "                line[i] = next(l_split)\n",
    "\n",
    "        res.append(line)      \n",
    "\n",
    "    fini = False\n",
    "    while not fini:\n",
    "        try:\n",
    "            res = [' '.join([word.text for word in line]) for line in res]\n",
    "            fini = True\n",
    "        except AttributeError:\n",
    "            temp = res \n",
    "            res = []\n",
    "            for line in temp:\n",
    "                res.extend(unlist(line))       \n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['digests']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('technical subjects covered by former uspc cross-reference art collections [xracs] and digests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transactions']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('billing, invoicing, buying or selling transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['technologies for mitigation against climate change',\n",
       " 'technologies for adaptation against climate change',\n",
       " 'applications for mitigation against climate change',\n",
       " 'applications for adaptation against climate change']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing(\"technologies or applications for mitigation or adaptation against climate change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['controlling of flood',\n",
       " 'controlling of hurricane',\n",
       " 'monitoring of flood',\n",
       " 'monitoring of hurricane']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing(\"controlling or monitoring, e.g. of flood or hurricane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1262442f0fd0499ba18b8b1237ef3deb-0\" class=\"displacy\" width=\"950\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">billing,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">invoicing,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">or</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">selling</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">transactions</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1262442f0fd0499ba18b8b1237ef3deb-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,152.0 800.0,152.0 800.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1262442f0fd0499ba18b8b1237ef3deb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1262442f0fd0499ba18b8b1237ef3deb-0-1\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1262442f0fd0499ba18b8b1237ef3deb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M194.0,229.0 L198.0,221.0 190.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1262442f0fd0499ba18b8b1237ef3deb-0-2\" stroke-width=\"2px\" d=\"M212,227.0 212,202.0 344.0,202.0 344.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1262442f0fd0499ba18b8b1237ef3deb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M344.0,229.0 L348.0,221.0 340.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1262442f0fd0499ba18b8b1237ef3deb-0-3\" stroke-width=\"2px\" d=\"M362,227.0 362,202.0 494.0,202.0 494.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1262442f0fd0499ba18b8b1237ef3deb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M494.0,229.0 L498.0,221.0 490.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1262442f0fd0499ba18b8b1237ef3deb-0-4\" stroke-width=\"2px\" d=\"M362,227.0 362,177.0 647.0,177.0 647.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1262442f0fd0499ba18b8b1237ef3deb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,229.0 L651.0,221.0 643.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('billing, invoicing, buying or selling transactions')\n",
    "options = {\"compact\": True, \"bg\": \"#09a3d5\",\n",
    "           \"color\": \"white\", \"font\": \"Source Sans Pro\"}\n",
    "displacy.serve(doc, style=\"dep\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['planning urban green infrastructure',\n",
       " 'developing urban green infrastructure']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('planning or developing urban green infrastructure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adapting infrastructure in roads',\n",
       " 'adapting infrastructure in waterways',\n",
       " 'adapting infrastructure in railways',\n",
       " 'adapting operation in roads',\n",
       " 'adapting operation in waterways',\n",
       " 'adapting operation in railways',\n",
       " 'protecting infrastructure in roads',\n",
       " 'protecting infrastructure in waterways',\n",
       " 'protecting infrastructure in railways',\n",
       " 'protecting operation in roads',\n",
       " 'protecting operation in waterways',\n",
       " 'protecting operation in railways']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('adapting or protecting infrastructure or their operation in transportation on roads, waterways or railways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uninterruptible power supplies integrating',\n",
       " 'back-up power supplies energies integrating']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing(\"uninterruptible or back-up power supplies integrating renewable energies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['controlling of flood',\n",
       " 'controlling of hurricane',\n",
       " 'monitoring of flood',\n",
       " 'monitoring of hurricane']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('controlling or monitoring of flood or hurricane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restoration of coral reefs', 'protection of coral reefs']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('restoration and protection of coral reefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['monitoring invasive species', 'fighting invasive species']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('monitoring or fighting invasive species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capture of greenhouse gases', 'disposal of greenhouse gases']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('capture or disposal of greenhouse gases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial reefs', 'artificial seaweed']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('artificial reefs or seaweed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restoration of coral reefs', 'protection of coral reefs']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('restoration or protection of coral reefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard structures', 'dams', 'dykes', 'breakwaters']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing('hard structures, e.g. dams, dykes or breakwaters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forecasting']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing(\"forecasting, e.g. risk assessment or mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['risk assessment', 'risk mapping']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing(\"risk assessment or mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base')",
   "language": "python",
   "name": "python37464bitbase5e3e771f486c4f06aa164a453e60de03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
