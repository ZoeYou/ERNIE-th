<!DOCTYPE html>
<html lang="en">
<head>
<title>displaCy</title>
</head>
<body style="font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr">
<figure style="margin-bottom: 6rem">
<div class="entities" style="line-height: 2.5; direction: ltr">_______________System and method for transforming video 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into directional object count_____20191212_____XMLs/xml/ipa191212.xml_____US-20190378283-A1 : US-16435008 : US-62682906_____G06T0007254000 : G06T0005500000 : G06N0020000000 : G06T0007215000The present invention is a computer-implemented system and method for transforming video 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into directional object counts. The method of transforming video 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is uniquely efficient in that it uses only a single column or row of pixels in a video camera to define the background from a moving object, count the number of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and determine their direction. By taking an image of a single column or row every frame and concatenating them together, the result is an image of the object that has passed, referred to herein as a sweep image. In order to determine the direction, two different 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can be used. Method one involves constructing another image using the same method. The two 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are then compared, and the direction is determined by the location of the object in the second image compared to the location of the object in the first image. Due to this recording method, elongation or compression of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can occur because of acceleration or deceleration of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and can be uniquely utilized to determine the speed or movement path of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The second method of determining direction involves comparing the object in the image to an established marker. The transformations can also be used to produce 
<a href="https://en.wikipedia.org/wiki/Labeled_data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    labeled data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for 
<a href="https://en.wikipedia.org/wiki/Training"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    training
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    models
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
: bounding-boxes provided in sweep image can be transformed to bound boxes in video, and boxes in video can be transformed into boxes in the sweep image._____d:CROSS-REFERENCE TO RELATED APPLICATIONThis application claims the benefit of U.S. Provisional Patent Application Ser. No. 62/682,906, entitled “System and method for transforming video 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into directional object count,” filed Jun. 9, 2018, the contents of which are incorporated herein by reference.FIELD OF THE INVENTIONThe present invention relates to 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, systems, and apparatuses for discerning useful information and 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 about moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image sequence. More specifically, the invention provides useful information including moving object count as potentially providing the direction and speed of the 
<a href="https://en.wikipedia.org/wiki/Time_travel"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object travel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, all using low-
<a href="https://en.wikipedia.org/wiki/Cost"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cost
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Imaging"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video imaging
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of that area.BACKGROUND OF THE INVENTIONImages and video can be rich mediums to encode and transfer information; however, machines are notoriously ineffective at extracting meaning from those mediums. A computer that could 
<a href="https://en.wikipedia.org/wiki/See"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    see
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and understand what it sees like a 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can is of obvious value. It became evident that what humans, even infants, could easily do, machines could not. It is much easier to teach a 
<a href="https://en.wikipedia.org/wiki/Machine"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the steps to perform 
<a href="https://en.wikipedia.org/wiki/Complex"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complex
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tasks involving higher mathematics than to teach them the comparably intuitive task of 
<a href="https://en.wikipedia.org/wiki/Outline_of_object_recognition"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In the 1970s, the attention shifted to attempting to break 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into its component pieces. These new approaches laid the groundwork for many 
<a href="https://en.wikipedia.org/wiki/Vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 techniques that exist today such as edge detection, non-polyhedral and polyhedral modeling, representation of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as interconnections of smaller structures, optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.These approaches have allowed significant advances in 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and they support the growing application of 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 approaches to understand 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; often, 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning algorithms
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 use traditional 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 approaches to improve efficiency and 
<a href="https://en.wikipedia.org/wiki/Accuracy_and_precision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    accuracy
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Traditional 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Machine"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-learned 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Face"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    face
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 trade-offs and can often complement one another in the field. Both require significant computing resources when evaluating video because they must mathematically evaluate each pixel in a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to extract useful information.There are several traditional approaches to extracting a moving object from an image sequence. The first common approach in the 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is the use of video cameras combined with background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in each frame of video and then to track the object over time. This approach, called “standard-background-detection,” while somewhat effective is computationally quite expensive seeing that it must compare each pixel in each 
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame of video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to a background to decide if it is sufficiently different. It then connects the pixels that are sufficiently different into distinct 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and associates these 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 over time.This approach accounts for all 
<a href="https://en.wikipedia.org/wiki/Variable"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    variables
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the object and its 
<a href="https://en.wikipedia.org/wiki/Kinematics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    relative movement
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the direction in both the two-dimensional and three-dimensional field and the size of the object. If there is little to no constraint on the object 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, this more general approach may be required. However, in many 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is constrained, for example, on most roads and in entrances or exits from parking 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In these cases, the 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of cars has very limited directions and a narrow set of expected positions. In other cases, such as the 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of people through a corridor entrance, the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can be limited, either in or out.In general, determining the contents of the background image comprises 1) generating a background image that is as close to what one should expect the background to look like; and 2) updating the image to account for temporal changes including changes in illumination or shadows.U.S. Pat. No. 5,748,775 issued May 5, 1998, is a method and apparatus for extracting moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by sequentially subtracting input 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from an updated background image. More specifically, it records temporal changes in the video frame, such as shadows and illumination, and updates the background image accordingly for use in background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The method accounts for temporal changes by statistically processing subdivisions of each frame to obtain a statistical quantity that reflects the change in condition. This is performed for each pixel of each frame of video. Referring to FIG. 1A, consider a traditional method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Camera is aimed at a fixed position capturing an image sequence where 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 100, 101, 102, and 103 are individual frames trying to extract moving object 160. An attentive reader will notice that the background has multiple 
<a href="https://en.wikipedia.org/wiki/Section"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sections
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 110, 111, 112, each subject to individual temporal changes depending on the components within each. For example, if the weather becomes 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloudy
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, section 110 will need to be updated to 
<a href="https://en.wikipedia.org/wiki/Reflection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    reflect
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the change; however, 
<a href="https://en.wikipedia.org/wiki/Section"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sections
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 111 and 112 could remain the same. In the same sense, the mountains in section 112 could become covered with snow while 110 and 112 remain unchanged, and so on. The considerable amount of combinations make a per pixel background 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 necessary for each frame. When considering one frame 104, traditional backgro
<a href="https://en.wikipedia.org/wiki/UND"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    und
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 first creates an updated background image 105 relative to that frame through techniques such as weighted averaging, and performs a 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the binarized 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to obtain an extracted image of the object, as seen in 106. This process is repeated for each subsequent frame. In many 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, this approach may be appropriate; however, it can be 
<a href="https://en.wikipedia.org/wiki/Analysis_of_algorithms"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computationally expensive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, seeing that each pixel in each frame of the video must be processed to update the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.There are many 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that do not require this level of 
<a href="https://en.wikipedia.org/wiki/Computation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
—referring now to FIG. 1B, consider the same camera to be capturing the same sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 120, 121, 122, and 123 with the same object 170 moving from 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to right. In this approach, now consider 130 to be an isolated column of pixels positioned orthogonal to the object's direction of travel. Each column 140, 141, 142, and 143 represents one image in the image sequence and can be concatenated into a new image 150. This new image would then embody the entire video with each column representing one frame. In updating the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, it would then be sufficient to account for temporal differences by processing each column of pixels in one image, rather than processing each pixel of many 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. This method maintains a similar level of 
<a href="https://en.wikipedia.org/wiki/Accuracy_and_precision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    accuracy
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as that of traditional background updating, but because it is only analyzing one column of pixels for each frame of video, it uses a fraction of the 
<a href="https://en.wikipedia.org/wiki/Moore's_law"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computational power
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.BRIEF SUMMARY OF THE INVENTIONThe present invention is a computer-implemented method and system for transforming video 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a directional object count. In accordance with one approach, from each image in the image sequence a single column or row of pixels is isolated. The set of these is transformed via sequential concatenation into a separate image referred to herein as a “sweep image.” Each sweep image is transformed into a per-pixel detection signal via techniques of 
<a href="https://en.wikipedia.org/wiki/Foreground_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprised of: a) initializing the 
<a href="https://en.wikipedia.org/wiki/One-Dimensional_Man"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    one dimensional
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Cosmic_microwave_background"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; b) processing the sweep image while adaptively updating the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to account for temporal changes such as changes in illumination or ghosting; and c) 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 differences between the currently processed column of the sweep image and the background. In another embodiment, the system uses multiple 1-dimensional background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    models
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, to 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 element under both sunny and 
<a href="https://en.wikipedia.org/wiki/Aedes_aegypti"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloudy lig
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
hting. The per-pixel detection signal is then transformed into object location, and a detection count is performed via techniques including, for example, quasi-connected components (QCC) (
<a href="https://en.wikipedia.org/wiki/See"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    see
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, Boult, T. E., R. Micheals, X. Gao, P. Lewis, C. Power, W. Yin, and A. Erkan. “Frame-rate omnidirectional surveillance and tracking of camouflaged and occluded targets.” In Proceedings Second 
<a href="https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    IEEE
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 Workshop on Visual Surveillance (VS′99)(Cat. No. 98-89223), pp. 48-55. 
<a href="https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    IEEE
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, 1999, which is incorporated herein by reference) which obtain locational 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 about each object in the form of bounding boxes and their corresponding centroids. The position of centroids are evaluated with reference to the imaginary or drawn centerline separating direction of travel to produce a final directional object count.In accordance with a second approach, the image sequence is transformed into multiple sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by selecting and concatenating 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from two or more 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or rows of pixels. Transformations to object detections and location are then 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. By analyzing the relative 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between the 
<a href="https://en.wikipedia.org/wiki/Leading_edge"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    leading edge
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object, one can determine the direction of travel. One embodiment does this by transforming each sweep image to obtain 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 about position and scale-invariant feature transformation points (SIFT points (
<a href="https://en.wikipedia.org/wiki/See"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    see
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, U.S. Pat. No. 6,711,293, “Method and apparatus for identifying 
<a href="https://en.wikipedia.org/wiki/Scale_invariance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scale invariant
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image and use of same for locating an object in an image”, David Lowe's patent for the SIFT algorithm, Mar. 23, 2004, which is incorporated herein by reference). A comparison of 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Railroad_switch"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    set of points
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in each sweep image can determine object counts and each object's direction of travel. In another embodiment, these counts and estimates of direction are then combined with information about the centerline to produce a final directional object count.In 
<a href="https://en.wikipedia.org/wiki/Contrast"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    contrast
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to known art, both approaches use sequential concatenation combined with 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of one-dimensional 
<a href="https://en.wikipedia.org/wiki/Foreground_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to obtain a directional object count. The present computer-implemented method and system drastically reduce the 
<a href="https://en.wikipedia.org/wiki/Moore's_law"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computational power
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 required over the prior object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In another embodiment, the video subsystem is configured such that only one row or column from a 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Video_sensor_technology"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is all that is transferred to a main 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer processor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, thus reducing the 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into the 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer processor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In one embodiment this can be accomplished by using a one-dimensional 
<a href="https://en.wikipedia.org/wiki/Region_of_interest"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    region of interest
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on a 
<a href="https://en.wikipedia.org/wiki/Video_display_controller"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video chip
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In another embodiment, a thin 2-dimensional region is binned to produce the 1-dimensional signal. Those skilled in the art will appreciate how this can improve low 
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 operation. Another embodiment might use triggered or 
<a href="https://en.wikipedia.org/wiki/Superior_temporal_sulcus"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    asymmetric temporal
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sampling of the 
<a href="https://en.wikipedia.org/wiki/Video"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video signal
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to obtain the one-dimensional signal.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1A shows a standard-background-
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process for a crowded background environment, where the video camera is aimed at a fixed position. Each 
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame of video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a duration of time is seen in 100, 101, 102, and 103. 104 depicts one frame in which the system is calculating an updated background image 105. The result of subtracting image 104 from its relative background 105 is shown in image 106.FIG. 1B shows the process of background-
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 when used in combination with sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Images 120, 121, 122, and 123 are sequential frames in an image sequence where a particular column of pixels 130 is extract and the set of extracted 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 concatenated into corresponding 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 140, 141, 142, and 143 to create a new sweep image 150.FIG. 2 shows a perspective view of a 
<a href="https://en.wikipedia.org/wiki/Video_camera"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video camera
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 looking directly down onto a street with 230, 231, 232, and 233 being 
<a href="https://en.wikipedia.org/wiki/One-off_vehicle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    one vehicle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 driving across the video camera's view. Each image 200, 201, 202 and 203 represents one frame of video, with there being many frames in between these examples. From each image, the transform isolates two 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of pixels 210 and 220 and, which are concatenated into separate sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Column 210 is being captured for each 
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame of video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to transform it into sweep image 240 while column 220 is being captured for each 
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame of video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to transform it into sweep image 280.FIG. 3 illustrates an image sequence with 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 300, 301, 302, and 303 being individual frames capturing two moving vehicles. Images 310 and 315 are sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 made from the concatenation of two 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of pixels. The vehicles in images 310 and 315 correspond with those in 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 300-303; however, the difference in appearance is used to illustrate the elongation and compression that can arise in sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4 is a set of two sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 410 and 415. The figure shows an imaginary centerline 430 for embodiments of the present invention that use information about the centerline to indicate the direction of travel.FIG. 5 is a 
<a href="https://en.wikipedia.org/wiki/Flow_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating one technique to transform the sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and detect differences between the sweep image and its background using a multi-background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The diagram illustrates the 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of processing one pixel from the sweep image.FIG. 6A illustrates a 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of pixels 600 with n representing each pixel.FIG. 6B shows a section of an image 603 where each subdivision consists of a group of pixels.FIG. 7 illustrates using an external process that detects 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the video frames which can be transferred to produce ground-truth boxes in the sweep image.FIG. 8 shows using ground-truth boxes in the sweep image to determine ground-truth boxes in raw video frames.FIG. 9 is schematic of the present computer-implemented system._____c:1. A method of transforming video 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into moving object counts comprising the steps of:extracting a 1-dimensional region from each 
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame of video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;constructing a sweep image by appending a plurality of the 1-dimensional regions to form a 2-dimensional image;processing the 2-dimensional sweep image to determine each distinct object within the 2-dimensional image; andreturning the count of 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. The method according to claim 1, where the step of processing the 2-dimensional sweep image to determine each distinct object comprises the steps of:processing the 2-dimensional sweep image to estimate a 1-dimensional 
<a href="https://en.wikipedia.org/wiki/Cosmic_background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background region
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to no 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 present;comparing the 1-dimensional regions of the 2-dimensional sweep image to the 1-dimensional 
<a href="https://en.wikipedia.org/wiki/Cosmic_background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background region
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine regions of significant changes; andanalyzing regions of significant changes to determine separate 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.3. The method according to claim 1, where the step of processing the 2-dimensional sweep image to determine each distinct object comprises the steps of:computing edge response perpendicular to the 1-dimensional region used to create the 2-dimensional sweep image; andconnecting pairs of adjacent regions with significant edge response to determine separate 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.4. The method according to claim 1, wherein a direction of object 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is estimated based on relative object position within the 1-dimensional slice.5. The method according to claim 1, wherein:at least two 2-dimensional sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are constructed by extracting approximately parallel 1-dimensional regions from different regions from each 
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame of video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;a location analysis step determines a location of each object in each 2-dimensional sweep image;a matching step is performed associating 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between the at least two 2-dimensional sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andan analysis is performed to compute a direction of 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by comparing a relative location of matching 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between the at least two 2-dimensional sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The method according to claim 5, wherein background is computed as a 1-dimensional representation where each pixel is a pixel vise 
<a href="https://en.wikipedia.org/wiki/Median"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    median
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of associated pixels in each 1-dimensional 
<a href="https://en.wikipedia.org/wiki/Decision-making"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    region making
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 up the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.7. The method according to claim 5, wherein the step of processing the 2-dimensional sweep image to determine each distinct object is accomplished using the quasi-connected components algorithm providing for multi-resolution processing with a plurality of thresholds.8. The method according to claim 5 wherein the analysis to compute the direction of 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is augmented with a secondary process that matches visual 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between the at least two 2-dimensional sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and fuses the resulting estimate with results based on matched object location.9. The method according to claim 8, wherein the fusion of direction further includes an estimate of the direction of object 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on relative object position within the 1-dimensional region.10. The method according to claim 1, wherein the step of constructing the 2-dimensional sweep image is used to produce 
<a href="https://en.wikipedia.org/wiki/Ground_truth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ground truth
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by using a secondary process analyzing the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine a 
<a href="https://en.wikipedia.org/wiki/Ground_truth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ground truth
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of each object within the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, with a set of such 
<a href="https://en.wikipedia.org/wiki/Ground_truth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ground truth
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 bounding boxes being used in 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    models
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to optimize 
<a href="https://en.wikipedia.org/wiki/Parameter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameters
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 2-dimensional sweep image.12. The method according to claim 10, wherein the step of constructing the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 stores an identifier of each frame and Wherein 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object location is then used to determine first and last frames when the object was passing over a 
<a href="https://en.wikipedia.org/wiki/Human_back"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    back
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-projection of the 1-dimensional region, with frames of video then being used for 
<a href="https://en.wikipedia.org/wiki/Training"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    training
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a in 
<a href="https://en.wikipedia.org/wiki/Higher_education"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    chine learning model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to optimize detection 
<a href="https://en.wikipedia.org/wiki/Parameter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameters
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from an original video.13. The method according to claim 11, where 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the original frame in the neighborhood of the 
<a href="https://en.wikipedia.org/wiki/Human_back"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    back
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-projected 1-dimensional region is used to determine a front and a rear of the object, which is then used to extract bounding boxes for each object to be used for 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to optimize a secondary systems detection 
<a href="https://en.wikipedia.org/wiki/Parameter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameters
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.14. An system for transforming a sequence of image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into moving object counts comprising:an input means for sequentially entering input 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing a moving object region to be counted;a sweep image generation means for extracting 1-dimensional regions for each image and combining them into a 2-dimensional sweep image;storage means for storing the 2-dimensional sweep image;
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means for processing the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect object locations;counting means to process the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object locations and determine object counts; andan output means that communicates the object count to an external system.15. The system according to claim 14, wherein the 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means estimates the expected 1-dimensional signal when no object is present and compares that with the 1-dimensional signals in the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect and localize each object.16. The system according to claim 14, wherein the 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means estimates edge 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 perpendicular to the 1-dimensional signal of the 2-dimensional sweep image and uses the estimated edge 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect and localize each object.17. The system according to claim 14, further including a direction 
<a href="https://en.wikipedia.org/wiki/Computation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means that combines the object locations from the 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means and the direction of 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is estimated based on the relative object position within the 1-dimensional slice.18. The system according to claim 14, wherein the 2-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_Comics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sweep image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generation means produces at least two 2-dimensional sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from non-overlapping 1-dimensional regions, the 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means produces object locations for each of the at least two 2-dimensional sweep 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and the system includes a direction 
<a href="https://en.wikipedia.org/wiki/Computation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means that combines the object locations from the 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means and determines the direction of 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.19. The system according to claim 18, wherein multiple estimates of direction of notion are fused.20. The system according to claim 14, further including a ground-truth estimation means that estimated each object location within the 2-dimensional sweep image and a 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine-learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means that uses the result of the ground estimation means to tune system 
<a href="https://en.wikipedia.org/wiki/Parameter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameters
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to improve 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._______________IMAGE PROCESSING APPARATUS, IMAGE CAPTURING APPARATUS, IMAGE PROCESSING METHOD, AND NON-TRANSITORY COMPUTER-READABLE STORAGE MEDIUM_____20191219_____XMLs/xml/ipa191219.xml_____US-20190385316-A1 : US-16440089 : JP-2018-113845_____G06T0007254000 : G06K0009620000A captured image is registered, as a background image, from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted. In a case where it is determined that a moving object is included in a first background image registered at a first timing, the registered first background image is replaced with a second background image registered at a second timing prior to the first timing._____d:BACKGROUND OF THE INVENTIONField of the InventionThe present invention relates to a technique of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an object within an image.Description of the Related ArtConventionally, for a detection of the removal of a specific object in which 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is used, a background difference method, in which a comparison between a captured image and a background image that is obtained in advance is performed and a region not existing in the background image that is obtained in advance is extracted, is often used. FIG. 1 illustrates an example of removal detection processing in which the background difference method is used. Reference numeral 1000 is a background image including an object 101, and reference numerals 1001 to 1003 are captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured in this order. Reference numeral 1004 indicates a difference between the background image 1000 and the captured image 1001, reference numeral 1005 indicates a difference between the background image 1000 and the captured image 1002, and reference numeral 1006 indicates a difference between the background image 1000 and the captured image 1003.Since the object 101 is removed at a timing between the captured image 1001 and the captured image 1002, the object 101, which appears in the captured image 1001, does not appear in the captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 1002 and 1003 as illustrated in FIG. 1. For this reason, in the differences 1005 and 1006, a background difference 103 exists within a removal detection region 102 which was set in advance. An alert 104 (display of the frame surrounding the background difference 103) occurs when it is determined that the removal occurred in a case where the size of the background difference 103 is a stipulated size or more and the difference was present in the captured image for a fixed time or more.In order to guarantee the 
<a href="https://en.wikipedia.org/wiki/Accuracy_and_precision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    accuracy
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the removal detection, it is necessary to extract an accurate background difference, and to do so it is necessary to always set an appropriate background image. Although it is necessary to update the background image whenever a change in environment such as an illumination condition occurs in order to set an appropriate background image, there is a possibility that a background image that includes a moving object will be set when the background image is updated.FIG. 2 illustrates an example of removal detection processing in a case where a background image including a moving object is set. Reference numeral 2000 is a background image that includes a 
<a href="https://en.wikipedia.org/wiki/Hand"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hand
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 201 which is a moving object. Reference numerals 2001 to 2003 are captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which are captured in that order. Reference numeral 2004 indicates a difference between the background image 2000 and the captured image 2001, reference numeral 2005 indicates a difference between the background image 2000 and the captured image 2002, and reference numeral 2006 indicates a difference between the background image 2000 and the captured image 2003.The 
<a href="https://en.wikipedia.org/wiki/Hand"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hand
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 201 which is captured in the captured image 2001 does not appear in the captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 2002 and 2003. Here, the background difference 203 occurs within the removal detection region 102 in the differences 2005 and 2006. By this, there is a possibility that an alert 204 (display of the frame surrounding the background difference 203) will occur when it is determined that the removal occurred.A method in which, in order to resolve such a problem, the updating of the background image by an updating means is 
<a href="https://en.wikipedia.org/wiki/Interrupt"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interrupted
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 when a 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which is not appropriate as a background is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and the processing is resumed when the 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is no longer 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is disclosed in Japanese Patent No. 4811653. Additionally, a method in which a frame for which a difference does not exist is extracted by difference-between-frames processing and updating of the background image is performed by using such a frame is disclosed in Japanese Patent Laid-Open No. 2013-257785.However, in the conventional technique disclosed in the above-described Japanese Patent No. 4811653, it is necessary to determine the moving object as a 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and application is thought to be difficult in cases of quick changes and where an 
<a href="https://en.wikipedia.org/wiki/Angle_of_view"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    angle of view
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is limited. Also, in the conventional technique disclosed in Japanese Patent Laid-Open No. 2013-257785, it is necessary to also calculate a difference between frames in addition to the background difference, and the 
<a href="https://en.wikipedia.org/wiki/Computation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 load becomes large.SUMMARY OF THE INVENTIONIn the present invention, a technique for registering a background image appropriate for removal detection is provided.According to the first aspect of the present invention, there is provided an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus comprising: a registration unit configured to register, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted; a determination unit configured to determine whether or not a moving object is included in a first background image that the registration unit registered at a first timing; and a replacing unit configured to, in a case where the determination unit determines that a moving object is included in the first background image, replace the first background image that the registration unit registered with a second background image registered at a second timing prior to the first timing.According to the second aspect of the present invention, there is provided an image capturing apparatus, comprising: an image capturing unit configured to obtain a captured image, and an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, comprising: a registrat
<a href="https://en.wikipedia.org/wiki/Ion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 unit configured to register, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted; a determination unit configured to determine whether or not a moving object is included in a first background image that the registration unit registered at a first timing; and a replacing unit configured to, in a case where the determination unit determines that a moving object is included in the first background image, replace the first background image that the registration unit registered with a second background image registered at a second timing prior to the first timing.According to the third aspect of the present invention, there is provided an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method that an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus performs, the method comprising: registering, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted; determining whether or not a moving object is included in a first background image registered at a first timing; and in a case where it is determined that a moving object is included in the first background image, replacing the first background image with a second background image registered at a second timing prior to the first timing.According to the fourth aspect of the present invention, there is provided a non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 storing a 
<a href="https://en.wikipedia.org/wiki/Computer_program"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer program
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for causing a computer to function as: a registration unit configured to register, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted; a determination unit configured to determine whether or not a moving object is included in a first background image that the registration unit registered at a first timing; and a replacing unit configured to, in a case where the determination unit determines that a moving object is included in the first background image, replace the first background image that the registration unit registered with a second background image registered at a second timing prior to the first timing.Further 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the present invention will become apparent from the following description of exemplary embodiments (with reference to the attached drawings).BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 is a view which illustrates an example of removal detection processing using a background difference method.FIG. 2 is a view which illustrates an example of removal detection processing in the case of setting a background image including a moving object.FIG. 3 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which illustrates an example of a 
<a href="https://en.wikipedia.org/wiki/Functional"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    functional
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 arrangement of an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus.FIG. 4 is a view which illustrates an example of updating a background image.FIG. 5 is a flowchart describing an operation in an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus 300.FIG. 6 is a view which illustrates an example of a configuration of table information.FIG. 7 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which illustrates an example of a 
<a href="https://en.wikipedia.org/wiki/Functional"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    functional
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 arrangement of the 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus.FIG. 8 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which illustrates an example of a hardware configuration of a computer apparatus.FIG. 9 is a view which illustrates an example of a configuration of a system._____c:1. An 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus comprising:a registration unit configured to register, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted;a determination unit configured to determine whether or not a moving object is included in a first background image that the registration unit registered at a first timing; anda replacing unit configured to, in a case where the determination unit determines that a moving object is included in the first background image, replace the first background image that the registration unit registered with a second backg
<a href="https://en.wikipedia.org/wiki/Image_scaling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    round image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 registered at a second timing prior to the first timing.2. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the determination unit determines, based on a difference image for a difference between a sequentially inputted captured image and the second background image, whether or not a moving object is included in the first background image.3. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the replacing unit, in a case where the determination unit determines that a moving object is included in the first background image, replaces the first background image with the second background image which is most similar to a captured image inputted after the determination.4. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein in a case where the determination unit determines that a moving object is included in the first background image, and a similarity between a captured image inputted after the determination and the second background image does not exceed a predetermined value, the replacing unit replaces the first background image with that captured image.5. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the registration unit, in accordance with a frequency of the registrations, controls a number of the second background 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be registered.6. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, further comprising:a detection unit configured to, based on a difference between a sequentially inputted captured image and the first background image, determine whether or not an object is included in the captured image and detect an existence or absence of a removal in accordance with a result of the determination; anda notification unit configured to notify the result of detection by the detection unit.7. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 6, wherein the notification unit counts and notifies the number of the detection of a removal.8. An image capturing apparatus, comprising:an image capturing unit configured to obtain a captured image, andan 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, comprising:a registration unit configured to register, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted;a determination unit configured to determine whether or not a moving object is included in a first background image that the registration unit registered at a first timing; anda replacing unit configured to, in a case where the determination unit determines that a moving object is included in the first background image, replace the first background image that the registration unit registered with a second backg
<a href="https://en.wikipedia.org/wiki/Image_scaling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    round image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 registered at a second timing prior to the first timing.9. An 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method that an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus performs, the method comprising:registering, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted;determining whether or not a moving object is included in a first background image registered at a first timing; andin a case where it is determined that a moving object is included in the first background image, replacing the first background image with a second background image registered at a second timing prior to the first timing.10. A non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 storing a 
<a href="https://en.wikipedia.org/wiki/Computer_program"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer program
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for causing a computer to function as:a registration unit configured to register, as a background image, a captured image from among captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sequentially inputted;a determination unit configured to determine whether or not a moving object is included in a first background image that the registration unit registered at a first timing; anda replacing unit configured to, in a case where the determination unit determines that a moving object is included in the first background image, replace the first background image that the registration unit registered with a second backg
<a href="https://en.wikipedia.org/wiki/Image_scaling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    round image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 registered at a second timing prior to the first timing._______________MOVING OBJECT DETECTION METHOD AND SYSTEM_____20181220_____XMLs/xml/ipa181220.xml_____US-20180365845-A1 : US-15737155 : CN-201610692267.0 : WO-PCT/CN2016/108836-00_____G06T0007254000 : G06T0007231000A moving object detection method and a moving object detection system are provided. The method includes: predetermining a background image corresponding to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 monitored by a video monitoring device; performing a 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing on a grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background image to acquire a difference image; and binarizing the difference image and determining a moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where the determining the background image includes: dividing a first grayscale image frame and a second grayscale image frame in a grayscale image frame sequence captured by the video monitoring device into image blocks to acquire a first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 respectively, and determining the background image using a difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:This application claims priority to Chinese Patent Application No. 201610692267.0, titled “MOVING OBJECT DETECTION METHOD AND SYSTEM,” filed on Aug. 19, 2016 with the State Intellectual Property Office of People's Republic of China, which is incorporated herein by reference in its entirety.FIELDThe present disclosure relates to the technical field of monitoring 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    picture processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and in particular to a moving object detection method and a moving object detection system.BACKGROUNDWith rapid development of the 
<a href="https://en.wikipedia.org/wiki/Computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer technology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and continuous reduction of costs of various monitoring devices, 
<a href="https://en.wikipedia.org/wiki/Closed-circuit_television"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video monitoring
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 systems are extensively 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in fields of finance, transportation, military and the like. The technology for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and tracking a moving object in a video sequence has been an important research subject in the 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 field.In recent years, many scholars have proposed 
<a href="https://en.wikipedia.org/wiki/Solution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    solutions
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for moving object detection, such as the Gaussian mixture model algorithm (GMM), the codebook algorithm (Codebook), the visual background 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 algorithm (Vibe) and the GMG algorithm. According to the Gaussian mixture model algorithm, multiple independent Gaussian distributions are established for each pixel, thus a moving object in a 
<a href="https://en.wikipedia.org/wiki/Complex"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complex
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can be well extracted. However, this algorithm requires time for 
<a href="https://en.wikipedia.org/wiki/Training"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    training
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 samples. In addition, it is difficult to establish an effective background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using the 
<a href="https://en.wikipedia.org/wiki/Mixture_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Gaussian mixture model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 algorithm in a case that the lighting condition changes abruptly since 
<a href="https://en.wikipedia.org/wiki/Parameter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameters
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are fixed. According to the codebook algorithm, a codebook 
<a href="https://en.wikipedia.org/wiki/Structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is established for each pixel, thereby providing a good real-time 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. However, a large amount of memory is occupied, and the algorithm is susceptible to subtle disturbances in the background. The visual background 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 algorithm adopts a random sample 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, thus a complete moving object can be rapidly extracted, and the algorithm has certain immunity to noises. However, the disadvantages of the algorithm includes that, sample values of the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are repeatedly selected, a fixed 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 threshold cannot adapt to dynamic change of the background in a 
<a href="https://en.wikipedia.org/wiki/Complex"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complex
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 video 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and noises caused by changes of the lighting cannot be effectively eliminated using the fixed updating factor. The GMG algorithm is a non-parametric method, which generates a time-varying background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using the 
<a href="https://en.wikipedia.org/wiki/Bayesian_inference"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 inference. The algorithm shows a poor 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a lighting-varying 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.As can be seen, a process of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a moving object in a video monitoring picture according to the conventional technology is relatively cumbersome and a detection effect needs further improvement.In view of the above, problems to be solved include how to improve the effect of moving object detection and how to reduce the complexity of the detection process.SUMMARYIn view of this, the purpose of the present disclosure is to provide a moving object detection method and a moving object detection system, with which a effect of moving object detection can be improved and the complexity of a detection process can be reduced. The solution is as follows.A moving object detection method is provided, which includes:predetermining a background image corresponding to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 monitored by a video monitoring device;performing a 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing on a grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background image to acquire a difference image; andbinarizing the difference image and determining a moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,where the determining the background image includes:dividing a first grayscale image frame and a second grayscale image frame in a grayscale image frame sequence captured by the video monitoring device into image blocks to acquire a first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 respectively, anddetermining the background image using a difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Preferably, a time instant at which the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is captured may be greater than or equal to a time instant at which the first grayscale image frame is captured, the time instant at which the first grayscale image frame is captured may be greater than a time instant at which the second grayscale image frame is captured, and there may be N grayscale image frames between the first grayscale image frame and the second grayscale image frame, where N is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer.Preferably, the dividing the first grayscale image frame and the second grayscale image frame in the grayscale image frame sequence captured by the video monitoring device into image blocks may include:dividing the first grayscale image frame into K image blocks which do not overlap with each other and include all pixels in the first grayscale image frame, to acquire the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, anddividing the second grayscale image frame into K image blocks which do not overlap with each other and include all pixels in the second grayscale image frame, to acquire the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, whereK is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer, the image blocks have the same size, and the K image blocks in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have a one-to-one correspondence with the K image blocks in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Preferably, the determining the background image using the difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include:calculating the difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andacquiring the background image using the difference and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Preferably, the calculating the difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include:calculating an image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference between each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a corresponding image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, to acquire an image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference set, where an i-th element in the image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference set is calculated according to 
<a href="https://en.wikipedia.org/wiki/Equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    an equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
:di=|gt,i−gt−N,i|,where gt,i represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which is represented by gt, gt−N,i represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which is represented by gt−N, and di represents an image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference between the i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where i=1, 2, . . . , K; andcalculating a difference between each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a corresponding image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using the image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference set to acquire a difference set, where an i-th element in the difference set is calculated according to 
<a href="https://en.wikipedia.org/wiki/Equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    an equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
:si=∑1≤x≤n,1≤y≤mdi(x,y),where n represents the length of each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, m represents the width of each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, both n and m are in units of pixels, di(x,y) represents a grayscale difference in di corresponding to an (x,y)-th pixel in the image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and si represents a difference between an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Preferably, the acquiring the background image using the difference and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include:converting the difference set to a determination set using a preset conversion equation:wi={1,si≤TH10,else,where TH1 represents a preset difference threshold, and wi represents an i-th determination element in the determination set; andinputting the determination set and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a preset first background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to acquire the background image, where the first background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is expressed as:bi={gt,i,wi=1bi,wi=0,where bi represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the background image, and bi′ represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a previous background image.Preferably, the acquiring the background image using the difference and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include:inputting the difference set and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a preset second background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to acquire the background image, where the second background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is expressed as:bi={gt,i,si≤TH1bi′,else,where TH1 represents a preset difference threshold, bi represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the background image, and bi′ represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a previous background image.Preferably, in a case that the previous background image is a first background image, the first background image may be an image in which grayscale values of all pixels are 0.Preferably, the binarizing the difference image and determining the moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include:binarizing the difference image using a preset binarization processing equation to acquire a binarized image, where the binarization processing equation is expressed as:F′(p,q)={0,F(p,q)≤TH2255,else,where TH2 represents a preset grayscale threshold, F(p,q) represents a grayscale value corresponding to a (p,q)-th pixel in the difference image, which is represented by F, and F′(p,q) represents a grayscale value corresponding to a (p,q)-th pixel in the binarized image; andextracting pixels of which grayscale values are 255 from the binarized image to acquire the moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.A moving object detection system is further provided according to the present disclosure, which includes:a background image determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, configured to predetermine a background image corresponding to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 monitored by a video monitoring device;a difference image acquisition 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, configured to perform a 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing on a grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background image to acquire a difference image; anda moving object determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, configured to binarize the difference image and determine a moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,where the background image determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 being configured to determine the background image includes:the background image determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 being configured todivide a first grayscale image frame and a second grayscale image frame in a grayscale image frame sequence captured by the video monitoring device into image blocks to acquire a first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 respectively, anddetermine the background image using a difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In the present disclosure, two grayscale image frames in the captured grayscale image frame sequence are divided into image blocks in advance, and the background image is determined using the difference between two image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sets acquired by division. As can be seen, the background image is determined based on the difference between the image blocks according to the present disclosure. As compared with the scheme of determining the background image based on the difference between pixels, the 
<a href="https://en.wikipedia.org/wiki/Data_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 amount is greatly reduced according to the present disclosure. Moreover, according to the present disclosure, the image frames for constructing the background image are grayscale image frames. Therefore, the overall 
<a href="https://en.wikipedia.org/wiki/Data_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 amount for determining the background image is small, since grayscale 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 contain less information, which is beneficial for reducing the complexity of moving object detection. Further, after the background image is determined, according to the present disclosure, the 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing is performed on a grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the above background image to acquire a difference image, and the difference image is binarized, so as to determine a moving object in the above grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. As can be seen, according to the present disclosure, during construction of the background image, 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the difference image and binarization, all the processed 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is grayscale 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, thus the capability of the moving object detection process according to the present disclosure of rejecting external interference 
<a href="https://en.wikipedia.org/wiki/Factor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    factors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can be improved, thereby improving the effect of moving object detection. In summary, the effect of the moving object detection is improved and the complexity of the detection process is reduced according to the present disclosure.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart of a moving object detection method according to an embodiment of the present disclosure; andFIG. 2 is schematic structural diagram of a moving object detection system according to an embodiment of the present disclosure._____c:1. A moving object detection method, comprising:predetermining a background image corresponding to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 monitored by a video monitoring device;performing a 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing on a grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background image to acquire a difference image; andbinarizing the difference image and determining a moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,wherein the determining the background image comprises:dividing a first grayscale image frame and a second grayscale image frame in a grayscale image frame sequence captured by the video monitoring device into image blocks to acquire a first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 respectively, anddetermining the background image using a difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. The moving object detection method according to claim 1, wherein a time instant at which the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is captured is greater than or equal to a time instant at which the first grayscale image frame is captured, the time instant at which the first grayscale image frame is captured is greater than a time instant at which the second grayscale image frame is captured, and there are N grayscale image frames between the first grayscale image frame and the second grayscale image frame, wherein N is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer.3. The moving object detection method according to claim 2, wherein the dividing the first grayscale image frame and the second grayscale image frame in the grayscale image frame sequence captured by the video monitoring device into image blocks comprises:dividing the first grayscale image frame into K image blocks which do not overlap with each other and include all pixels in the first grayscale image frame, to acquire the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, anddividing the second grayscale image frame into K image blocks which do not overlap with each other and include all pixels in the second grayscale image frame, to acquire the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, whereinK is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer, the image blocks have the same size, and the K image blocks in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have a one-to-one correspondence with the K image blocks in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.4. The moving object detection method according to claim 3, wherein the determining the background image using the difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:calculating the difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andacquiring the background image using the difference and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The moving object detection method according to claim 4, wherein the calculating the difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:calculating an image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference between each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a corresponding image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, to acquire an image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference set, wherein an i-th element in the image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference set is calculated according to 
<a href="https://en.wikipedia.org/wiki/Equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    an equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
:wherein gt,i represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which is represented by gt, gt−N,i represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which is represented by gt−N, and di represents an image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference between the i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein i=1, 2, . . . , K; andcalculating a difference between each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a corresponding image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using the image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 grayscale difference set to acquire a difference set, wherein an i-th element in the difference set is calculated according to 
<a href="https://en.wikipedia.org/wiki/Equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    an equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
:wherein n represents the length of each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, m represents the width of each image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, both n and m are in units of pixels, di(x,y) represents a grayscale difference in di corresponding to an (x,y)-th pixel in the image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and si represents a difference between an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The moving object detection method according to claim 5, wherein the acquiring the background image using the difference and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:converting the difference set to a determination set using a preset conversion equation:wherein TH1 represents a preset difference threshold, and wi represents an i-th determination element in the determination set; andinputting the determination set and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a preset first background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to acquire the background image, wherein the first background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is expressed as:wherein bi represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the background image, and bi′ represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a previous background image.7. The moving object detection method according to claim 5, wherein the acquiring the background image using the difference and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:inputting the difference set and the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a preset second background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to acquire the background image, wherein the second background image 
<a href="https://en.wikipedia.org/wiki/Quadratic_equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    construction equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is expressed as:wherein TH1 represents a preset difference threshold, bi represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the background image, and bi′ represents an i-th image 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a previous background image.8. The moving object detection method according to claim 6, wherein in a case that the previous background image is a first background image, the first background image is an image in which grayscale values of all pixels are 0.9. The moving object detection method according to claim 6, wherein the binarizing the difference image and determining the moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:binarizing the difference image using a preset binarization processing equation to acquire a binarized image, wherein the binarization processing equation is expressed as:wherein TH2 represents a preset grayscale threshold, F(p,q) represents a grayscale value corresponding to a (p,q)-th pixel in the difference image, which is represented by F, and F′(p,q) represents a grayscale value corresponding to a (p,q)-th pixel in the binarized image; andextracting pixels of which grayscale values are 255 from the binarized image to acquire the moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.10. A moving object detection system, comprising:a background image determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, configured to predetermine a background image corresponding to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 monitored by a video monitoring device;a difference image acquisition 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, configured to perform a 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing on a grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background image to acquire a difference image; anda moving object determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, configured to binarize the difference image and determine a moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,wherein the background image determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 being configured to determine the background image comprises:the background image determination 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 being configured todivide a first grayscale image frame and a second grayscale image frame in a grayscale image frame sequence captured by the video monitoring device into image blocks to acquire a first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 respectively, anddetermine the background image using a difference between the first image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second image 
<a href="https://en.wikipedia.org/wiki/R.O.B."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block set
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.11. The moving object detection method according to claim 7, wherein in a case that the previous background image is a first background image, the first background image is an image in which grayscale values of all pixels are 0.12. The moving object detection method according to claim 7, wherein the binarizing the difference image and determining the moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:binarizing the difference image using a preset binarization processing equation to acquire a binarized image, wherein the binarization processing equation is expressed as:wherein TH2 represents a preset grayscale threshold, F(p,q) represents a grayscale value corresponding to a (p,q)-th pixel in the difference image, which is represented by F, and F′(p,q) represents a grayscale value corresponding to a (p,q)-th pixel in the binarized image; andextracting pixels of which grayscale values are 255 from the binarized image to acquire the moving object in the grayscale image to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._______________OBJECT TRACKING SYSTEM AND METHOD THEREOF_____20191205_____XMLs/xml/ipa191205.xml_____US-20190370984-A1 : US-16241613 : TW-107118678_____G06T0007254000 : G06K0009000000 : G06T0007194000 : G06T0007130000 : G06T0005000000 : G06T0005500000An object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, an object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and an object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determines an attribute information of each pixel position of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame according to a difference between a pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame, so as to generate a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame. The object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sets a label to each pixel position according to the attribute information of surrounding pixel positions of each pixel position, and connects adjacent pixel positions with the same label to form an object. The object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determines the object being a tracked object according to whether the pixel positions corresponding to the object are at least partially overlapped with the pixel positions corresponding to the tracked object._____d:CROSS REFERENCE TO RELATED APPLICATIONThis application claims the benefits of the Taiwan Patent Application Serial Number 107118678, filed on May 31, 2018, the subject matter of which is incorporated herein by reference.BACKGROUND OF THE INVENTION1. Field of the InventionThe present invention relates to an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system and a method thereof, and more particularly to an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a method thereof.2. Description of Related ArtObject tracking has been a popular research subject in the field of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a long time. In practical object tracking tasks, the tracking 
<a href="https://en.wikipedia.org/wiki/Accuracy_and_precision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    accuracy
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and subsequent operations are highly dependent on occlusion among different objects and appearance change of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, making object tracking a technically challenging work. For the same reason, most existing tracking technologies are somehow incompetent. For example, the algorithm-based 
<a href="https://en.wikipedia.org/wiki/Solution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    solutions
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are too complicated to be used in real-time 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and their use must be confined in a 
<a href="https://en.wikipedia.org/wiki/Simple"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    simple
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 monitoring environment, leaving much room for improvement. Besides, most known tracking 
<a href="https://en.wikipedia.org/wiki/Solution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    solutions
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 require considerable labor in 
<a href="https://en.wikipedia.org/wiki/Pre"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pre
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-processing and/or post-processing operations, such as that for building a robust background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in advance, resulting in unsatisfactory labor and time costs.In view of this, the present invention provides an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a method thereof for addressing the foregoing problems and being 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in any real-world environment.SUMMARY OF THE INVENTIONOne objective of the present invention is to provide an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which comprises: a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, determining an attribute information of each pixel position of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame of a frame series according to a difference between a pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame, so as to generate a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame, wherein the attribute information is of a foreground attribute or a background attribute; an object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, setting a label to each said pixel position according to the attribute information of a plurality of surrounding pixel positions of each said pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame, and connecting a plurality of adjacent said pixel positions with the same label to form an object; and an object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, determining the object is a specific object according to whether the pixel positions corresponding to the object in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame are at least partially overlapped with the pixel positions corresponding to the specific object in a previous foreground frame of the frame series, and converting the label corresponding to the object into the label of the specific object.Another objective of the present invention is to provide an object tracking method, which is configured to be performed by an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and comprises steps of: making a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determine an attribute information of each pixel position of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame according to a difference between a pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame, so as to generate a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foregro
<a href="https://en.wikipedia.org/wiki/UND"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    und
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame, wherein the attribute information is of a foreground attribute or a background attribute; making an object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 set a label to each said pixel position according to the attribute information of a plurality of surrounding pixel positions of each said pixel position, and connect a plurality of adjacent said pixel positions with the same label to form an object; and making an object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determine the object is a specific object according to whether the pixel positions corresponding to the object in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame are at least partially overlapped with the pixel positions corresponding to the specific object in a previous foreground frame, and convert the label corresponding to the object into the label of the specific object.Other 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, advantages, and novel 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the invention will become more apparent from the following detailed description when taken in conjunction with the accompanying drawings.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1(A) is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to one embodiment of the present invention;FIG. 1(B) is an overall flowchart of an object tracking method according to one embodiment of the present invention;FIG. 2(A) is a detailed operational diagram of a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to one embodiment of the present invention;FIG. 2(B) is a detailed operational diagram of a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to another embodiment of the present invention;FIG. 3(A) is a detailed operational diagram of an object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to one embodiment of the present invention;FIG. 3(B) illustrates the operation of step S31 of FIG. 3(A) according to one embodiment of the present invention;FIG. 3(C) illustrates the operation of step S32(a) of FIG. 3(A) according to one embodiment of the present invention;FIG. 3(D) illustrates the operation of step S32(b) of FIG. 3(A) according to one embodiment of the present invention;FIG. 3(E) illustrates the operation of step S32(c) of FIG. 3(A) according to one embodiment of the present invention;FIG. 3(F) illustrates the operation of step S33 of FIG. 3(A) according to one embodiment of the present invention;FIG. 3(G) illustrates the operation of step S34 of FIG. 3(A) according to one embodiment of the present invention;FIGS. 3(H) to 3(J) illustrate the operation of step S35 of FIG. 3(A) according to one embodiment of the present invention;FIG. 4 is an operational diagram of an object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to one embodiment of the present invention; andFIG. 5 is an operational diagram of an object occlusion resolving 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to one embodiment of the present invention._____c:1. An object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, comprising:a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, determining an attribute information of each pixel position of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame of a frame series according to a difference between a pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame, so as to generate a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame, wherein the attribute information is of a foreground attribute or a background attribute;an object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, setting a label to each said pixel position according to the attribute information of a plurality of surrounding pixel positions of each said pixel position, and connecting a plurality of adjacent said pixel positions with the same label to form at least one object; andan object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, determining the at least one object being a specific object according to whether the pixel positions corresponding to the at least one object in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame are at least partially overlapped with the pixel positions corresponding to the specific object in a previous foreground frame of the frame series, and converting the label corresponding to the at least one object into the label of the specific object.2. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, wherein the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further uses a Gaussian 
<a href="https://en.wikipedia.org/wiki/Smoothing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    smoothing matrix
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to perform a 
<a href="https://en.wikipedia.org/wiki/Smoothing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    smoothing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 operation on the difference between the pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame.3. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, wherein when a pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame is of the background attribute, the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 performs a filtering operation to update the pixel value of a corresponding pixel position of the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame.4. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, wherein the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further generates a successive frame difference information of each pixel position according to a difference between the pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a previous frame.5. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 4, wherein when a pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame is of the foreground attribute, the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further generates a foreground accumulated time information of the pixel position according to the successive frame difference information and a pixel value hold time information of the pixel position, and determines whether the pixel position has to be changed to the background attribute according to whether the foreground accumulated time information is greater than a foreground lasting time threshold.6. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 4, wherein when a pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame is of the foreground attribute, the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further compares the pixel value of the pixel position with those of corresponding pixel positions in a plurality of background samples, and determines whether the pixel position has to be changed to the background attribute according to whether a match degree between the pixel position and the corresponding pixel positions in the background samples is greater than a preset threshold.7. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, wherein when a pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame is of the foreground attribute, and the plurality of surrounding pixel positions of the pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame are all of the background attribute, the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sets a minimal label that has not been used to the pixel position; when a pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame is of the foreground attribute, and the plurality of surrounding pixel positions of the pixel position are all of the foreground attribute and have the same label, the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sets the same label to the pixel position; when a pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame is of the foreground attribute, and the plurality of surrounding pixel positions of the pixel position are all of the foreground attribute and have at least two different labels, the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sets a minimal one between the at least two labels to the pixel position.8. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, wherein the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further determines whether two 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have to be combined according to a boundary information of the two 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame.9. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, further comprising an object occlusion resolving 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which determines whether there is object occlusion in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame according to a moving trajectory and an edge feature of at least one specific object in the frame series.10. The object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 9, wherein the object occlusion resolving 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 splits at least two 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that are of a staggered case object in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame according to the moving trajectory, the edge feature and an average area of the at least one specific object.11. An object tracking method, which is performed by an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, comprising the steps of:using a foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine an attribute information of each pixel position of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame of a frame series according to a difference between a pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame, so as to generate a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame, wherein the attribute information is of a foreground attribute or a background attribute;using an object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to set a label to each said pixel position according to the attribute information of a plurality of surrounding pixel positions of each said pixel position, and connect a plurality of adjacent said pixel positions with the same label to form at least one object; andusing an object tracking 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine the at least one object being a specific object according to whether the pixel positions corresponding to the at least one object in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame are at least partially overlapped with the pixel positions corresponding to the specific object in a previous foreground frame, and convert the label corresponding to the at least one object into the label of the specific object.12. The object tracking method according to claim 11, further comprising the step of: enabling the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to use a Gaussian 
<a href="https://en.wikipedia.org/wiki/Smoothing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    smoothing matrix
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to perform a 
<a href="https://en.wikipedia.org/wiki/Smoothing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    smoothing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 operation on the difference between the pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame.13. The object tracking method according to claim 11, further comprising the step of: when a pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame is of the background attribute, using the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to perform a filtering operation to update the pixel value of a corresponding pixel position of the background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame.14. The object tracking method according to claim 11, further comprising the step of: using the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate a successive frame difference information of each pixel position according to a difference between the pixel value of each pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame and that of a previous frame.15. The object tracking method according to claim 14, further comprising the step of: when a pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame is of the foreground attribute, using the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate a foreground accumulated time information of the pixel position according to the successive frame difference information and a pixel value hold time information of the pixel position, and determine whether the pixel position has to be changed to the ba
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ckground
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 attribute according to whether the foreground accumulated time information is greater than a foreground lasting time threshold.16. The object tracking method according to claim 14, further comprising the step of: when a pixel position of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing frame is of the foreground attribute, using the foreground identifying 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to compare the pixel value of the pixel position with those of corresponding pixel positions in a plurality of background samples, and determine whether the pixel position has to be changed to the background attribute according to whether a match degree between the pixel position and the corresponding pixel positions in the background samples is greater than a preset threshold.17. The object tracking method according to claim 11, further comprising the step of: when a pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame is of the foreground attribute, and the plurality of surrounding pixel positions of the pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame are all of the background attribute, using the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to set a minimal label that has not been used to the pixel position; when a pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame is of the foreground attribute, and the plurality of surrounding pixel positions of the pixel position are all of the foreground attribute and have the same label, using the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to set the same label to the pixel position; and when a pixel position in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame is of the foreground attribute, and the plurality of surrounding pixel positions of the pixel position are all of the foreground attribute and have at least two different labels, using the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to set a minimal one between the at least two labels to the pixel position.18. The object tracking method according to claim 11, further comprising the step of: using the object grouping 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine whether two 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have to be combined according to a boundary information of the two 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the current foreground frame.19. The object tracking method according to claim 11, further comprising the step of: using an object occlusion resolving 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine whether there is object occlusion in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame according to a moving trajectory and an edge feature of at least one specific object in the frame series.20. The object tracking method according to claim 19, further comprising the step of: using the object occlusion resolving 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to split at least two 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that are of a staggered case object in the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 foreground frame according to the moving trajectory, the edge feature and an average area of the at least one specific object._______________MEASURING A PROPERTY OF A TRAJECTORY OF A BALL_____20190829_____XMLs/xml/ipa190829.xml_____US-20190266735-A1 : US-16348715 : AU-2016904594 : WO-PCT/AU2017/051236-00_____G06T0007254000A method for determining whether a goal is achieved by a trajectory of a ball using a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device comprises capturing a sequence of video frames of the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball with
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a camera of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device; 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the ball in at least three of the video frames; computing a trajectory of the ball using the detections of the ball; 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a goal image in at least one of the video frames; computing whether the trajectory of the ball achieves intersection or similar with a goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 computed from the goal im—age according to a goal criterion._____d:FIELD OF THE INVENTIONThe present invention relates to a method of measuring a property of a trajectory of a ball with a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device.BACKGROUNDMobile computer devices, including smartphones, 
<a href="https://en.wikipedia.org/wiki/Tablet_computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tablet computers
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the like are widely used. Most people now own a 
<a href="https://en.wikipedia.org/wiki/Smartphone"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    smart phone
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Commonly, these 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 devices have an in-built camera and can be loaded with customised software, commonly referred to as an App.Sports are a common pass time and a source of competition between players, not just during the playing of a sports 
<a href="https://en.wikipedia.org/wiki/Game"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    game
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, but on how well a player's skills compare with another player. Association football, also known as soccer, is a type of football widely played around the world. Players of soccer, even on the same team, will often be competitive about how accurate they can kick the soccer ball, how fast they can kick or how well they can deceive a goalkeeper into thinking they are kicking to one side of the goals, but in actuality kick to the other side of the goals.The present invention relates to ball games such as soccer, tennis, table tennis, basketball, baseball or golf, and using a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device to determine a property of a kicked, batted or thrown ball. The present invention also relates to use of the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine if a goal is achieved.US Patent Application 20140300733 focuses on 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the speed of the ball from a side view. While useful for some sports, the side view tracking of a ball is not useful in others.US Patent Application 20140300745 again focuses on 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the speed of the ball between two time spaced frames, by measuring distance travelled by the ball over the time to determine the speed.U.S. Pat. No. 9,275,470 
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a ball by tracking the image on the ball.US Patent Application 20140301598 focuses on tracking a ball based on 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the ball in 2D pixel space, converting the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 ball into 3D space and then determining a characteristic of the ball. However, this does not account for false 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detections of the ball.A reference to a 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 document is not intended to be an admission that such a 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 document forms part of the common general 
<a href="https://en.wikipedia.org/wiki/Knowledge"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    knowledge
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a person skilled in the art of the invention in any jurisdiction.In this specification the terms “comprising” or “comprises” are used inclusively and not exclusively or exhaustively.SUMMARY OF THE INVENTIONAccording to an aspect of the present invention there is provided a method for determining a property of a trajectory of a ball with a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, comprising:capturing a sequence of video frames of the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball with
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a camera of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device;finding candidates of the ball in at least three of the video frames; eliminating false 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detections of the ball, comprising fitting ball candidates to a 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which ball candidates not sufficiently representing the curve trajectory are eliminated as ball candidates;computing a property of the trajectory of the ball using travel of the ball through the 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In an embodiment the eliminating step comprises eliminating outlier candidates of the ball, leaving remaining candidate balls to which the fitting occurs. In an embodiment eliminating outlier candidate balls comprises conducting a random sample consensus iterative analysis across the at least three frames to eliminate unlikely candidates of the position of the ball in the frames. In an embodiment the eliminating step comprises eliminating ball candidates that do not have an appropriate sequential change in the size of a circle fitted to the perimeter of the found ball candidates.In an embodiment the curve is fitted to candidates of the ball for video frames in which the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball is
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determined to be moving.In an embodiment the method further comprises identifying a reference object in the video frames. Preferably the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is stationary, so that the reference object is stationary in the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In an embodiment the reference object is a soccer goal. In an embodiment the type of reference object is predetermined according to the type of sport in which the ball is used. For example, if a soccer goal is identified then a soccer 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball is
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sought to be identified, however if a basketball ring is identified then a basketball is sought to be identified.In an embodiment the fitting step comprises finding a centre of each candidate ball as a 2-dimensional coordinate in pixel space.In an embodiment the fitting step comprises converting the centre of each candidate ball into a 3 dimensional coordinate in space.In an embodiment the fitting step comprises fitting a 
<a href="https://en.wikipedia.org/wiki/Conic_section"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    quadratic curve
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to at least one 
<a href="https://en.wikipedia.org/wiki/Anatomical_plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cardinal plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 through the 3 dimensional coordinate space. In an embodiment the fitting step comprises fitting a 
<a href="https://en.wikipedia.org/wiki/Conic_section"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    quadratic curve
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to each of the three ca
<a href="https://en.wikipedia.org/wiki/Conic_section"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rdinal
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 planes through the 3 dimensional coordinate space.In an embodiment the fitting of the trajectory curve comprises constraining movement of the ball through the vertical planes according to acceleration due to gravity.In an embodiment the camera is positioned substantially rearward of the direction of travel of the ball.In an embodiment finding ball candidates comprises converting each of the at least three video frames into greyscale. In an embodiment finding ball candidates comprises determining a difference image between consecutive ones of the at least three video frames. In an embodiment finding ball candidates comprises converting the difference 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a binary image. In an embodiment finding ball candidates comprises applying a function to remove groups of adjacent pixels in each of the at least three video frames that are too small. In an embodiment finding ball candidates comprises applying a function to remove groups of adjacent pixels in each of the at least three video frames that are too big. In an embodiment finding ball candidates comprises calculating a 
<a href="https://en.wikipedia.org/wiki/Vector_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    gradient vector field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In an embodiment finding ball candidates comprises shape matching. In an embodiment the shape matching comprises checking that the gradient direction in the gradient vector field is a smooth circle. In an embodiment the shape matching comprises applying a Hough transform.In an embodiment finding ball candidates comprises eliminating ball candidates outside of an area of interest.In an embodiment the method further comprises computing whether the trajectory of the ball achieves intersection or similar with a goal image in the video frames according to a goal criterion.In an embodiment the property computed comprises one or more of:The speed of the ballThe force with which the ball was kickedThe angle at which the ball was kickedThe flight time and distance of the ballThe 
<a href="https://en.wikipedia.org/wiki/Spin"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    spin
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 asserted on the ballAccording to an aspect of the present invention there is provided a method for determining whether a goal is achieved by a trajectory of a ball using a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, comprising:capturing a sequence of video frames of the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball with
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a camera of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device;
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the ball in at least three of the video frames;computing a trajectory of the ball using the detections of the ball; 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a goal image in at least one of the video frames;computing whether the trajectory of the ball achieves intersection or similar with a goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 computed from the goal image according to a goal criterion.In an embodiment 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the goal image comprises determining the position of a goal in the at least one of the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In an embodiment computing the goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises determining a 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in 3 
<a href="https://en.wikipedia.org/wiki/Four-dimensional_space"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    dimensional space
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which coincides with the position of the goal in the at least one of the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In an embodiment 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the goal image comprises defining a shape of the goal in the determined 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In an embodiment computing the trajectory of the ball comprises fitting a curve to the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 ball in the at least three video frames. In an embodiment computing whether the trajectory of the ball achieves intersection or similar with the goal image comprises computing whether the curve fitted to the trajectory of the ball intersects with the inside of the defined shape.In an embodiment the goal criterion comprises one or more of achieving a minimum speed of the ball; achieving placement of the ball in a particular position in the goal image; achieving a particular 
<a href="https://en.wikipedia.org/wiki/Spin"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    spin
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the ball.In an embodiment the goal criterion comprises a difficulty input.In an embodiment the goal criterion determines whether the kick of the ball would be a goal or not according to the difficulty input.In an embodiment the goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is mapped to a 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In an embodiment the 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is determined by characteristics assigned to a virtual goalkeeper. A virtual goalkeeper may be a generic goalkeeper, or a personality goalkeeper. In an embodiment the characteristics comprise height, arm span, speed and 
<a href="https://en.wikipedia.org/wiki/Reaction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    reaction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 time. In an embodiment the goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is mapped to a 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to 
<a href="https://en.wikipedia.org/wiki/Equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    an equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a curve derived from the characteristics of height and arm span.In an embodiment a 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is selected form the 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the placement of the ball. Placement is determined by 
<a href="https://en.wikipedia.org/wiki/Missionary_position"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    position of crossing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In an embodiment the selected 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is modified according to characteristics of the kick, such as for example ball speed and path deviation. Path deviation is determined by 
<a href="https://en.wikipedia.org/wiki/Finger_spin"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball spin
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.The method may be performed on a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, such as a smartphone, 
<a href="https://en.wikipedia.org/wiki/Tablet_computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tablet computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or mobile 
<a href="https://en.wikipedia.org/wiki/VLC_media_player"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    media player
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.The method steps can, for example, be performed by a 
<a href="https://en.wikipedia.org/wiki/Computer_program"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer program
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (such as an app) installed on the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device. Alternatively, the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device may be equipped with the claimed functionality.The method can use the camera of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device to take a sequence of video frames of, for example, a kick of a soccer ball. It is contemplated to use the method with other ball sports such as tennis, golf, table tennis, football, basketball, baseball and the like. Also, instead of a kick, the ball may be batted, for example, as a 
<a href="https://en.wikipedia.org/wiki/Tennis_ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tennis ball
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is 
<a href="https://en.wikipedia.org/wiki/Hit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; or thrown, for example, as a basketball is thrown.The sequence of video frames may be taken directly by use of the app, which performs the method steps. Alternatively the sequence may be taken with a default 
<a href="https://en.wikipedia.org/wiki/Application_software"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video application
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, stored in a memory of the mobile 
<a href="https://en.wikipedia.org/wiki/Computer_hardware"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and subsequently provided to an app for analysis.One or more parts of the finding, fitting, 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, or computing steps may be performed on a 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 remote from the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 under the 
<a href="https://en.wikipedia.org/wiki/Control"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    control
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Some of the ball detection techniques described in US 20140300745 and/or US 20140301598 may be used, the contents of both is incorporated herein by reference.According to a further aspect of the present invention there is a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device configured to perform a method described herein.According to a still further aspect of the present invention there is a 
<a href="https://en.wikipedia.org/wiki/Computer_program"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer program
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which comprises instructions for controlling a processor and a camera of a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device to perform a method described herein.BRIEF DESCRIPTION OF THE DRAWINGSEmbodiments of the present invention are described in the following detailed description by example only, with reference to the following drawings:FIG. 1: is a front view of an example 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device on which embodiments of the present invention may be implemented.FIG. 2: is a side view of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device of FIG. 1.FIG. 3: is a schematic representation of the beginning of recording a sequence of video frames of a kick to a ball towards a soccer goal.FIG. 4: is a schematic 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Component"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    of components
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of FIG. 1.FIG. 5: is a schematic 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an application for 
<a href="https://en.wikipedia.org/wiki/Capital_punishment"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    execution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6: is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart of a method of an embodiment of the present invention.FIG. 7: is an example of a screen view on the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of FIG. 1 in which the ball is identified before being kicked.FIG. 8: is an example of a screen view on the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of FIG. 1 in which the ball has been kicked showing a schematic representation of 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 instances of the trajectory of the ball.FIG. 9: is an example of a screen view on the 
<a href="https://en.wikipedia.org/wiki/Mobile_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of FIG. 1 in which the trajectory of FIG. 8 is shown along with a curve fitted to the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 trajectory of the ball.FIG. 10: is a schematic representation of a computer generated recreation of the kick of the ball.FIG. 11: is a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first type of 
<a href="https://en.wikipedia.org/wiki/Probability_distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to a goal area.FIG. 12: is a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second type of 
<a href="https://en.wikipedia.org/wiki/Probability_distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to a goal area.FIG. 13: is a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 depicting defeating an 
<a href="https://en.wikipedia.org/wiki/Obstacle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    obstacle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (in this example a player wall).FIG. 14: is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart of a method of determining whether a goal criteria is met._____c:1. A method for determining whether a goal is achieved by a trajectory of a ball using a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, comprising:capturing a sequence of video frames of the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball with
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a camera of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device;
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the ball in at least three of the video frames;computing a trajectory of the ball using the detections of the ball;
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a goal 
<a href="https://en.wikipedia.org/wiki/Structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image in at least one of the video frames; andcomputing whether the trajectory of the ball achieves intersection or similar with a goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 computed from the goal 
<a href="https://en.wikipedia.org/wiki/Structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image according to a goal criterion.2. A method according to claim 1, wherein 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the goal image comprises determining the position of a goal in the at least one of the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.3. A method according to claim 1, wherein computing whether the trajectory of the ball achieves intersection or similar with the goal image comprises computing whether the curve fitted to the trajectory of the ball intersects with the 
<a href="https://en.wikipedia.org/wiki/INS"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ins
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
ide of the defined shape.4. A method according to claim 1, wherein the goal criterion comprises one or more of achieving a minimum speed of the ball, achieving placement of the ball in a particular position in the goal image, or achieving a particular 
<a href="https://en.wikipedia.org/wiki/Spin"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    spin
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the ball.5. A method according to claim 1, wherein the goal criterion comprises a difficulty input, wherein the goal criterion is defeating a virtual 
<a href="https://en.wikipedia.org/wiki/Obstacle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    obstacle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to score a goal, and the difficulty input is the difficulty of defeating the virtual obstacle, wherein the goal criterion determines whether the kick of the ball would be a goal or not according to the difficulty input.6. A method according to claim 1, wherein the goal criterion determines whether the kick of the ball would be a goal or not according to the difficulty input computed trajectory is a curved 3D 
<a href="https://en.wikipedia.org/wiki/Airway_(aviation)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flight path
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the ball.7. A method according to claim 1, wherein the goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is mapped to a 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. A method according to claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is determined by characteristics assigned to a virtual goalkeeper.9. A method according to claim 1, wherein the goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is mapped to a 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to 
<a href="https://en.wikipedia.org/wiki/Equation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    an equation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a curve derived from the characteristics of height and arm span of the goalkeeper.10. A method according to claim 1, wherein a 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is selected form the 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the placement of the ball.11. A method according to claim 1, wherein the selected 
<a href="https://en.wikipedia.org/wiki/Probability_density_function"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability density
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is modified according to characteristics of the kick.12. A method for determining a property of a trajectory of a ball with a 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, comprising:capturing a sequence of video frames of the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball with
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a camera of the 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device;finding candidates of the ball in at least three of the video frames;eliminating false 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detections of the ball, comprising fitting ball candidates to a 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which ball candidates not sufficiently representing the 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are eliminated as ball candidates;computing a property of the trajectory of the ball using travel of the ball through the 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. A method according to claim 12, wherein the eliminating step comprises eliminating outlier candidates of the ball, leaving remaining candidate balls to which the fitting occurs, and wherein eliminating outlier candidate balls comprises eliminating ball candidates that do not have an appropriate sequential change in the size of a circle fitted to the perimeter of the found ball candidates.14. (canceled)15. A method according to claim 12, wherein the curve is fitted to candidates of the ball for video frames in which the 
<a href="https://en.wikipedia.org/wiki/Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball is
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determined to be moving.16. A method according to claim 12, wherein the method further comprises identifying a reference object in the video frames.17. (canceled)18. A method according to claim 12, wherein finding ball candidates comprises calculating a 
<a href="https://en.wikipedia.org/wiki/Vector_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    gradient vector field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.19. A method according to claim 18, wherein the shape matching comprises checking that the gradient direction in the 
<a href="https://en.wikipedia.org/wiki/Gradient"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    gradient vector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 field is a smooth circle.20. A method according to claim 12, wherein the method further comprises computing whether the trajectory of the ball achieves intersection or similar with a goal 
<a href="https://en.wikipedia.org/wiki/Structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image in the video frames according to a goal criterion.21. A method according to claim 12, wherein the property computed comprises one or more of:The force with which the ball was kickedThe 
<a href="https://en.wikipedia.org/wiki/Spin"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    spin
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 asserted on the ball22. A 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device configured to perform the method of claim 12.23. (canceled)24. A 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device configured to determine a property of a trajectory of a ball, said 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device comprising:a camera for capturing a sequence of video frames of the ball;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to capture a sequence of video frames of the ball with the camera;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to detect the ball in at least three of the video frames;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to compute a trajectory of the ball using the detections of the ball;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to detect a goal image in at least one of the video frames;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to compute whether the trajectory of the ball achieves intersection or similar with a goal 
<a href="https://en.wikipedia.org/wiki/Plane"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 computed from the goal image according to a goal criterion.25. A 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device configured to determine whether a goal is achieved by a trajectory of a ball, said 
<a href="https://en.wikipedia.org/wiki/Mobile_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile computer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device comprising:a camera for capturing a sequence of video frames of the ball;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to find candidates of the ball in at least three of the video frames;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to eliminate false 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detections of the ball, comprising fitting ball candidates to a 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which ball candidates not sufficiently representing the 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are eliminated as ball candidates;a processor 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to compute a property of the trajectory of the ball using travel of the ball through the 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    curve trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.26. A method according to claim 1, wherein the position of the camera is spaced from the goals and the goals are in the 
<a href="https://en.wikipedia.org/wiki/Field_of_view"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    field of view
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the camera and wherein the position of the camera is such that the ball moves generally away from the camera._______________OBJECT EXTRACTION FROM VIDEO IMAGES SYSTEM AND METHOD_____20170713_____XMLs/xml/ipa170713.xml_____US-20170200281-A1 : US-15470477 : US-14525181 : US-9639954 : US-15470477_____G06T0007254000 : G06T0007215000 : G06K0009460000 : G06K0009000000 : G06T0007194000A computer implemented method of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method comprising steps a computer is programmed to perform, the steps comprising: receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and extracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences._____d:CROSS-REFERENCE TO RELATED APPLICATIONSThis application is a continuation of U.S. patent application Ser. No. 14/525,181, filed Oct. 27, 2014, which is hereby incorporated in its entirety including all tables, figures, and claims.FIELD AND BACKGROUND OF THE INVENTIONThe present invention relates to 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and, more particularly, but not exclusively to extracting 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured during a sport event.In recent years, the use of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 has been gaining more and more popularity in a variety of fields and industries. Some known 
<a href="https://en.wikipedia.org/wiki/Industrial"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    industrial
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 include, for example, security 
<a href="https://en.wikipedia.org/wiki/Surveillance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    surveillance systems
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, operational 
<a href="https://en.wikipedia.org/wiki/Management_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    management systems
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (say in a 
<a href="https://en.wikipedia.org/wiki/Retail"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    retail industry
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 environment), tactical battlefield systems, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.The 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is an aspect of 
<a href="https://en.wikipedia.org/wiki/Video_content_analysis"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video analysis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.One of the techniques widely used in the fields of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a technique in which an image's foreground is extracted for further processing, usually for recognition of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest.Generally, an image's foreground is made of regions of the image, which are occupied by 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest (humans, cars, text, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.). After a stage of image 
<a href="https://en.wikipedia.org/wiki/Preprocessing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    preprocessing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (which may include image noise removal, 
<a href="https://en.wikipedia.org/wiki/Morphology"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    morphology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based analysis, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.), object 
<a href="https://en.wikipedia.org/wiki/Localization"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    localization
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be required, which object 
<a href="https://en.wikipedia.org/wiki/Localization"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    localization
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may make use of background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is widely used for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (say cars or pedestrians) in videos, from static cameras, the rationale being one of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the difference between the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame and a reference 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, also referred to as “background image” or “background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
”, which is made of static 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 such as a building or a traffic 
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 positioned at a road intersection.Objection 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is often done if the image in question is a part of a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 provides important cues for numerous 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example surveillance tracking or 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 poses estimation.SUMMARY OF THE INVENTIONAccording to one aspect of the present invention there is provided a computer implemented method of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method comprising steps a computer is programmed to perform, the steps comprising: receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and extracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.According to a second aspect of the present invention there is provided an apparatus for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the apparatus comprising: a computer, a 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receiver, implemented on the computer, configured to receive a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 deriver, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receiver, configured to derive a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a difference calculator, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 deriver, configured to calculate a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual video image and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and an object extractor, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the difference calculator, configured to extract an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.According to a third aspect of the present invention there is provided a non-transitory 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium storing computer executable instructions for performing steps of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the steps comprising: receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and extracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.Unless otherwise defined, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs.The materials, 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and examples provided herein are illustrative only and not intended to be limiting. Implementation of the method and system of the present invention involves performing or completing certain selected tasks or steps manually, automatically, or a combination thereof.Moreover, according to actual instrumentation and equipment of preferred embodiments of the method and system of the present invention, several selected steps could be implemented by hardware or by software on any 
<a href="https://en.wikipedia.org/wiki/Operating_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    operating system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of any firmware or a combination thereof.For example, as hardware, selected steps of the invention could be implemented as a chip or a circuit. As software, selected steps of the invention could be implemented as a plurality of software instructions being executed by a computer using any suitable 
<a href="https://en.wikipedia.org/wiki/Operating_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    operating system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In any case, selected steps of the method and system of the invention could be described as being performed by a 
<a href="https://en.wikipedia.org/wiki/Data_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data processor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such as a 
<a href="https://en.wikipedia.org/wiki/Computing_platform"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing platform
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for executing a plurality of instructions.BRIEF DESCRIPTION OF THE DRAWINGSThe invention is herein described, by way of example only, with reference to the accompanying drawings. With specific reference now to the drawings in detail, it is stressed that the particulars shown are by way of example and for purposes of illustrative discussion of the preferred embodiments of the present invention only, and are presented in order to provide what is believed to be the most useful and readily understood description of the principles and conceptual aspects of the invention. The description taken with the drawings making apparent to those skilled in the art how the several forms of the invention may be embodied in practice.In the drawings:FIG. 1 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 schematically illustrating an exemplary apparatus for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIG. 2 is a simplified flowchart schematically illustrating a first exemplary method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIG. 3 is a simplified flowchart schematically illustrating a second exemplary method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIGS. 4A-4H are simplified 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagrams schematically illustrating a first implementation scenario, according to an exemplary embodiment of the present invention.FIG. 4A illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4B illustrates a player who stands in a right position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4C is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It does not include the image of a player.FIG. 4D is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in the 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 4E illustrates a player standing in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 4F illustrates a player who stands next to one or more trees and the sun coming out from behind a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4G is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4H illustrates a player who stands next to one or more trees, with the sun coming out from behind a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 5 is a simplified flowchart schematically illustrating a third exemplary method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIGS. 6A-6O are simplified 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagrams schematically illustrating a second implementation scenario, according to an exemplary embodiment of the present invention.FIG. 6A illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6B illustrates a player stands in a right position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6C illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6D is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It does not include the image of a player.FIG. 6E is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in the right position.FIG. 6F illustrates a player standing in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6G is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in the right position and a player in the 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6H illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6I illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and the sun.FIG. 6J illustrates a player who stands in a right position next to one or more trees and the sun.FIG. 6K is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It does not include the image of a player.FIG. 6L illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and the sun.FIG. 6M illustrates a player who stands in a right position next to one or more trees and the sun.FIG. 6N is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in a right position and a player in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6O shows a player standing in a right position.FIG. 7 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 schematically illustrating an exemplary 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium storing computer executable instructions for performing steps of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention._____c:1. A computer implemented method of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method comprising steps a computer is programmed to perform, the steps comprising:receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the background templates; andextracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.2. The method of claim 1, further comprising selecting the 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 rule among a plurality of predefined rules.3. The method of claim 1, further comprising allowing a user to select the 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 rule.4. The method of claim 1, further comprising selecting the 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 rule, according to circumstances of capturing of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The method of claim 1, further comprising selecting the 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 rule, according to a characteristic pertaining to the object of interest.7. The method of claim 1, further comprising selecting the 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 rule, according to a characteristic pertaining to a background of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. The method of claim 1, wherein said deriving of the background templates is based on a rule selected among a plurality of predefined rules.9. The method of claim 1, further comprising allowing a user to select a rule for said deriving of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein said deriving is based on the rule selected by the user.10. The method of claim 1, wherein said deriving of the background templates is based on a rule selected according to circumstances of capturing of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.11. The method of claim 1, wherein said deriving of the background templates is based on a rule selected according to a characteristic pertaining to the object of interest.12. The method of claim 1, wherein said deriving of the background templates is based on a rule selected according to a characteristic pertaining to a background of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The method of claim 1, further comprising deriving each one of at least two of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a respective and different one of a plurality of background 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.14. The method of claim 1, further comprising deriving each one of at least two of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a respective and at least partially different subset of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.15. The method of claim 1, further comprising deriving each one of at least two of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a respective and at least partially less recent subset of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. The method of claim 1, further comprising deriving each one of at least two of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a respective and different frequency of sampling of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.17. The method of claim 1, further comprising deriving each one of at least two of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a respective and different in size subset of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.18. The method of claim 1, further comprising updating each one of at least two of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, with a respective and different update rate.19. Apparatus for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the apparatus comprising:a computer;a 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receiver, implemented on the computer, configured to receive a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 deriver, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with said 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receiver, configured to derive a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;a difference calculator, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with said 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 deriver, configured to calculate a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the background templates; andan object extractor, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with said difference calculator, configured to extract an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.20. A non-transitory 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium storing computer executable instructions for performing steps of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the steps comprising:receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the background templates; andextracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences._______________IMAGE PROCESSING METHOD AND INFORMATION PROCESSING APPARATUS_____20190516_____XMLs/xml/ipa190516.xml_____US-20190147604-A1 : US-16166298 : JP-2017-218636_____G06T0007254000 : G06T0007292000An 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus includes a processor that detects positions of ball candidates from a plurality of 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time-series image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frames. The processor adds a position of a second ball candidate to a second image frame subsequent to a first image frame based on a position of a first ball candidate and movement definition information. The first ball candidate is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the first image frame. The movement definition information defines a characteristic of a movement of a ball. The processor generates a plurality of trajectory candidates by combining a plurality of ball candidates 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from image frames of different times. The processor evaluates the plurality of trajectory candidates to determine a 
<a href="https://en.wikipedia.org/wiki/Trajectory"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball trajectory
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The processor interpolates, when the ball trajectory is 
<a href="https://en.wikipedia.org/wiki/Interrupt"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interrupted
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, between a starting point and an ending point of the interruption with a trajectory of a first person who moves from the starting point to the ending point._____d:CROSS-REFERENCE TO RELATED APPLICATIONThis application is based upon and claims the benefit of priority of the prior Japanese Patent Application No. 2017-218636, filed on Nov. 13, 2017, the entire contents of which are incorporated herein by reference.FIELDThe embodiments discussed herein are related to an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method and an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus.BACKGROUNDThe information and 
<a href="https://en.wikipedia.org/wiki/Information_and_communications_technology"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication technology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (ICT) has recently been introduced in the field of sports. For example, there is a technique which captures 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Game"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    game
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and generates statistical information based on the captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The statistical information refers to information that combines 
<a href="https://en.wikipedia.org/wiki/Game"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    game
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 performances of a team or an individual player.Here, in order to generate the statistical information, the movements of a player and a ball are both used as input information. As for a technique of tracking the movement of a person, there is, for example, a technique which connects images of a person appearing on multiple cameras in sequence to generate tracking information, based on statistical information premising that the movement speed or direction of a person is somewhat constant. Further, there is a technique which 
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a person by using a template.In addition, as for a technique of tracking the movement of a ball, there is, for example, a technique which detects a ball by a difference image between a background image and an image including a ball and 
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the ball by using a vector related to the ball among 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Further, there is a technique which 
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a ball by 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the ball from a camera image through an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the premise that, for example, a reflecting material is used for the ball.Related technologies are disclosed in, for example, Japanese Laid-open Patent Publication No. 2016-099941, Japanese Laid-open Patent Publication No. 2004-046647, Japanese Laid-open Patent Publication No. 2009-143722, Japanese Laid-open Patent Publication No. 2004-096402, U. S. Patent Publication No. 2005/0254686, and Japanese Laid-open Patent Publication No. 2001-273500.SUMMARYAccording to an aspect of the present invention, provided is an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus including a memory and a processor coupled to the memory. The processor is configured to detect positions of ball candidates from a plurality of 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time-series image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frames. The processor is configured to add a position of a second ball candidate to a second image frame subsequent to a first image frame based on a position of a first ball candidate and movement definition information. The first and second image frames are included in the plurality of image frames. The first ball candidate is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the first image frame. The movement definition information defines a characteristic of a movement of a ball. The processor is configured to generate a plurality of trajectory candidates by combining a plurality of ball candidates 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from image frames of different times with each other. The processor is configured to evaluate the plurality of trajectory candidates to determine a ball trajectory. The processor is configured to interpolate, when the ball trajectory is 
<a href="https://en.wikipedia.org/wiki/Interrupt"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interrupted
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, between a starting point and an ending point of the interruption with a trajectory of a first person who moves from the starting point to the ending point.The object and advantages of the invention will be realized and attained by means of the elements and combinations particularly pointed out in the claims. It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are not restrictive of the invention, as claimed.BRIEF DESCRIPTION OF DRAWINGSFIG. 1 is a view illustrating an example of a system according to Embodiment 1 of the present disclosure;FIG. 2 is a view illustrating an example of image capturing ranges of cameras;FIG. 3 is a view illustrating a configuration of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to Embodiment 1;FIG. 4 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Buffer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to Embodiment 1;FIG. 5 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Lambda_calculus"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a conversion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table according to Embodiment 1;FIG. 6 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second conversion table;FIG. 7 is a view for describing a relationship between an image frame 
<a href="https://en.wikipedia.org/wiki/Coordinate_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    coordinate system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a global 
<a href="https://en.wikipedia.org/wiki/Coordinate_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    coordinate system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 8 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Alan_Ball_Jr."><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball management
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table according to Embodiment 1;FIG. 9 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a player 
<a href="https://en.wikipedia.org/wiki/Management"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    management
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table according to Embodiment 1;FIG. 10 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of movement definition information according to Embodiment 1;FIG. 11 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a trajectory candidate 
<a href="https://en.wikipedia.org/wiki/Management"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    management
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table according to Embodiment 1;FIG. 12 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a trajectory 
<a href="https://en.wikipedia.org/wiki/Management"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    management
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table according to Embodiment 1;FIG. 13 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of statistical information according to Embodiment 1;FIG. 14 is a view (part 1) for describing a process performed by a ball detection unit according to Embodiment 1;FIG. 15 is a view (part 2) for describing the process performed by the ball detection unit according to Embodiment 1;FIG. 16 is a view (part 3) for describing the process performed by the ball detection unit according to Embodiment 1;FIG. 17 is a view for describing a process performed by a generation unit according to Embodiment 1;FIG. 18 is a view (part 1) for describing a process performed by a trajectory determination unit according to Embodiment 1;FIG. 19 is a view (part 2) for describing the process performed by the trajectory determination unit according to Embodiment 1;FIG. 20 is a flowchart illustrating a procedure of processes performed by the 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to Embodiment 1;FIG. 21 is a view illustrating a configuration of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to Embodiment 2;FIG. 22 is a view for describing a process performed by a trajectory determination unit according to Embodiment 2;FIG. 23 is a view illustrating a configuration of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to Embodiment 3;FIG. 24 is a view for describing an example of a landmark;FIG. 25 is a view illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Data_structure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of landmark information;FIG. 26 is a view for describing a process performed by a trajectory determination unit according to Embodiment 3;FIG. 27 is a view illustrating a configuration of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to Embodiment 4;FIG. 28 is a view for describing a process performed by a trajectory determination unit according to Embodiment 4;FIG. 29 is a flowchart illustrating a procedure of processes performed by the 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to Embodiment 4; andFIG. 30 is a view illustrating an example of a hardware configuration._____c:1. A non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 having stored therein a program that causes a computer to execute a process, the process comprising:
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 positions of ball candidates from a plurality of 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time-series image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frames;adding a position of a second ball candidate to a second image frame subsequent to a first image frame based on a position of a first ball candidate and movement definition information, the first and second image frames being included in the plurality of image frames, the first ball candidate being 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the first image frame, the movement definition information defining a characteristic of a movement of a ball;generating a plurality of trajectory candidates by combining a plurality of ball candidates 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from image frames of different times with each other;evaluating the plurality of trajectory candidates to determine a ball trajectory; andinterpolating, when the ball trajectory is 
<a href="https://en.wikipedia.org/wiki/Interrupt"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interrupted
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, between a starting point and an ending point of the interruption with a trajectory of a first person who moves from the starting point to the ending point.2. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, the process further comprising:estimating the position of the second 
<a href="https://en.wikipedia.org/wiki/Krystal_Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball candidate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the position of the first ball candidate and the movement definition information; andadding the estimated position of the second ball candidate to the second image frame when no ball candidate is present in a predetermined range defined based on the estimated position of the second 
<a href="https://en.wikipedia.org/wiki/Krystal_Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball candidate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.3. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 2, the process further comprising:assigning lost information to a third ball candidate on the second frame image, the third ball candidate not being included in the predetermined range; anddetermining the ball trajectory based on the lost information included in the trajectory candidates.4. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 3, the process further comprising:counting a number of ball candidates assigned with the lost information with respect to each of the plurality of trajectory candidates; anddetermining the ball trajectory from trajectory candidates having the counted number less than a predetermined 
<a href="https://en.wikipedia.org/wiki/Threshold_limit_value"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    threshold value
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, the process further comprising:comparing the determined ball trajectory and the plurality of trajectory candidates with each other to generate a new trajectory by connecting the determined ball trajectory and one of the plurality of trajectory candidates to each other.6. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, the process further comprising:evaluating, to determine the ball trajectory, the plurality of trajectory candidates by further using positional information of a landmark on a field where the first person plays a 
<a href="https://en.wikipedia.org/wiki/Game"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    game
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.7. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, the process further comprising:extending the ball trajectory when a second trajectory of a second person is present between a starting point of the ball trajectory and an ending point of one of the plurality of trajectory candidates, by connecting the ball trajectory with the second trajectory and the one of the plurality of trajectory candidates.8. The non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to claim 1, the process further comprising:calculating a distance of a ball dribbled by the first person or a number of times that the first player passes the ball based on the ball trajectory and the trajectory of the first person.9. An 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus comprising:a memory; anda processor coupled to the memory and the processor configured to:detect positions of ball candidates from a plurality of 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time-series image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frames;add a position of a second ball candidate to a second image frame subsequent to a first image frame based on a position of a first ball candidate and movement definition information, the first and second image frames being included in the plurality of image frames, the first ball candidate being 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the first image frame, the movement definition information defining a characteristic of a movement of a ball;generate a plurality of trajectory candidates by combining a plurality of ball candidates 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from image frames of different times with each other;evaluate the plurality of trajectory candidates to determine a ball trajectory; andinterpolate, when the ball trajectory is 
<a href="https://en.wikipedia.org/wiki/Interrupt"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interrupted
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, between a starting point and an ending point of the interruption with a trajectory of a first person who moves from the starting point to the ending point.10. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 9, wherein the processor is further configured to:estimate the position of the second 
<a href="https://en.wikipedia.org/wiki/Krystal_Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball candidate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the position of the first ball candidate and the movement definition information; andadd the estimated position of the second ball candidate to the second image frame when no ball candidate is present in a predetermined range defined based on the estimated position of the second 
<a href="https://en.wikipedia.org/wiki/Krystal_Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball candidate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.11. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 10, wherein the processor is further configured to:assign lost information to a third ball candidate on the second frame image, the third ball candidate not being included in the predetermined range; anddetermine the ball trajectory based on the lost information included in the trajectory candidates.12. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 11, wherein the processor is further configured to:count a number of ball candidates assigned with the lost information with respect to each of the plurality of trajectory candidates; anddetermine the ball trajectory from trajectory candidates having the counted number less than a predetermined 
<a href="https://en.wikipedia.org/wiki/Threshold_limit_value"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    threshold value
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 9, wherein the processor is further configured to:compare the determined ball trajectory and the plurality of trajectory candidates with each other to generate a new trajectory by connecting the determined ball trajectory and one of the plurality of trajectory candidates to each other.14. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 9, wherein the processor is further configured to:evaluate, to determine the ball trajectory, the plurality of trajectory candidates by further using positional information of a landmark on a field where the first person plays a 
<a href="https://en.wikipedia.org/wiki/Game"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    game
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.15. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 9, wherein the processor is further configured to:extend the ball trajectory when a second trajectory of a second person is present between a starting point of the ball trajectory and an ending point of one of the plurality of trajectory candidates, by connecting the ball trajectory with the second trajectory and the one of the plurality of trajectory candidates.16. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 9, wherein the processor is further configured to:calculate a distance of a ball dribbled by the first person or a number of times that the first player passes the ball based on the ball trajectory and the trajectory of the first person.17. An 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method comprising:
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, by a computer, positions of ball candidates from a plurality of 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time-series image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frames;adding a position of a second ball candidate to a second image frame subsequent to a first image frame based on a position of a first ball candidate and movement definition information, the first and second image frames being included in the plurality of image frames, the first ball candidate being 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the first image frame, the movement definition information defining a characteristic of a movement of a ball;generating a plurality of trajectory candidates by combining a plurality of ball candidates 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from image frames of different times with each other;evaluating the plurality of trajectory candidates to determine a ball trajectory; andinterpolating, when the ball trajectory is 
<a href="https://en.wikipedia.org/wiki/Interrupt"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interrupted
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, between a starting point and an ending point of the interruption with a trajectory of a first person who moves from the starting point to the ending point.18. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method according to claim 17, further comprising:estimating the position of the second 
<a href="https://en.wikipedia.org/wiki/Krystal_Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball candidate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the position of the first ball candidate and the movement definition information; andadding the estimated position of the second ball candidate to the second image frame when no ball candidate is present in a predetermined range defined based on the estimated position of the second 
<a href="https://en.wikipedia.org/wiki/Krystal_Ball"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ball candidate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.19. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method according to claim 18, further comprising:assigning lost information to a third ball candidate on the second frame image, the third ball candidate not being included in the predetermined range; anddetermining the ball trajectory based on the lost information included in the trajectory candidates.20. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method according to claim 19, further comprising:counting a number of ball candidates assigned with the lost information with respect to each of the plurality of trajectory candidates; anddetermining the ball trajectory from trajectory candidates having the counted number less than a predetermined 
<a href="https://en.wikipedia.org/wiki/Threshold_limit_value"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    threshold value
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._______________REAL-TIME DETECTON OF PERIODIC MOTION SYSTEMS AND METHODS_____20191128_____XMLs/xml/ipa191128.xml_____US-20190362507-A1 : US-16538680 : US-PCT/US2018/019543 : US-16538680 : US-62463273_____G06T0007254000 : G06T0005200000 : G06F0017180000Provided are systems and 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 periodic movement in a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. A system includes an imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to capture video of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communicate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The logic device is configured to receive a video sequence of the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where the received video sequence comprises one or more video regions that are pixel-wise consistent between successive frames of the received video sequence. The 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to determine a periodicity deviation with respect to at least one of the one or more video regions based, at least in part, on the at least one video region. The 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Concealed_carry_in_the_United_States"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    may issue
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an alert 
<a href="https://en.wikipedia.org/wiki/Base"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    base
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
d, at least in part, on the determined periodicity deviation._____d:CROSS REFERENCE TO RELATED APPLICATIONSThis application is a continuation of International Patent Application No. PCT/US2018/019543 filed Feb. 24, 2018 and entitled “REAL TIME DETECTION OF PERIODIC MOTION SYSTEMS AND METHOD,” which is incorporated herein by reference in its entirety.International Patent Application No. PCT/US2018/019543 filed Feb. 24, 2018 claims priority to and the benefit of U.S. Provisional Patent Application. No. 62/463,273 filed Feb. 24, 2017 and entitled “REAL-TIME DETECTION OF PERIODIC MOTION SYSTEMS AND METHODS,” which is hereby incorporated by reference in its entirety.TECHNICAL FIELDOne or more embodiments of the invention relate generally to detection of movement, and more particularly, for example, to 
<a href="https://en.wikipedia.org/wiki/Real-time_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    near real-time detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of periodic movement in a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.BACKGROUNDVideo surveillance has made considerable advancements over the past few decades as the proliferation of 
<a href="https://en.wikipedia.org/wiki/Digital"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    digital
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 cameras and the 
<a href="https://en.wikipedia.org/wiki/Internet_of_things"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    internet of things
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have evolved. A majority of businesses are now monitored by security cameras, and people are increasingly installing cameras in and around their homes to 
<a href="https://en.wikipedia.org/wiki/Monitor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    monitor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 their property and 
<a href="https://en.wikipedia.org/wiki/Family"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    family
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. A majority of these systems go unmonitored in 
<a href="https://en.wikipedia.org/wiki/Real-time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    real time
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and are primarily used to investigate after-the-fact observed aberrations in a user's daily routine. This process is time intensive and exceedingly inefficient.In more recent years, 
<a href="https://en.wikipedia.org/wiki/Closed-circuit_television"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video surveillance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 systems have implemented various forms of 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 recording and alerts so that the 
<a href="https://en.wikipedia.org/wiki/Review"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    review
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process time is more focused and efficient. Integrating 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 has allowed alerts to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and sent to users when the system detects movement captured by one of the cameras in a 
<a href="https://en.wikipedia.org/wiki/Surveillance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    surveillance system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. However, contemporary alert detection systems suffer from many problems.Of 
<a href="https://en.wikipedia.org/wiki/Primary"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    primary
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 concern, by 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and triggering an alert based on arbitrary movement in the image capture region, many false alarms are reported. For example, a tree blowing in the 
<a href="https://en.wikipedia.org/wiki/Wind"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    wind
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image capture region could repeatedly trigger an unwanted alert. After a few too many false alarms, a user may decide to terminate the 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 feature or simply ignore the repeated alerts. Some systems have sought to remedy this problem by allowing a user to select portions of the camera's viewing area and only triggering an alert when 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in those user selected 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detection 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, but the user risks not being alerted to potentially triggering events that are outside those designated 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Moreover, the same false alert problems exist within each selected 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; namely that any arbitrary movement will trigger an alert. Other 
<a href="https://en.wikipedia.org/wiki/Organic_farming"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    conventional methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of preventing false alerts include requiring 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 over a period of time or providing a black out period after an alert, but both of these 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 risk missing important triggering events. Thus, conventional 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 systems remain highly prone to false alerts (and users deactivating or ignoring alerts due to the relatively poor alert reliability) and false negative alerts.Accordingly, 
<a href="https://en.wikipedia.org/wiki/Existential_quantification"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    there exists
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a need in the art for a reliable and 
<a href="https://en.wikipedia.org/wiki/Real-time_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    near real-time detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Methodology"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methodology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that can reduce risk of false detections and false negative detections in a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.SUMMARYProvided is a 
<a href="https://en.wikipedia.org/wiki/Methodology"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methodology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 periodic movement in a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Embodiments provide for an efficient, adaptive method of evaluating periodic movement that can be performed in 
<a href="https://en.wikipedia.org/wiki/Real-time_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    near real-time
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and that can generate corresponding alerts for 
<a href="https://en.wikipedia.org/wiki/Distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to one or more monitoring users or for further processing. Embodiments provide reliable detection of and differentiation between different types of periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such as detection of a 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 waving their hands or arms to signal for help, as differentiated from a pets wagging 
<a href="https://en.wikipedia.org/wiki/Tail"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tail
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, as described in detail herein.In one embodiment, a system includes an imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to capture video of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communicate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be configured to receive a video sequence of the scene from the imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where the received video sequence comprises one or more video regions that are pixel-wise consistent between successive frames of the received video sequence; determine a periodicity deviation with respect to at least one of the one or more video regions based, at least in part, on the at least one video region; and issue an alert based, at least in part, on the determined periodicity deviation.In another embodiment, a method includes receiving a video sequence of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from an imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where the received video sequence comprises one or more video regions that are pixel-wise consistent between successive frames of the received video sequence; determining a periodicity deviation with respect to at least one of the one or more video regions based, at least in part, on the at least one video region; and issuing an alert based, at least in part, on the determined periodicity deviation.Embodiments of the invention and their advantages are best understood by referring to the detailed description that follows. It should be appreciated that like reference numerals are used to identify like elements illustrated in one or more of the figures.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an 
<a href="https://en.wikipedia.org/wiki/Imaging"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    imaging system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to detect periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment of the disclosure.FIG. 2 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a controller configured to perform periodic 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment of the disclosure.FIG. 3 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Preprocessing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    preprocessing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to facilitate periodic 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment of the disclosure.FIG. 4 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a periodic 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to determine periodicity deviations in a video sequence, in accordance with an embodiment of the disclosure.FIG. 5 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an alert 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to issue an alert based on a periodicity deviation in a video sequence, in accordance with an embodiment of the disclosure.FIG. 6 illustrates a comparison of a first video sequence including a global temporal trend against a second video sequence with the global temporal trend removed by de-trending, in accordance with an embodiment of the disclosure.FIG. 7 illustrates fifty consecutive frames of an infrared 
<a href="https://en.wikipedia.org/wiki/Video_editing_software"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video sequence
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 arranged in frame series that portray a person waving both arms as a form of periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment of the disclosure.FIG. 8 illustrates a 
<a href="https://en.wikipedia.org/wiki/Flow_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a process to provide periodic 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment of the disclosure.FIG. 9 illustrates a 
<a href="https://en.wikipedia.org/wiki/Flow_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a process to provide periodic 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment of the disclosure._____c:1. A system comprising:an imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to capture video of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anda 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communicate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to:receive a video sequence of the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the received video sequence comprises one or more video regions that are pixel-wise consistent between successive frames of the received video sequence;determine at least one periodicity deviation corresponding to at least one of the one or more video regions based, at least in part, on the at least one video region; andissue an alert based, at least in part, on the determined at least one periodicity deviation.2. The system of claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to:determine a spatial average of the received video sequence; andde-trend the received video sequence by subtracting the determined spatial average from each frame of the received video sequence, prior to the determining the periodicity deviation.3. The system of claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to:apply a low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to the received video sequence, prior to the determining the periodicity deviation.4. The system of claim 3, wherein:the low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises a linear low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andthe linear low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is implemented by a separable two dimensional Bernoulli filter.5. The system of claim 1, wherein:the one or more video regions comprise a plurality of rectangular video regions;each rectangular video region at least partially overlaps at least one other rectangular video region; andeach rectangular video region comprises a height or width between 5 pixels and one half a corresponding full height or width of a frame of the received video sequence.6. The system of claim 1, wherein:the one or more video regions comprise a plurality of overlapping rectangular video regions; andthe plurality of overlapping rectangular video regions comprises a corresponding plurality of positions and/or sizes configured to completely cover each frame of the received video sequence.7. The system of claim 1, wherein:the determining the periodicity deviation comprises determining a discretized, grey level translation invariant, normalized periodicity deviation corresponding to the at least one video region based, at least in part, on the at least one video region and an identified period; andthe temporal length of the received video sequence is at least twice the identified period.8. The system of claim 1, wherein the one or more video regions comprise a plurality of video regions, the at least one periodicity deviation comprises a plurality of periodicity deviations corresponding respectively to the plurality of video regions, and the 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to:determine the plurality of periodicity deviations corresponding respectively to the plurality of video regions based, at least in part, on the corresponding respective video regions and one or more identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or an identified range of 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andissue the alert based, at least in part, on the determined plurality of periodicity deviations, the one or more identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or the identified range of 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a periodicity deviation threshold.9. The system of claim 1, wherein the at least one periodicity deviation comprises first and second periodicity deviations corresponding respectively to first and second identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with a biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and wherein the 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to:determine the first periodicity deviation corresponding to the first identified period is greater than or equal to a periodicity deviation threshold corresponding to the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determine a first 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the first identified period and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is greater than a 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 threshold associated with the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determine the second periodicity deviation corresponding to the second identified period is less than the periodicity deviation threshold corresponding to the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andissue the alert based, at least in part, on the second periodicity deviation, to indicate a presence of the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the video sequence.10. The system of claim 9, wherein:the 
<a href="https://en.wikipedia.org/wiki/Programmable_logic_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    logic device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is configured to update a 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table associated with a set of identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;the set of identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises the first and second identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table comprises at least the first 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the first identified period and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the second identified period and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andthe updating the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table comprises increasing the second 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and decreasing at least the first 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table.11. A method comprising:receiving a video sequence of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from an imaging 
<a href="https://en.wikipedia.org/wiki/Module"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    module
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the received video sequence comprises one or more video regions that are pixel-wise consistent between successive frames of the received video sequence;determining a periodicity deviation with respect to at least one of the one or more video regions based, at least in part, on the at least one video region; andissuing an alert based, at least in part, on the determined periodicity deviation.12. The method of claim 11, further comprising:determining a spatial average of the received video sequence; andde-trending the received video sequence by subtracting the determined spatial average from each frame of the received video sequence, prior to the determining the periodicity deviation.13. The method of claim 11, further comprising:applying a low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to the received video sequence, prior to the determining the periodicity deviation.14. The method of claim 13, wherein:the low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises a linear low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andthe linear low 
<a href="https://en.wikipedia.org/wiki/Band-pass_filter"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pass filter
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is implemented by a separable two dimensional Bernoulli filter.15. The method of claim 11, wherein:the one or more video regions comprise a plurality of rectangular video regions;each rectangular video region at least partially overlaps at least one other rectangular video region; andeach rectangular video region comprises a height or width between 5 pixels and one half a corresponding full height or width of a frame of the received video sequence.16. The method of claim 11, wherein:the one or more video regions comprise a plurality of rectangular video regions; andthe plurality of rectangular video regions comprises a corresponding plurality of positions and/or sizes configured to completely cover each frame of the received video sequence.17. The method of claim 11, wherein:the determining the periodicity deviation comprises determining a discretized, translation invariant, normalized periodicity deviation corresponding to the at least one video region based, at least in part, on the at least one video region and an identified period; andthe temporal length of the received video sequence is at least twice the identified period.18. The method of claim 11, wherein the one or more video regions comprise a plurality of video regions and the at least one periodicity deviation comprises a plurality of periodicity deviations corresponding respectively to the plurality of video regions, the method further comprising:determining the plurality of periodicity deviations corresponding respectively to the plurality of video regions based, at least in part, on the corresponding respective video regions and one or more identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or an identified range of 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andissuing the alert based, at least in part, on the determined plurality of periodicity deviations, the one or more identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or the identified range of 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a periodicity deviation threshold.19. The method of claim 11, wherein the at least one periodicity deviation comprises first and second periodicity deviations corresponding to respective first and second identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with a biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method further comprising:determining the first periodicity deviation corresponding to the first identified period is greater than or equal to a periodicity deviation threshold corresponding to the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determining a first 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the first identified period and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is greater than a 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 threshold associated with the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determining the second periodicity deviation corresponding to the second identified period is less than the periodicity deviation threshold corresponding to the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andissuing the alert based, at least in part, on the second periodicity deviation, to indicate a presence of the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the video sequence.20. The method of claim 19, wherein:the method comprises updating a 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table associated with a set of identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;the set of identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises at least the first and second identified 
<a href="https://en.wikipedia.org/wiki/Period"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    periods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table comprises at least the first 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the first identified period and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 associated with the second identified period and the biological periodic 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andthe updating the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table comprises increasing the second 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and decreasing at least the first 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 table._______________A BUILDING MANAGEMENT SYSTEM USING OBJECT DETECTION AND TRACKING IN A LARGE SPACE WITH A LOW RESOLUTION SENSOR_____20190124_____XMLs/xml/ipa190124.xml_____US-20190026908-A1 : US-16070945 : US-62280942 : WO-PCT/US2017/014016-00_____G06T0007254000 : G06T0007277000A method of operating an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes the step of estimating (202) a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 background of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated by a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on a previous frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by a computer-based processor. The method further includes estimating (204) a foreground of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by comparing the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 background, and 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (212) an object using a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific object 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:BACKGROUNDThe present disclosure relates to building 
<a href="https://en.wikipedia.org/wiki/Management_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    management systems
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and more particularly, to 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and tracking in a large area using a 
<a href="https://en.wikipedia.org/wiki/Image_resolution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    low resolution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Infrared detectors used for intrusion and presence detection are typically limited to pixel counts of about four-by-four (4×4) elements to stay reasonable in terms of 
<a href="https://en.wikipedia.org/wiki/Cost"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cost
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Even with advances in MEMS, the pixel counts remain less than approximately one hundred-by-one hundred (100×100). The manufacturing process for these low 
<a href="https://en.wikipedia.org/wiki/Cost"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cost
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detectors does not scale well in terms of 
<a href="https://en.wikipedia.org/wiki/Cost"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cost
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as 
<a href="https://en.wikipedia.org/wiki/Image_resolution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pixel count
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 increases. Additionally, the physical size of an infrared 
<a href="https://en.wikipedia.org/wiki/Focal_seizure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    focal plan
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
e array is large compared to the same 
<a href="https://en.wikipedia.org/wiki/Image_resolution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pixel count
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for, as one example, 
<a href="https://en.wikipedia.org/wiki/CMOS"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complementary metal oxide
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 silicon (CMOS) visible 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 because of the longer wavelength. As such, one-by-one (1×1) to four-by-four (4×4) pyroelectric elements are commonplace as, for example, occupancy detectors, but even in sizes up to approximately one hundred-by-one hundred (100×100) they are not able to count with the fidelity needed to achieve more efficiently controlled 
<a href="https://en.wikipedia.org/wiki/Central_heating"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    heating
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, ventilation, and air conditioning (HVAC) systems and lighting. Yet further, energy consumption of infrared 
<a href="https://en.wikipedia.org/wiki/Cardinal_point_(optics)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    focal plane
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 arrays becomes larger than desired for arrays having sufficient pixels to meet fidelity needs when supporting other systems such as HVAC and lighting.Typical state-of-the-art presence detection may use a 
<a href="https://en.wikipedia.org/wiki/Electrical_element"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    two-element passive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 infrared (PR) 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. These 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 typically include 
<a href="https://en.wikipedia.org/wiki/Lens"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    faceted lens
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 designs and may include masks and variable detection thresholds to achieve useable 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Unfortunately, such PIR 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may have difficulty in distinguishing people from other heat sources (e.g., 
<a href="https://en.wikipedia.org/wiki/Animal"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    animals
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, HVAC operation, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.), may not be able to localize or track the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object, and may not be able to count the number of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Typical state-of-the-art algorithms for people detection, classification, tracking and counting have been developed in the field of 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. For instance, there are state-of-the-art object detection algorithms for people detection and tracking including Support Vector Machines (
<a href="https://en.wikipedia.org/wiki/Support-vector_machine"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    SVM
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
) on Histogram of Oriented Gradient (HOG) 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and discriminatively trained Deformable Part Models (DPM). Unfortunately, these algorithms are designed to work on visible spectrum, multi-color video with many hundreds or thousands of pixels on target. It is desirable to design 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 systems and associated algorithms for infrared video and/or video with relatively few pixels on target (i.e., tens to a few hundreds of pixels). It is further desirable to develop 
<a href="https://en.wikipedia.org/wiki/Cost"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cost
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 effective 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 systems and 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that perform occupancy detection and people counting with improved fidelity and reduced energy consumption to, for example, support HVAC and lighting systems.SUMMARYA method of operating an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to one, non-limiting, embodiment of the present disclosure includes estimating a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 background of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated by a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and based on a previous frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by a computer-based processor; estimating a foreground of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by comparing the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 background; and 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an object using a sensor-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Additionally to the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is an absolute 
<a href="https://en.wikipedia.org/wiki/Image_noise"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    intensity sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 utilizing a chopper.In the alternative or additionally thereto, in the foregoing embodiment, the method includes tracking the object via a 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and wherein the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In the alternative or additionally thereto, in the foregoing embodiment, the chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Gaussian Mixture 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In the alternative or additionally thereto, in the foregoing embodiment, the chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is 
<a href="https://en.wikipedia.org/wiki/Macro_(computer_science)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameterized
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at least in-part by perspective 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In the alternative or additionally thereto, in the foregoing embodiment, the chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is learned by discriminative 
<a href="https://en.wikipedia.org/wiki/Sparse_dictionary_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    dictionary learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In the alternative or additionally thereto, in the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Kalman Filter.In the alternative or additionally thereto, in the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Particle Filter.In the alternative or additionally thereto, in the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a 
<a href="https://en.wikipedia.org/wiki/Relative_intensity_noise"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    relative intensity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that does not utilize a chopper.In the alternative or additionally thereto, in the foregoing embodiment, the method includes tracking the object utilizing a 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and wherein the object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 via a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a ghost filter to compensate for characteristics of un-chopped imagery.In the alternative or additionally thereto, in the foregoing embodiment, the ghost filter is an 
<a href="https://en.wikipedia.org/wiki/Boeing_RC-135"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    iterative joint
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation process.In the alternative or additionally thereto, in the foregoing embodiment, the ghost filter is a space adaptive shape suppression process.In the alternative or additionally thereto, in the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Kalman Filter.In the alternative or additionally thereto, in the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Particle Filter.In the alternative or additionally thereto, in the foregoing embodiment, the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 utilizes a designed basis.In the alternative or additionally thereto, in the foregoing embodiment, the designed basis comprises one of a Harr basis and a Gabor basis.In the alternative or additionally thereto, in the foregoing embodiment, the designed basis is over-complete.The foregoing 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and elements may be combined in various combinations without exclusivity, unless expressly indicated otherwise. These 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and elements as well as the operation thereof will become more apparent in 
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the following description and the accompanying drawings. However, it should be understood that the following description and drawings are intended to be exemplary in nature and non-limiting.BRIEF DESCRIPTION OF THE DRAWINGSVarious 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 will become apparent to those skilled in the art from the following detailed description of the disclosed non-limiting embodiments. The drawings that accompany the detailed description can be briefly described as follows:FIG. 1 is a schematic of a 
<a href="https://en.wikipedia.org/wiki/Building_management_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    building management system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 utilizing an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and tracking (ODT) system of the present disclosure;FIG. 2 is a schematic of one embodiment of the 
<a href="https://en.wikipedia.org/wiki/Building_management_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    building management system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 having an ambient 
<a href="https://en.wikipedia.org/wiki/Temperature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    air temperature
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Control_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    control system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 utilizing the ODT system;FIG. 3 is a schematic of the ODT system;FIG. 4 is a 
<a href="https://en.wikipedia.org/wiki/Multiview_orthographic_projection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    plan view
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Focal_seizure"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    focal plan
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array of a remote unit of the ODT system;FIG. 5 is a perspective view 
<a href="https://en.wikipedia.org/wiki/Component"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    of components
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the remote unit integrated into a common 
<a href="https://en.wikipedia.org/wiki/Substrate_integrated_waveguide"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    substrate platform
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 6 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart of a method of operating a first embodiment of the ODT system utilizing an absolute intensity (chopped) array 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andFIG. 7 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart of a method of operating a second embodiment of the ODT system utilizing a 
<a href="https://en.wikipedia.org/wiki/Relative_intensity_noise"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    relative intensity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (un-chopped) array 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 8 is a diagram of a rotating wheel chopper 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which provides an absolute intensity image.FIG. 9 is a diagram of imagery from an un-chopped 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 depicting one possible spurious artefact._____c:1. A method of operating an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprising:estimating a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 background of a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated by a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and based on a previous frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by a computer-based processor;estimating a foreground of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by comparing the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame of 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 background; and
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an object using a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. The method set forth in claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is an absolute 
<a href="https://en.wikipedia.org/wiki/Image_noise"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    intensity sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 utilizing a chopper.3. The method set forth in claim 2 further comprising:tracking the object via a 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and wherein the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.4. The method set forth in claim 3, wherein the chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Gaussian Mixture 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The method set forth in claim 3, wherein the chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is 
<a href="https://en.wikipedia.org/wiki/Macro_(computer_science)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parameterized
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at least in-part by perspective 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The method set forth in claim 3, wherein the chopped-
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is learned by discriminative 
<a href="https://en.wikipedia.org/wiki/Sparse_dictionary_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    dictionary learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.7. The method set forth in claim 3, wherein the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Kalman Filter.8. The method set forth in claim 3, wherein the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Particle Filter.9. The method set forth in claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a 
<a href="https://en.wikipedia.org/wiki/Relative_intensity_noise"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    relative intensity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that does not utilize a chopper.10. The method set forth in claim 9 further comprising:tracking the object utilizing a 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and wherein the object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 via a 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a ghost filter to compensate for characteristics of un-chopped imagery.11. The method set forth in claim 10, wherein the ghost filter is an 
<a href="https://en.wikipedia.org/wiki/Boeing_RC-135"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    iterative joint
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation process.12. The method set forth in claim 10, wherein the ghost filter is a space adaptive shape suppression process.13. The method set forth in claim 10, wherein the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Kalman Filter.14. The method set forth in claim 10, wherein the 
<a href="https://en.wikipedia.org/wiki/Bayes_estimator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Bayesian Estimator
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a Particle Filter.15. The method set forth in claim 9, wherein the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-specific 
<a href="https://en.wikipedia.org/wiki/Object_model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 utilizes a designed basis.16. The method set forth in claim 13, wherein the designed basis comprises one of a Harr basis and a Gabor basis.17. The method set forth in claim 16, wherein the designed basis is over-complete._______________DETECTING MOTION DRAGGING ARTIFACTS 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 DYNAMIC ADJUSTMENT OF FRAME RATE CONVERSION SETTINGS_____20190613_____XMLs/xml/ipa190613.xml_____US-20190180454-A1 : US-16214632 : US-62597326_____G06T0007254000 : G06T0007110000 : G06T0007194000 : G06T0007400000 : G06T0007130000 : G06T0007155000Motion characteristics related to foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and background regions bordering the foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are determined. A frame rate conversion (FRC)-related metadata portion is generated based on the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics. The FRC-related metadata portion is to be used for determining an optimal FRC operational mode with a downstream device for the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are encoded into a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The FRC-related metadata portion is encoded into the video stream as a part of image metadata. The 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is caused to be transmitted to the downstream device._____d:CROSS REFERENCE TO RELATED APPLICATIONSThis application claims priority to U.S. Provisional Patent Application No. 62/597,326, filed on Dec. 11, 2017, the entire contents of which are hereby incorporated by reference.TECHNOLOGYThe present invention relates generally to 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. More particularly, an embodiment of the present invention relates to 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging artifacts for dynamic adjustment of frame rate conversion settings.BACKGROUNDImage interpolation, which computes a set of plausible interpolated 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using two or more adjacent 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, has varied 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including but not limited to frame rate conversion (FRC) between different broadcast standards, synthesis of virtual views, animating still 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and so on.Some TV manufacturing companies incorporate built-in 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 interpolation technology in their products to perform FRC. A mechanism for FRC can be as 
<a href="https://en.wikipedia.org/wiki/Simple"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    simple
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as merely replicating received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to achieve the desired 
<a href="https://en.wikipedia.org/wiki/Frame_rate"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    frame rate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. For example, a TV running at an image 
<a href="https://en.wikipedia.org/wiki/Refresh_rate"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    refresh rate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 120 Hz and receiving a 30 Hz image sequence may simply display each image four consecutive times. The advantage of this solution is that the complexity of the system is very low, at the expense of possibly resulting in 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 judder.Complicated systems can be designed for 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 interpolation. However, computational costs of such techniques can be quite high, and may even result in 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging artifacts, noticeable lags, and so forth, in viewing image sequences involving motions.The approaches described in this section are approaches that could be pursued, but not necessarily approaches that have been previously conceived or pursued. Therefore, unless otherwise indicated, it should not be assumed that any of the approaches described in this section qualify as 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 merely by virtue of their inclusion in this section. Similarly, issues identified with respect to one or more approaches should not assume to have been recognized in any 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the basis of this section, unless otherwise indicated.BRIEF DESCRIPTION OF DRAWINGSThe present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:FIG. 1 illustrates an example process 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that can be used to detect foreground and background 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in media content;FIG. 2A and FIG. 2B illustrate example process flows that can be used to determine whether 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging artifacts are likely to be generated in a set of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 3A through FIG. 3C illustrate example video encoders and clients;FIG. 4A and FIG. 4B illustrate example process flows; andFIG. 5 illustrates an example 
<a href="https://en.wikipedia.org/wiki/Computing_platform"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hardware platform
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on which a computer or a 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as described herein may be implemented._____c:1. A method, comprising:determining one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics related to one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and one or more background regions bordering the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;generating, based at least in part on the one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics related to the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the one or more background regions bordering the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a frame rate conversion (FRC)-related metadata portion, wherein the FRC-related metadata portion is to be used for determining an optimal FRC operational mode with a downstream device for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;
<a href="https://en.wikipedia.org/wiki/Code"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    encoding
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 into a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the FRC-related metadata portion is encoded into the 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as a part of image metadata;causing the 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be transmitted to the downstream device.2. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics are computed after the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the one or more background regions are separated in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using one or more optical-
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image analysis 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.3. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics are computed after the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the one or more background regions are separated in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using one or more non-optical-flow 
<a href="https://en.wikipedia.org/wiki/Image_analysis"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image analysis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.4. The method of claim 3, wherein the one or more optical-
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Image_analysis"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image analysis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprise one or more of: operations generating one or more optical flows based on image content visually depicted in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, operations generating and completing edges between the foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background regions from one or more optical flows, operations flood filling closed edges of the foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, operations generating one or more binary masks deli
<a href="https://en.wikipedia.org/wiki/Neat"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neating
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the background regions, morphological operations performed on edges 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from one or more optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, or morphological operations performed on one or more binary masks directly or indirectly derived from one or more optical flows.5. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics include one or more of: pixel-based 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector magnitudes, pixel-
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector magnitudes, 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector magnitudes, pixel-based 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector directions, pixel-
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector directions, or 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector directions.6. The method of claim 1, wherein the FRC-related metadata portion is generated further based at least in part on texture information determined for the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the one or more background regions.7. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 belong to a set of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that represent a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and wherein the optimal FRC operational mode applies to all 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the set of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that represent the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. The method of claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is encoded with an image sequence representing a first 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time sequence
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that include the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; wherein the first 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time sequence
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 supports a first image refresh rate in normal playing of the 
<a href="https://en.wikipedia.org/wiki/Time_series"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time sequence
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; wherein the downstream device supports a second different image 
<a href="https://en.wikipedia.org/wiki/Refresh_rate"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    refresh rate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in normal playing; and wherein the downstream device is to operate the optimal FRC operational mode to generate, based on the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 decoded from the 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, additional 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for complying with the second image 
<a href="https://en.wikipedia.org/wiki/Refresh_rate"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    refresh rate
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.9. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprise a plurality of spatial regions; wherein the plurality of spatial regions respectively corresponds to a plurality of sets of 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics; wherein each spatial reg
<a href="https://en.wikipedia.org/wiki/Ion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the plurality of spatial regions corresponds to a respective set of 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics; wherein the optimal FRC operational mode represents a FRC operational mode optimally selected from a plurality of FRC operational modes for a specific spatial region in the plurality of spatial regions of the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and wherein the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 metadata portion is to be used to determine a second optimal FRC operational mode with the downstream device that represents a second different FRC operational mode optimally selected from the plurality of FRC operational modes for a second specific spatial region in the plurality of spatial regions of the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.10. The method of claim 9, wherein the plurality of FRC operational modes comprises two or more FRC operational modes indicating different levels of image interpolation.11. The method of claim 1, wherein at least one of the one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics related to the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the one or more background regions bordering the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is determined based on 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vectors in one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and wherein the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vectors are already 
<a href="https://en.wikipedia.org/wiki/Pre"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pre
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-computed by an upstream device.12. The method of claim 1, wherein the FRC-related metadata portion includes one or more 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 values to indicate whether 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging is likely to occur in derived 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 interpolated from the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The method of claim 1, wherein each of the one or more 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 values is computed based at least in part on one or more of: a difference between an overall 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector magnitude of a foreground object and a 
<a href="https://en.wikipedia.org/wiki/Cosmic_background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background region
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 bordering the foreground object as determined for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; a difference between an overall 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector direction of the foreground object and the 
<a href="https://en.wikipedia.org/wiki/Cosmic_background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background region
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as determined for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; a texture of the foreground object as determined for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; or a texture of the 
<a href="https://en.wikipedia.org/wiki/Cosmic_background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background region
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.14. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 values comprises a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 value to indicate whether a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that includes in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is likely to have 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging with image interpolation, and wherein the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is computed based at least in part on one or more of: a difference between an overall 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector magnitude of a foreground object and a 
<a href="https://en.wikipedia.org/wiki/Cosmic_background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background region
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 bordering the foreground object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a difference between an overall 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector direction of the foreground object and the background region in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a texture of the foreground object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, or a texture of the background region in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.15. The method of claim 1, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 values comprises a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 value to indicate whether a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that includes in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is likely to have 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging with image interpolation, and wherein the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-based 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is computed based at least in part on a percentage of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that are determined to be likely to have 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging with image interpolation.16. A method, comprising:decoding, from a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a frame rate conversion (FRC)-related metadata portion, wherein the FRC-related metadata portion is generated by an upstream device for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based at least in part on one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics related to one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and one or more background regions bordering the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 characteristics are computed after the one or more foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the one or more background regions are separated based on image content visually depicted in one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;using the FRC-related metadata portion to determine an optimal FRC operational mode for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;operating the optimal FRC operational mode to generate, based on the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, zero or more additional 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in addition to the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;causing the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the zero or more additional 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be rendered on a 
<a href="https://en.wikipedia.org/wiki/Display_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    display device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.17. The method of claim 16, wherein the FRC-related metadata portion includes one or more 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 values to indicate whether 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 dragging is likely to occur in derived 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 interpolated from the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.18. The method of claim 16, wherein the optimal FRC operational mode represents a specific FRC operational mode selected from a plurality of FRC operational modes for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.19. The method of claim 18, wherein the plurality of FRC operational modes comprises two or more FRC operational modes indicating different levels of image interpolation.20. The method of claim 16, wherein the FRC-related metadata portion for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 indicates avoiding generating the one or more additional 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using image interpolation of the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the optimal FRC operational mode.21. The method of claim 16, wherein the FRC-related metadata portion for the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 indicates generating the one or more additional 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using image interpolation of the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the optimal FRC operational mode.22. The method of claim 16, further comprising changing to a different FRC operational mode at a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 cut separating two adjacent scenes.23. The method of claim 16, further comprising determining whether to perform image interpolation with respect to the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based at least in part on user preferences of a user to which the one or more 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are to be rendered._______________SURVEILLANCE METHOD AND COMPUTING DEVICE USING THE SAME_____20190131_____XMLs/xml/ipa190131.xml_____US-20190035092-A1 : US-15661064_____G06T0007254000 : G06T0007246000A 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is able to detect one or more 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 events based on two consecutive 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such as a first image and a second image. In the detection process, the 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 assigns identifiers to difference blocks retrieved from a plurality of first blocks of the first image, then defines a scanning window and moves the scanning window on a preset route over the first image. A new identical identifier is assigned for difference blocks within a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea which falls into the scanning window. After a scanning period is completed, the 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 determines the happening of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 event according to sufficient pixel similarities found in one of new identifiers._____d:FIELDThe subject matter herein generally relates to 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 technologies, and more particularly to a 
<a href="https://en.wikipedia.org/wiki/Surveillance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    surveillance method
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using the same.BACKGROUNDWith the development of science and technology, 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 technologies are used in more situations, such as 
<a href="https://en.wikipedia.org/wiki/Home_security"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    home security
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, community security, or 
<a href="https://en.wikipedia.org/wiki/Birdwatching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    field birdwatching
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.However, 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the traditional technology needs large amount of 
<a href="https://en.wikipedia.org/wiki/Computation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, thereby greatly increasing workload of a reference 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Therefore, it's necessary to provide a method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object (e.g., 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
) using fewer 
<a href="https://en.wikipedia.org/wiki/Computation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.BRIEF DESCRIPTION OF THE DRAWINGSImplementations of the present technology will be described, by way of example only, with reference to the attached figures, wherein:FIG. 1 illustrates a diagram showing a 
<a href="https://en.wikipedia.org/wiki/Distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of difference pixels in a first image;FIG. 2 illustrates a diagram showing a 
<a href="https://en.wikipedia.org/wiki/Distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of difference blocks in a first image;FIG. 3 illustrates a flowchart of an exemplary embodiment of a 
<a href="https://en.wikipedia.org/wiki/Surveillance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    surveillance method
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 4 illustrates a flowchart of an exemplary embodiment of step S10 in flowchart of FIG. 3;FIG. 5 illustrates a diagram showing a 
<a href="https://en.wikipedia.org/wiki/Distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of difference pixels in a part of the first image of FIG. 1, wherein FIG. 5 is the state of the part of the first image of FIG. 1 after being enlarged.FIG. 6 illustrates a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 showing a 
<a href="https://en.wikipedia.org/wiki/Distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of identifiers in difference blocks in the part of the first image of FIG. 5;FIGS. 7-10 illustrate 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagrams
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an exemplary embodiment of processes of reassigning new identifiers in the difference blocks in the part of the first image of FIG. 5, during a scanning period of method of FIG. 3;FIG. 11 illustrates a flowchart of an exemplary embodiment of step S10 of method in FIG. 3;FIG. 12 illustrates a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 showing a 
<a href="https://en.wikipedia.org/wiki/Distribution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    distribution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of new identifiers in the difference blocks in the part of the first image of FIG. 5, after the scanning period is completed in method of FIG. 3; andFIG. 13 illustrates an exemplary embodiment of 
<a href="https://en.wikipedia.org/wiki/Functional"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    functional
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Modularity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    modules
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 applying the method of FIG. 3._____c:1. A 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprising:at least one processor;a non-transitory 
<a href="https://en.wikipedia.org/wiki/Computer_data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 coupled to the at least one processor and configured to store one or more programs to be executed by the at least one processor, the one or more programs including instructions for:retrieving a plurality of difference blocks from a plurality of first blocks of a first image by comparing the first image with a second image;assigning identifiers to the difference blocks, wherein adjacent difference blocks are assigned with an identical identifier;defining a scanning window and moving the scanning window on a preset route over the first image, reassigning a new identical identifier to difference blocks within a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea which is falling into the scanning window, wherein the new identical identifier is selected from 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 identifiers of the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea according a preset rule;selecting a target identifier associating with a target object from the new identifiers and determining whether the amount of difference blocks associating with the target identifier exceeds a first preset value; andoutputting a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 event of the target object upon the condition that the amount of difference blocks associating with the target identifier exceeds the first preset value.2. The 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of claim 1, the retrieving instruction further comprises:comparing each pixel of the first image with a corresponding pixel of the second image;retrieving difference pixels of the first image, wherein a difference between each difference pixel and corresponding pixel of the second image is greater than a second preset value; andretrieving the difference blocks from the first blocks, wherein the number of difference pixels of each difference 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is greater than a third preset value.3. The 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of claim 1, the moving instructions further comprise:(A). moving the scanning window from 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to right based on a preset increment, until the scanning window touches a right edge of the first image;(B), resetting the scanning window on a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 side edge of the first image and moving the scanning window down a preset increment;repeating (A) and (B) until a scanning period is completed.4. The 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of claim 1, the reassigning instructions further comprise:selecting a smallest one of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 identifiers of the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea as the new identical identifier; andreassigning the new identical identifier to the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea.5. The 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of claim 1, wherein the determining instruction further comprises:counting amounts, each of which indicates the number of difference blocks associating with corresponding one of the new identifiers; andselecting one new identifier with a maximum amount as the target identifiers, and determining whether the maximum amount exceeds the first preset value.6. A 
<a href="https://en.wikipedia.org/wiki/Surveillance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    surveillance method
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprising:retrieving a plurality of difference blocks from a plurality of first blocks of a first image by comparing the first image with a second image;assigning identifiers to the difference blocks, wherein adjacent difference blocks are assigned with an identical identifier;defining a scanning window and moving the scanning window on a preset route over the first image, reassigning a new identical identifier to difference blocks within a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea which is falling into the scanning window, wherein the new identical identifier is selected from 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 identifiers of the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea according a preset rule;selecting a target identifier associating with a target object from the new identifiers and determining whether the amount of difference blocks associating with the target identifier exceeds a first preset value; andoutputting a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 event of the target object upon the condition that the amount of difference blocks associating with the target identifier exceeds the first preset value.7. The method of claim 6, the retrieving instruction further comprises:comparing each pixel of the first image with a corresponding pixel of the second image;retrieving difference pixels of the first image, wherein a difference between each difference pixel and corresponding pixel of the second image is greater than a second preset value; andretrieving the difference blocks from the first blocks, wherein the number of difference pixels of each difference 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is greater than a third preset value.8. The method of claim 6, the moving instructions further comprise:(A). moving the scanning window from 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to right based on a preset increment, until the scanning window touches a right edge of the first image;(B), resetting the scanning window on a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 side edge of the first image and moving the scanning window down a preset increment;repeating (A) and (B) until a scanning period is completed.9. The method of claim 6, the reassigning instructions further comprise:selecting a smallest one of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 identifiers of the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea as the new identical identifier; andreassigning the new identical identifier to the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea.10. The method of claim 6, wherein the determining step further comprises:counting amounts, each of which indicates the number of difference blocks associating with corresponding one of the new identifiers; andselecting one new identifier with a maximum amount as the target identifiers, and determining whether the maximum amount exceeds the first preset value.11. A non-transitory 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 storing 
<a href="https://en.wikipedia.org/wiki/Executable"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    executable program
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 instructions which, when executed by a processing system, cause the processing system to perform a method comprising:retrieving a plurality of difference blocks from a plurality of first blocks of a first image by comparing the first image with a second image;assigning identifiers to the difference blocks, wherein adjacent difference blocks are assigned with an identical identifier;defining a scanning window and moving the scanning window on a preset route over the first image, and when the scanning window is moved to an image subarea of the first image, reassigning a new identical identifier to difference blocks within the image subarea of the first image, wherein the new identical identifier is selected from 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 identifiers of the difference blocks within the image subarea of the first image according a preset rule;selecting a target identifier associating with a target object from the new identifiers and determining whether the amount of difference blocks associating with the target identifier exceeds a first preset value; andoutputting a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 event of the target object upon the condition that the amount of difference blocks associating with the target identifier exceeds the first preset value.12. The medium of claim 11, the retrieving instruction further comprises:comparing each pixel of the first image with a corresponding pixel of the second image;retrieving difference pixels of the first image, wherein a difference between each difference pixel and corresponding pixel of the second image is greater than a second preset value; andretrieving the difference blocks from the first blocks, wherein the number of difference pixels of each difference 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is greater than a third preset value.13. The medium of claim 11, the moving instructions further comprise:(A). moving the scanning window from 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to right based on a preset increment, until the scanning window touches a right edge of the first image;(B), resetting the scanning window on a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 side edge of the first image and moving the scanning window down a preset increment;repeating (A) and (B) until a scanning period is completed.14. The medium of claim 11, the reassigning instructions further comprise:selecting a smallest one of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 identifiers of the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea as the new identical identifier; andreassigning the new identical identifier to the difference blocks within the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image subarea.15. The medium of claim 11, wherein the determining step further comprises:counting amounts, each of which indicates the number of difference blocks associating with corresponding one of the new identifiers; andselecting one new identifier with a maximum amount as the target identifiers, and determining whether the maximum amount exceeds the first preset value._______________OBJECT DISPLACEMENT DETECTION METHOD 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 DETECTING OBJECT DISPLACEMENT BY MEANS OF DIFFERENCE IMAGE DOTS_____20190207_____XMLs/xml/ipa190207.xml_____US-20190043206-A1 : US-15987876 : CN-201710657081.6_____G06T0007254000 : G06T0011200000 : G08B0013196000An object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method includes capturing n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object for obtaining n sets of image dots, where the object corresponds to an ith set of image dots in an ith image of the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; performing (n−1) difference calculations using the n sets of image dots to obtain (n−1) sets of difference image dots, where a jth set of difference image dots of the (n−1) sets of difference image dots is generated by performing a jth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (n−1) difference calculations using a (j+1)th set of image dots and a jth set of image dots of the n sets of the image dots; and determining the object has displaced when a sum of numbers of the (n−1) sets of difference image dots reaches a first threshold._____d:BACKGROUND OF THE INVENTION1. Field of the InventionThe invention relates to an object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and more particularly, an object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method used for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object displacement by means of difference image dots.2. Description of the Prior ArtConventional security monitoring method can detect a large movement of an object. For example, a person who is walking or running can be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. However, it is relatively difficult to detect a small movement of an object. For example, w
<a href="https://en.wikipedia.org/wiki/Hen"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hen
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an unknown person enters a monitored area, it is difficult for a conventional 
<a href="https://en.wikipedia.org/wiki/Security_through_obscurity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    security method
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect the person's movement if the person intentionally keeps still. Taking a 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as an example, slight vibrations may still occur due to breathing or 
<a href="https://en.wikipedia.org/wiki/Multivibrator"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    inevitable slight
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 movement even if the 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 intentionally stays still. However, the 
<a href="https://en.wikipedia.org/wiki/Probability"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    probability
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of false alarms will greatly increase if sending an alarm 
<a href="https://en.wikipedia.org/wiki/Universal_quantification"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    for every
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 slight vibration in a monitored area. Hence, most 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 slight vibrations are filtered out as 
<a href="https://en.wikipedia.org/wiki/Background_noise"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background noise
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and the slight vibrations which should be alerted (e.g. the slight 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vibrations of an intruder without consent) are likely to be neglected. By means of a specific method such as Eulerian algorithm, transient changes of the position of an object in an image can be amplified to visualize the above mentioned slight movement. However, this sort of method relates to 
<a href="https://en.wikipedia.org/wiki/Complex"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complex
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculations and image processing programs, and excessive resource of hardware and software will therefore be consumed. Hence, a better solution is still required in the field.SUMMARY OF THE INVENTIONAn embodiment provides an object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method. The method includes capturing n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object for obtaining n sets of image dots, where the object corresponds to an ith set of image dots in an ith image of the n imag
<a href="https://en.wikipedia.org/wiki/ES"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    es
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; performing (n−1) difference calculations using the n sets of image dots to obtain (n−1) sets of difference image dots, where a jth set of difference image dots of the (n−1) sets of difference image dots is generated by performing a jth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (n−1) difference calculations using a (j+1)th set of image dots and a jth set of image dots of the n sets of the image dots; and determining the object has displaced when a sum of numbers of the (n−1) sets of difference image dots reaches a first threshold.Another embodiment provides an object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 displacement of an object. The system includes an image capture unit, a memory and a processor. The image capture unit is used to capture n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the object for obtaining n sets of image dots, where the object corresponds to an ith set of image dots in an ith image of the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The memory is coupled to the image capture unit and used to store then 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a first threshold. The pr
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ocessor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is coupled to the memory and the image capture unit and used to perform (n−1) difference calculations using the n sets of image dots to obtain (n−1) sets of difference image dots and determine whether the object has displaced, where a jth set of difference image dots of the (n−1) sets of difference image dots is generated by the processor by performing a jth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (n−1) difference calculations using a (j+1)th set of image dots and a jth set of image dots of the n sets of the image dots, and the processor determines that the object has displaced when a sum of numbers of the (n−1) sets of difference image dots reaches a first threshold.These and other 
<a href="https://en.wikipedia.org/wiki/Objective"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objectives
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the present invention will no doubt become obvious to those of ordinary skill in the art after reading the following detailed description of the preferred embodiment that is illustrated in the various figures and drawings.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 illustrates that a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object are captured according to an embodiment.FIG. 2 illustrates that a difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is performed using two 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to an embodiment.FIG. 3 illustrates that an area is displayed on a visual display according to a plurality of sets of difference image dots according another embodiment.FIG. 4 illustrates an object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system according to an embodiment._____c:1. An object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method comprising:capturing n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object for obtaining n sets of image dots, wherein the object corresponds to an ith set of image dots in an ith image of the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;performing (n−1) difference calculations using the n sets of image dots to obtain (n−1) sets of difference image dots, wherein a jth set of difference image dots of the (n−1) sets of difference image dots is generated by performing a jth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (n−1) difference calculations using a (j+1)th set of image dots and a jth set of image dots of the n sets of the image dots; anddetermining the object has displaced when a sum of numbers of the (n−1) sets of difference image dots reaches a first threshold;wherein i, n and j are 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integers, i≤n, and j+1≤n.2. The method of claim 1, wherein the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are captured during a first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and the method further comprises:capturing m 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during a second 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 following the first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for obtaining m sets of image dots, wherein the object corresponds to a pth set of image dots in a pth image of the m 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;performing (m−1) difference calculations using the m sets of image dots to obtain (m−1) sets of difference image dots, wherein a qth set of difference image dots of the (m−1) sets of difference image dots is generated by performing a qth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (m−1) difference calculations using a (q+1)th set of image dots and a qth set of image dots of the m sets of the image dots; anddetermining the object has not displaced during the second 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 when a sum of numbers of the (m−1) sets of difference image dots fails to reach a second threshold;wherein p, m and q are 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integers, p≤m, and q+1≤m.3. The method of claim 1, further comprising:displaying at least one visual pattern on a visual display according to the (n−1) sets of difference image dots.4. The method of claim 3, wherein the visual pattern is displayed by displaying the (n−1) sets of difference image dots on the visual display.5. The method of claim 3, wherein displaying the at least one visual pattern on the visual display according to the (n−1) sets of difference image dots comprises:displaying k sets of difference image dots of the (n−1) sets of difference image dots on the visual display during a first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andeliminating the k sets of difference image dots from the visual display after the first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 has elapsed;wherein k is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer and k≤(n−1).6. The method of claim 3, wherein displaying the at least one visual pattern on the visual display according to the (n−1) sets of difference image dots comprises:displaying an area on the visual display according to the (n−1) sets of difference image dots wherein the area highlights the object.7. The method of claim 3, wherein displaying the at least one visual pattern on the visual display according to the (n−1) sets of difference image dots comprises:displaying an area on the visual display according to k sets of difference image dots of the (n−1) sets of difference image dots during a first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the area highlights the object; andeliminating the area from the visual display after the first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 has elapsed;wherein k is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer and k≤(n−1).8. The method of claim 3, wherein the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are captured during a first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and the method further comprises:capturing m 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during a second 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 following the first 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for obtaining m sets of image dots, wherein the object corresponds to a pth set of image dots in a pth image of the m 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;performing (m−1) difference calculations using the m sets of image dots to obtain (m−1) sets of difference image dots, wherein a qth set of difference image dots of the (m−1) sets of difference image dots is generated by performing a qth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (m−1) difference calculations using a (q+1)th set of image dots and a qth set of image dots of the m sets of the image dots;determining the object has not displaced during the second 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 when a sum of numbers of the (m−1) sets of difference image dots fails to reach a second threshold; andeliminating the visual pattern from the visual display after determining the object has not displaced during the second 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;wherein p, m and q are 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integers, p≤m, and q+1≤m.9. An object 
<a href="https://en.wikipedia.org/wiki/DWDD"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    displacement detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 displacement of an object, comprising:an image capture unit configured to capture n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the object for obtaining n sets of image dots, wherein the object corresponds to an ith set of image dots in an ith image of the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;a memory coupled to the image capture unit and configured to store the n 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a first threshold; anda processor coupled to the memory and the image capture unit and configured to perform (n−1) difference calculations using the n sets of image dots to obtain (n−1) sets of difference image dots and determine whether the object has displaced, wherein a jth set of difference image dots of the (n−1) sets of difference image dots is generated by the processor by performing a jth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (n−1) difference calculations using a (j+1)th set of image dots and a jth set of image dots of the n sets of the image dots, and the processor determines that the object has displaced when a sum of numbers of the (n−1) sets of difference image dots reaches a first threshold;wherein i, n and j are 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integers, i≤n, and j+1≤n.10. The system of claim 9 further comprising:a 
<a href="https://en.wikipedia.org/wiki/Display_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    display device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 coupled to the memory and the processor wherein the processor controls the 
<a href="https://en.wikipedia.org/wiki/Display_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    display device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to display at least one visual pattern according to the (n−1) sets of difference image dots.11. The system of claim 9, wherein:the image capture unit is further configured to capture m 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during a 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for obtaining m sets of image dots corresponding to the object, wherein the object corresponds to a pth set of image dots in a pth image of the m imag
<a href="https://en.wikipedia.org/wiki/ES"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    es
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;the memory is further configured to store the 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the m 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a second threshold;the processor is further configured to perform (m−1) difference calculations using the m sets of image dots to obtain (m−1) sets of difference image dots, wherein a qth set of difference image dots of the (m−1) sets of difference image dots is generated by performing a qth difference 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the (m−1) difference calculations using a (q+1)th set of image dots and a qth set of image dots of the m sets of the image dots; and the processor determines that the object has not displaced during the 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 when a sum of numbers of the (m−1) sets of difference image dots fails to reach a second threshold;wherein p, m and q are 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integers, p≤m and q+1≤m.12. The system of claim 11, further comprising:a 
<a href="https://en.wikipedia.org/wiki/Display_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    display device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 coupled to the memory and the processor;wherein the processor controls the 
<a href="https://en.wikipedia.org/wiki/Display_device"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    display device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to display the at least one visual pattern when the processor determines the object has displaced according to the (n−1) sets of difference image dots, and the processor controls the display device to eliminate the at least one visual pattern when the processor determines the object has not displaced during the 
<a href="https://en.wikipedia.org/wiki/Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time interval
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the (m−1) sets of difference image dots._______________LEARNING RIGIDITY OF DYNAMIC SCENES 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 THREE-DIMENSIONAL SCENE FLOW ESTIMATION_____20190221_____XMLs/xml/ipa190221.xml_____US-20190057509-A1 : US-16052528 : US-62546442_____G06T0007254000 : G06T0007900000 : G06T0007500000 : G06N0003080000 : G06N0005040000 : G06T0003000000 : G06T0007700000 : G06T0007600000 : G06T0007110000 : G06T0007194000A 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receives color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a dynamic 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in three-dimensional (3D) space. Motion of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the image sequence results from a combination of a dynamic camera orientation and motion or a change in the shape of an object in the 3D space. The 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generates two components that are used to produce a 3D 
<a href="https://en.wikipedia.org/wiki/Motion_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 representing the dynamic (non-rigid) part of the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The two components are information identifying dynamic and static portions of each image and the camera orientation. The dynamic portions of each image contain 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 3D space that is independent of the camera orientation. In other words, the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 3D space (estimated 3D 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
) is separated from the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the camera._____d:CLAIM OF PRIORITYThis application claims the benefit of U.S. Provisional Application No. 62/546,442 (Attorney Docket No. NVIDP1184+/17SC0167US01) titled “Learning-Based 3D Scene Flow Estimation with RGBD Images,” filed Aug. 16, 2017, the entire contents of which are incorporated herein by reference.FIELD OF THE INVENTIONThe present invention relates to three-dimensional (3D) 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation for 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and more particularly to learning 
<a href="https://en.wikipedia.org/wiki/Rigidity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rigidity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of dynamic scenes by a 
<a href="https://en.wikipedia.org/wiki/Neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.BACKGROUNDThe estimation of 3D 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a fundamental 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 problem, and key to many 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 such as robot manipulation, dynamic 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 reconstruction, 
<a href="https://en.wikipedia.org/wiki/Self-driving_car"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    autonomous driving
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, 
<a href="https://en.wikipedia.org/wiki/Activity_recognition"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    action recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and 
<a href="https://en.wikipedia.org/wiki/Video_content_analysis"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video analysis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The task of estimating 3D 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is commonly referred as 3D 
<a href="https://en.wikipedia.org/wiki/Motion_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation. 3D 
<a href="https://en.wikipedia.org/wiki/Motion_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation in a dynamic environment is, however, a challenging and still open problem when the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is observed from different viewpoints and the number of moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (either rigid or non-rigid) or movement of a single object in each image is large. The difficulty is mainly because the 
<a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    disambiguation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Motion_capture"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    camera motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (ego-
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
) from object 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 requires the correct 
<a href="https://en.wikipedia.org/wiki/Identification"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    identification
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of rigid 
<a href="https://en.wikipedia.org/wiki/Statics"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    static structure
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Existing approaches suffer from demanding computational expenses and often fail when a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes multiple moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the foreground. There is a need for addressing these issues and/or other issues associated with the 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.SUMMARYA method, 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium, and system are disclosed for learning 
<a href="https://en.wikipedia.org/wiki/Rigidity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rigidity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of dynamic scenes by a 
<a href="https://en.wikipedia.org/wiki/Neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are received for a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a dynamic 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in three-dimensional (3D) space including a first image and a second image, where the first image is captured from a first viewpoint and the second image is captured from a second viewpoint. The color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are processed by layers of a 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate segmentation 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 indicating a portion of the second image where a first object changes position or shape relative the first object in the first image.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1A illustrates 2D 
<a href="https://en.wikipedia.org/wiki/Flow_Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a static 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 resulting from 
<a href="https://en.wikipedia.org/wiki/Motion_capture"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    camera motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment.FIG. 1B illustrates 2D 
<a href="https://en.wikipedia.org/wiki/Flow_Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 resulting from 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a static camera, in accordance with an embodiment.FIGS. 1C and 1D illustrate 2D 
<a href="https://en.wikipedia.org/wiki/Flow_Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 resulting from 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Motion_capture"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    camera motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment.FIG. 1E illustrates a flowchart of a method for generating a 
<a href="https://en.wikipedia.org/wiki/Rigidity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rigidity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 mask for 3D 
<a href="https://en.wikipedia.org/wiki/Motion_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation, in accordance with an embodiment.FIG. 2A illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 3D 
<a href="https://en.wikipedia.org/wiki/Motion_field"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 estimation system, in accordance with an embodiment.FIG. 2B illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Rigidity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rigidity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 transform 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from FIG. 2A, in accordance with an embodiment.FIG. 2C illustrates another 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Rigidity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rigidity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 transform 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from FIG. 2A, in accordance with an embodiment.FIG. 2D illustrates a flowchart of a method for 
<a href="https://en.wikipedia.org/wiki/Training"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    training
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Rigidity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rigidity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 transform 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in accordance with an embodiment.FIG. 3 illustrates a 
<a href="https://en.wikipedia.org/wiki/Parallel_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parallel processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 unit, in accordance with an embodiment.FIG. 4A illustrates a general processing 
<a href="https://en.wikipedia.org/wiki/Cluster"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cluster
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 within the 
<a href="https://en.wikipedia.org/wiki/Parallel_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parallel processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 unit of FIG. 3, in accordance with an embodiment.FIG. 4B illustrates a memory partition unit of the 
<a href="https://en.wikipedia.org/wiki/Parallel_computing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    parallel processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 unit of FIG. 3, in accordance with an embodiment.FIG. 5A illustrates the streaming multi-processor of FIG. 4A, in accordance with an embodiment.FIG. 5B is a 
<a href="https://en.wikipedia.org/wiki/Concept_map"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    conceptual diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a processing system implemented using the PPU of FIG. 3, in accordance with an embodiment.FIG. 5C illustrates an exemplary system in which the various architecture and/or functionality of the various previous embodiments may be implemented._____c:1. A computer-implemented method, comprising:receiving color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a dynamic 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in three-dimensional (3D) space including a first image and a second image, wherein the first image is captured from a first viewpoint and the second image is captured from a second viewpoint; andprocessing the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by layers of a 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 indicating a portion of the second image where a first object changes position or shape relative the first object in the first image.2. The computer-implemented method of claim 1, further comprising processing the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the layers of the 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to produce a pose of the second viewpoint, the pose including a 
<a href="https://en.wikipedia.org/wiki/Orientation_(geometry)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    position and orientation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 3D space.3. The computer-implemented method of claim 2, further comprising:warping the pose to generate 2D viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the second image; andsubtracting the 2D viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from two-dimensional 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to produce estimated projected 3D 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the second image.4. The computer-implemented method of claim 2, further comprising refining the pose based on two-dimensional 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The computer-implemented method of claim 1, further comprising refining the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on two-dimensional 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The computer-implemented method of claim 1, further comprising:receiving depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andprocessing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.7. The computer-implemented method of claim 1, further comprising:processing the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to extract depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andprocessing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. The computer-implemented method of claim 1, further comprising 
<a href="https://en.wikipedia.org/wiki/Training"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    training
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using a 
<a href="https://en.wikipedia.org/wiki/Data_set"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    dataset
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including a first image sequence for viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a static 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a second image sequence for 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a static viewpoint, and a third image sequence for simultaneous viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.9. The computer-implemented method of claim 8, wherein a portion of the 
<a href="https://en.wikipedia.org/wiki/Data_set"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    dataset
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes a real background 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and synthetic foreground 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.10. The computer-implemented method of claim 1, wherein the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a mask comprising a single bit for each pixel in the second image.11. The computer-implemented method of claim 1, wherein the layers of the 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprise one or more convolutional layers followed by one or more deconvolutional layers.12. A system, comprising:a processing unit configured to:receive color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a dynamic 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in three-dimensional (3D) space including a first image and a second image, wherein the first image is captured from a first viewpoint and the second image is captured from a second viewpoint; andprocess the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by layers of a 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 indicating a portion of the second image where a first object changes position or shape relative the first object in the first image.13. The system of claim 12, wherein the processing unit is further configured to process the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the layers of the 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to produce a pose of the second viewpoint, the pose including a 
<a href="https://en.wikipedia.org/wiki/Orientation_(geometry)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    position and orientation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the 3D space.14. The system of claim 13, wherein the processing unit is further configured to:warp the pose to generate 2D viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the second image; andsubtract the 2D viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from two-dimensional 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to produce estimated projected 3D 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the second image.15. The system of claim 14, wherein the processing unit is further configured to refine the pose based on two-dimensional 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. The system of claim 12, wherein the processing unit is further configured to refine the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on two-dimensional 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.17. The system of claim 12, wherein the processing unit is further configured to:receive depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andprocess the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.18. The system of claim 12, wherein the processing unit is further configured to train the 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using a 
<a href="https://en.wikipedia.org/wiki/Data_set"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    dataset
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including a first image sequence for viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a static 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a second image sequence for 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 motion and a static viewpoint, and a third image sequence for simultaneous viewpoint 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.19. The system of claim 12, wherein the 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a mask comprising a single bit for each pixel in the second image.20. A non-transitory, computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 storing instructions that, when executed by a processing unit, cause the processing unit to:receive color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a dynamic 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in three-dimensional (3D) space including a first image and a second image, wherein the first image is captured from a first viewpoint and the second image is captured from a second viewpoint; andprocess the color 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by layers of a 
<a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    neural network model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmentation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 indicating a portion of the second image where a first object changes position or shape relative the first object in the first image._______________IMAGE PROCESSING APPARATUS, IMAGE PROCESSING METHOD, AND STORAGE MEDIUM_____20190801_____XMLs/xml/ipa190801.xml_____US-20190236791-A1 : US-16260806 : JP-2018-014188_____G06T0007254000 : G06T0007215000 : G08B0013196000 : H04N0005232000 : H04N0005272000An 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus includes a detection unit configured to detect a first region in which a foreground object is present with respect to a plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a retention unit configured to retain a first background image, a generation unit configured to generate a second background image based on portions of each of the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which are not 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as a first region, and an output unit configured to select one of the first 
<a href="https://en.wikipedia.org/wiki/Human_back"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    back
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Ground-glass_opacity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ground image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background image based on a property of the second background image, and configured to output, based on the selected background image and the first region, an image in which the foreground object is obscured._____d:BACKGROUND OF THE INVENTIONField of the InventionAspects of the present invention generally relate to an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and a 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 each of which hides a specific object, such as a person, from a captured image so as to protect privacy.Description of the Related ArtIn recent years, the importance of 
<a href="https://en.wikipedia.org/wiki/Information_privacy"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    privacy protection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for an individual whose image is captured by a monitoring camera has been increasing. Therefore, there is a technique to use a background image so as to detect a region in which to protect privacy. For example, there is a method of previously acquiring, as a background image, an image captured at timing when no foreground is shown in the image, comparing a processing target image with the background image, and 
<a href="https://en.wikipedia.org/wiki/Tijdschrift_voor_Gerontologie_en_Geriatrie"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performi
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
ng concealment processing on a specific region of the processing target image based on a result of comparison, thus protecting privacy. A technique discussed in Japanese Patent Application Laid-Open No. 2016-115214 detects a 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or moving object included in a captured image and performs processing in such a way as to update a background image based on the detection thereof, thus increasing the 
<a href="https://en.wikipedia.org/wiki/Accuracy_and_precision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    accuracy
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of concealment processing.In the technique of acquiring, as a background image, an image captured at timing when no foreground is shown in the image and using the background image in a fixed manner, if, for example, a large change occurs in the luminance of an image capturing environment, a comparison with the background image may sometimes cause a region to be excessively extracted as a foreground. On the other 
<a href="https://en.wikipedia.org/wiki/Hand"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hand
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, in the technique discussed in Japanese Patent Application Laid-Open No. 2016-115214, while regions other than 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or moving object regions included in an image capturing range are combined to successively update a background image, depending on an environment in which image capturing is performed, a region which is always determined to be a moving object region occurs, so that the background image may enter a hole-like defective state. Here, a hole-like defective state is a state where the moving object region is removed from the background image. It may be unfavorable to use such a hole-like defective image as a background image for foreground 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing or 
<a href="https://en.wikipedia.org/wiki/Information_privacy"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    privacy protection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing.SUMMARY OF THE INVENTIONAccording to an aspect of the present invention, an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus includes a detection unit configured to detect a first region in which a foreground object is present with respect to a plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a retention unit configured to retain a first background image, a generation unit configured to generate a second background image based on portions of each of the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which are not 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as a first region, and an output unit configured to select one of the first background image and the second background image based on a property of the second background image, and configured to output, based on the selected background image and the first region, an image in which the foreground object is obscured.Further 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the present invention will become apparent from the following description of exemplary embodiments with reference to the attached drawings.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1A is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a hardware configuration of each apparatus of an 
<a href="https://en.wikipedia.org/wiki/Image_processor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and FIG. 1B is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a schematic configuration of the 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system.FIG. 2 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a 
<a href="https://en.wikipedia.org/wiki/Functional"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    functional
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configuration of each apparatus.FIGS. 3A, 3B, 3C, and 3D are 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagrams
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an outline of generation processing for a background image.FIG. 4 is a flowchart illustrating the generation processing for a background image.FIG. 5A is a flowchart illustrating generation processing for a 
<a href="https://en.wikipedia.org/wiki/Information_privacy"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    privacy protection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 image, and FIG. 5B is a diagram illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/User_interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____c:1. An 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus comprising:a detection unit configured to detect a first region in which a foreground object is present with respect to a plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;a retention unit configured to retain a first background image;a generation unit configured to generate a second background image based on portions of each of the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which are not 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as a first region; andan output unit configured to select one of the first background image and the second background image based on a property of the second background image, and configured to output, based on the selected background image and the first region, an image in which the foreground object is obscured.2. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the property of the second background image used by the output unit to select one of the first background image and the second background image is a proportion of a number of pixels of the second background image to a number of pixels of the captured image3. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the property of the second background image used by the output unit to select one of the first background image and the second background image is an area ratio of the second background image to an 
<a href="https://en.wikipedia.org/wiki/Field_of_view"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    angular field
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the captured image.4. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the detection unit is configured to detect an object having a predetermined attribute as the foreground object.5. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the detection unit is configured to detect a foreground object included in the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the first background image.6. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the first region is defined as a rectangular region which includes the foreground object.7. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1,wherein the detection unit is configured to detect the first region in each of a first captured image and a second captured image, andwherein the generation unit is configured to generate the second background image using, with respect to a second region in which the first region of the first captured image and the first region of the second captured image overlap, pixel values of a region corresponding to the second region included in the second captured image.8. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1,wherein the detection unit is configured to detect a first region in each of a first captured image and a second captured image, andwherein the generation unit is configured to generate the second background image based on, with respect to a second region in which the first region of the first captured image and the first region of the second captured image overlap, both pixel values of a region corresponding to the second region included in the first captured image and pixel values of a region corresponding to the second region included in the second captured image.9. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the generation unit is configured to determine whether to use a further captured image for 
<a href="https://en.wikipedia.org/wiki/Composite"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    composite
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generation of the second background image based on, with respect to the second background image generated based on the plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a score determined based on a proportion of a region in which pixel values are not acquired from the plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.10. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the generation unit is configured to update the generated second background image with use of a newly captured image.11. The 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, further comprising an acquisition unit configured to acquire the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.12. An 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method comprising:
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in which a foreground object is present with respect to a plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;retaining a first background image;generating a second background image based on portions of each of the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which are not 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as a first region; andselecting one of the first background image and the second background image based on a property of the second background image, and outputting, based on the selected background image and the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 first region, an image in which the foreground object is obscured.13. A non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 storing computer-executable instructions that, when executed by a computer, cause the computer to perform a method comprising:
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in which a foreground object is present with respect to a plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;retaining a first background image;generating a second background image based on portions of each of the plurality of captured 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which are not 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as a first region; andselecting one of the first background image and the second background image based on a property of the second background image, and outputting, based on the selected background image and the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 first region, an image in which the foreground object is obscured._______________DETECTION SYSTEM, DETECTION METHOD, AND PROGRAM STORAGE MEDIUM_____20170629_____XMLs/xml/ipa170629.xml_____US-20170186179-A1 : US-15315413 : JP-2014-115207 : WO-PCT/JP2015/002775-00_____G06T0007254000 : G06T0007215000A detection system which detects a mobile object includes: an image input unit for receiving an input of a plurality of image frames having different capturing times; an inter-background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 distance 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 unit for calculating differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and a mobile object detection unit for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in an image frame._____d:TECHNICAL FIELDSome aspects of the present invention relate to an 
<a href="https://en.wikipedia.org/wiki/Image_processor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and a program 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.BACKGROUND ARTIn recent years, in the application of video surveillance or the like, needs for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and tracking a mobile object such as a person or 
<a href="https://en.wikipedia.org/wiki/Vehicle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a vehicle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are increasing. With such increasing needs, many techniques for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a mobile object and tracking the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Mobile_object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    mobile object
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have been proposed. A mobile object herein is not limited to an object which continues to move among 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 appeared on an image, and also includes an object which “temporarily stops” (also referred to as “rests” or “loiters”). In other words, a mobile object generally means an object appeared on an image except a portion regarded as a background. For example, a person or 
<a href="https://en.wikipedia.org/wiki/Vehicle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a vehicle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which is a common target to be monitored by video surveillance is moving not all the time, but has a state of resting such as temporarily stopping or parking. For this reason, it is important in 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 such as video surveillance that an object can be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 even when the object temporarily stops.As a method of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a mobile object, a background difference method is known (
<a href="https://en.wikipedia.org/wiki/See"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    see
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, Non Patent Literature 1 and Non Patent Literature 2). The background difference method is a method in which an image stored as a background is compared with an image captured by a camera to extract a region having a difference as a mobile object. Here, when the mobile object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by using a background difference, an accurate background 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is required at the time of analysis. This is because, when 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at the start of measurement is simply used as a background fixedly, many error detections occur, caused by influence of a change of the background due to an 
<a href="https://en.wikipedia.org/wiki/Environmental_change"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    environmental change
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 such as a change of illumination. Accordingly, in order to avoid such problems, usually, a background at the time of analysis is performed by a method such as calculating a mean value for each pixel from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 observed within the latest time period. For example, Non Patent Literature 1 discloses a method of applying a background difference method while performing an update of a background successively.On the other 
<a href="https://en.wikipedia.org/wiki/Hand"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hand
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, there is also a technique in which only an object which temporarily rests such as a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object or a person who loiters for a predetermined time is extracted (
<a href="https://en.wikipedia.org/wiki/See"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    see
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, Patent Literature 1). Patent Literature 1 discloses a method in which a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is analyzed by a plurality of background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    models
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 having different time spans. In the method, a long-term background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which is analyzed using a long time range and a short-term background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which is analyzed using a 
<a href="https://en.wikipedia.org/wiki/Short_Time"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    short time
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 range are generated. When a mobile object is not 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the background difference based on the short-term background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the background difference based on the long-term background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a predetermined times, the mobile object is then 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as being a temporarily stationary object.CITATION LISTPatent Literature[PTL 1] Patent No. 5058010Non Patent Literature[NPL 1] KAWABATA ATSUSHI, TANIFUJI SHINYA, MOROOKA YASUO. “An Image Extraction Method for Moving Object”, Information Processing Society of Japan, vol.28, no.4, pp.395-402, 1987[NPL 2] C. Stauffer and W. E. L. Grimson, “Adaptive background mixture 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    models
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for real-time tracking”, Proceedings of CVPR, vol.2, pp. 246-252, 1999SUMMARY OF INVENTIONTechnical ProblemAs described in Non Patent Literature 1, a case in which a mobile object such as a person or 
<a href="https://en.wikipedia.org/wiki/Vehicle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a vehicle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 stays for a longer time than a time span for analyzing a background image in a method of extracting a difference between a successively updated background image and an image to be analyzed will be considered. In this case, there is a problem that the mobile object cannot be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 since it is determined as a portion of a background image. On the other 
<a href="https://en.wikipedia.org/wiki/Hand"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hand
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, when a time span for analyzing is increased for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a temporarily stationary object, the analysis is likely to be influenced by a change of a background due to an external noise such as illumination fluctuation, and therefore, there arises a problem that a temporary change of a background image other than the stationary object is often erroneously 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Patent Literature 1 aims at 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a temporarily stationary object on the assumption that a background difference based on a long-term background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can express a true background at the time of obtaining an observed image. For this reason, it has been difficult to sufficiently suppress error detections in an environment in which a background gradually changes such as illumination fluctuation since there is a large difference from a true background at the time of obtaining an observed image in a long-term background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Some aspects of the present invention have been made in view of the above-described problems, and an object of the present invention is provide a detection system, a detection method, and a program 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which can preferably detect a mobile object.Solution to ProblemA detection system of the present invention includes: input means for receiving an input of a plurality of image frames having different capturing times;
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 means for calculating differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetect means for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in an image frame in which a difference between the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a first threshold, and a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than second threshold times a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.A detection method of the present invention by a computer, includes:receiving an input of a plurality of image frames having different capturing times;calculating differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in an image frame in which a difference between the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a first threshold, and a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third 
<a href="https://en.wikipedia.org/wiki/Human_back"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    back
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
ground 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than second threshold times a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.A program 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the present invention for storing a program causing a computer to executea processing of receiving an input of a plurality of image frames having different capturing times;a processing of calculating differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anda processing of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in an image frame in which a difference between the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a first threshold, and a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than second threshold times a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In the present invention, a “unit”, “means”, “apparatus”, or a “system” does not simply means a physical means, and also includes a 
<a href="https://en.wikipedia.org/wiki/Software_engineering"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    software realizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a function of the “unit”, “means”, “apparatus”, or “system”. A function of one “unit”, “means”, “apparatus”, or “system” may be realized by two or more physical means or apparatuses, or two or more functions of a “unit”, “means”, “apparatus”, or a “system” may be realized by one physical means or apparatus.Advantageous Effects of InventionAccording to the present invention, a detection system, a detection method, and a program 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 which can preferably detect a mobile object can be provided.BRIEF DESCRIPTION OF DRAWINGSFIG. 1 is a diagram illustrating a relationship between a background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and an input image frame.FIG. 2 is a 
<a href="https://en.wikipedia.org/wiki/Functional_block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    functional block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 schematically illustrating a detection system according to a first example embodiment.FIG. 3 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart illustrating a processing 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a detection system illustrated in FIG. 2.FIG. 4 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a hardware configuration which can implement a detection system shown in FIG. 2.FIG. 5 is a 
<a href="https://en.wikipedia.org/wiki/Functional_block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    functional block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 schematically illustrating a detection system according to a second example embodiment._____c:1. A detection system comprising:one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 acting as input unit configured to receive an input of a plurality of image frames having different capturing times;the one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 acting as 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 unit configured to calculate differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andthe one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 acting as a detect unit configured to detect a first region in an image frame in which a difference between the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a first threshold, and a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than second threshold times a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. The detection system according to claim 1, whereinthe first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have a different time span of capturing of image frames to be considered.3. The detection system according to claim 1, whereinThe one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 acting as detect unit detects a second region in the image frame in which a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a third threshold.4. The detection system according to claim 1, the one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further acting as output unit configured to output the first region and the second region by discriminating them.5. The detection system according to claim 1, whereinan influence of an image frame at the processing time in the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is changeable.6. The detection system according to claim 5, whereinan influence that the first region in an image frame at the processing time has on the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is smaller than an influence that other regions have on the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.7. A detection method by a computer, comprising:receiving an input of a plurality of image frames having different capturing times;calculating differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in an image frame in which a difference between the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a first threshold, and a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third 
<a href="https://en.wikipedia.org/wiki/Human_back"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    back
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
ground 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than second threshold times a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. A computer-readable non-transitory 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for storing a program causing a computer to execute function of:receiving an input of a plurality of image frames having different capturing times;calculating differences between a first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 generated based on an image frame at the time of processing, a second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and a third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in which an influence of an image frame at the time of processing is smaller than that of the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a first region in an image frame in which a difference between the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a first threshold, and a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the third 
<a href="https://en.wikipedia.org/wiki/Human_back"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    back
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
ground 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than second threshold times a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.9. The detection system according to claim 2, whereinthe one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 acting as detect unit detects a second region in the image frame in which a difference between the first background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is not less than a third threshold.10. The detection system according to claim 2, the one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further acting as output unit configured to output the first region and the second region by discriminating them.11. The detection system according to claim 3, the one or more 
<a href="https://en.wikipedia.org/wiki/Central_processing_unit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 further acting as output unit configured to output the first region and the second region by discriminating them.12. The detection system according to claim 2, whereinan influence of an image frame at the processing time in the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is changeable.13. The detection system according to claim 3, whereinan influence of an image frame at the processing time in the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is changeable.14. The detection system according to claim 4, whereinan influence of an image frame at the processing time in the second background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is changeable._______________OBJECT DETECTION DEVICE AND OBJECT DETECTION METHOD_____20180719_____XMLs/xml/ipa180719.xml_____US-20180204333-A1 : US-15744026 : WO-PCT/JP2015/083880-00_____G06T0007254000 : G06K0009000000 : G06T0007110000An object detection device includes: an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator to calculate an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured by the image capturer at different times; an evaluation value calculator to divide the image captured by the image capturer into 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and calculate, for each divided area, an evaluation value by using the optical flows of pixels belonging to the divided area, the evaluation value indicating a measure of a possibility that the divided area is an object area representing part or whole of the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and an area determinator to determine an area in an image, in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by comparing the evaluation value of each divided area calculated by the evaluation value calculator with a 
<a href="https://en.wikipedia.org/wiki/Threshold_limit_value"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    threshold value
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:TECHNICAL FIELDThe present invention relates to an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device and an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an area in an image, in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists.BACKGROUND ARTProcessing of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an object, such as a person or a car, from an image captured by a camera is an important technology 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to a 
<a href="https://en.wikipedia.org/wiki/Vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for robot or 
<a href="https://en.wikipedia.org/wiki/Vehicle"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    vehicle
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, an image 
<a href="https://en.wikipedia.org/wiki/System_monitor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    monitoring system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, or the like.In 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a desired object, discrimination processing, such as 
<a href="https://en.wikipedia.org/wiki/Pattern_recognition"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pattern recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing based on 
<a href="https://en.wikipedia.org/wiki/Machine_learning"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    machine learning
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, is often used.Specifically, a window that indicates a local area having an appropriate size is cut out from frames of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 continuously captured by a camera, discrimination processing, such as 
<a href="https://en.wikipedia.org/wiki/Pattern_recognition"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pattern recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing, for the image in the 
<a href="https://en.wikipedia.org/wiki/Wind"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    wind
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
ow is executed, and it is determined whether an object exists within the window. By these processing, an area in the image in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.It is known that the discrimination processing, such as the 
<a href="https://en.wikipedia.org/wiki/Pattern_recognition"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pattern recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing, has a large amount of operation. In general, a position where an object exists in each frame of an image and a size of the object are unknown. Therefore, the discrimination processing, such as the 
<a href="https://en.wikipedia.org/wiki/Pattern_recognition"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pattern recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 processing, is continuously executed while slightly changing the size and the position of the window.For the reason above, an enormous number of times of discrimination processing is needed per frame, resulting in an enormous operation amount.In Patent Literature 1 below, in order to decrease the number of times of discrimination processing to reduce the operation amount, an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device is disclosed, which detects in advance pixels indicating large luminance change in a time direction as an object area and exclusively uses the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object area as a target for the discrimination processing.CITATION LISTPatent Literature 1JP 2007-18324 A (paragraph [0008], FIG. 1)SUMMARY OF INVENTIONSince the conventional 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device is configured as described above, the processing time to detect the object can be shortened by reducing the operation amount. However, such operation is premised on the condition where the camera remains stationary when capturing an image. The conventional 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device cannot be 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to an image captured by a camera that is moving at the time of capture, like a camera mounted in a moving 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 such as a robot or an automobile, or a 
<a href="https://en.wikipedia.org/wiki/Hand"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hand
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
-held camera. Therefore, there is a problem that an area in an image, in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, cannot be accurately 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the image which is captured while moving.The present invention has been made to solve the above-described problem, and an object thereof is to provide an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device and an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, each being capable of accurately 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an area in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, even from an image captured while moving.An object detection device according to the present invention is provided with an image capturer to continuously capture 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator to calculate an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured by the image capturer at different times; and an object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect, by using the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculated by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator, an area in an image, in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists.According to the present invention, the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator to calculating an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured by an image capturer at different times is provided, and the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detects an area in an image in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists by using the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculated by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator. Therefore, there is an effect to accurately detect the area in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists from an image captured by the image capturer while moving.BRIEF DESCRIPTION OF DRAWINGSFIG. 1 is a structural diagram illustrating an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to Embodiment 1 of the present invention.FIG. 2 is a 
<a href="https://en.wikipedia.org/wiki/Open-source_hardware"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hardware structural
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagram illustrating the object detection device according to the Embodiment 1 of the present invention.FIG. 3 is a 
<a href="https://en.wikipedia.org/wiki/Open-source_hardware"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hardware structural
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagram, where an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator 2 and an object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 3 are realized by a computer.FIG. 4 is a flowchart illustrating processing contents of the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator 2 and the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 3.FIG. 5 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 example of optical flows and an 
<a href="https://en.wikipedia.org/wiki/Aggregation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    aggregation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 example of optical flows in a spatial direction.FIG. 6 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example in which spatial sets of optical flows are aggregated in a time direction.FIG. 7 is a structural diagram illustrating an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to Embodiment 2 of the present invention.FIG. 8 is a 
<a href="https://en.wikipedia.org/wiki/Open-source_hardware"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hardware structural
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagram illustrating the object detection device according to the Embodiment 2 of the present invention.FIG. 9 is a flowchart illustrating processing contents of an area determinator 6 in an object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 3.FIG. 10 is a flowchart illustrating processing contents of an area corrector 7.FIG. 11 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a setting example of 
<a href="https://en.wikipedia.org/wiki/Google_Search"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 window performed by the area determinator 6.FIG. 12 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating relation between 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 windows and 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 13 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating processing of the area determinator 6 for determining whether an object exists in 
<a href="https://en.wikipedia.org/wiki/Google_Search"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 window while shifting a position of the 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 window.FIG. 14 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a case where a size and a position of an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 cannot be accurately grasped even by reference to longitudinal/
<a href="https://en.wikipedia.org/wiki/Lateral"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    lateral
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 sizes and positional coordinates of a rectangle output by the area determinator 6.FIG. 15 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a setting example of 
<a href="https://en.wikipedia.org/wiki/Google_Search"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    a search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 window by the area corrector 7.FIG. 16 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of an edge image.FIG. 17 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating relation between 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 windows and edge density.FIG. 18 is a structural diagram illustrating an 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to Embodiment 3 of the present invention.FIG. 19 is a 
<a href="https://en.wikipedia.org/wiki/Open-source_hardware"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    hardware structural
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagram illustrating the object detection device according to the Embodiment 3 of the present invention.FIG. 20 is a flowchart illustrating processing contents of an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 predictor 36.FIG. 21 is a flowchart illustrating processing contents of an evaluation value calculator 37 and an area determinator 38 in an object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 3.FIG. 22 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of optical flows obtained by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 predictor 36, which depends on 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a camera 11 and a spatial shape captured by the camera 11.FIG. 23 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of optical flows calculated by an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator 2.FIG. 24 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a difference between optical flows output by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator 2 and optical flows output by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 predictor 36._____c:1-11. (canceled)12. An 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device comprising:an image capturer to continuously capture 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator to calculate, for each pixel constituting the image, an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured by the image capturer at different times; andan object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to aggregate the optical flows calculated by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator in a spatial direction and a time direction and detect an area in an image, in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by using difference absolute values of arbitrary two optical flows,wherein the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes:an evaluation value calculator todivide the image captured by the image capturer into one or more 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,calculate, for each divided area, a total of difference absolute values of angles of the optical flows and a total of difference absolute values of lengths of the optical flows of the pixels belonging to a corresponding divided area, andcalculate, for each divided area, an evaluation value of a corresponding divided area by using the total of difference absolute values of the angles and the total of difference absolute values of the lengths, the evaluation value indicating a measure of a possibility that the corresponding divided area is an object area representing part or whole of the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andan area determinator to determine an area in an image, in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by comparing the evaluation value of each divided area calculated by the evaluation value calculator with a 
<a href="https://en.wikipedia.org/wiki/Threshold_limit_value"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    threshold value
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The object detection device according to claim 12, further comprising an area corrector to correct the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,wherein the area connection unit is configured tocalculate an image characteristic amount in the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and an image characteristic amount in an area obtained by changing a position and a size of the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 area, and compare the calculated image characteristic amounts, andselect, as a 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 area for the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, any one among the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the changed area on a basis of a comparison result of the image characteristic amounts.14. An 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device comprising:an image capturer to continuously capture 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator to calculate, for each pixel constituting the image, an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured by the image capturer at different times; andan object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to aggregate the optical flows calculated by the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 calculator in a spatial direction and a time direction and detect an area in an image, in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by using difference absolute values of arbitrary two optical flows,wherein the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes:an evaluation value calculator todivide the image captured by the image capturer into one or more 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,calculate, for each divided area, a total of difference absolute values of angles of the optical flows and a total of difference absolute values of lengths of the optical flows of the pixels belonging to a corresponding divided area, andcalculate, for each divided area, an evaluation value of a corresponding divided area by using the total of difference absolute values of the angles and the total of difference absolute values of the lengths, the evaluation value indicating a measure of a possibility that the corresponding divided area is an object area representing part or whole of the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andan area determinator to determine an area in an image, in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by searching for an area in which the evaluation value of each divided area calculated by the evaluation value calculator indicates a maximum in the image.15. An 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method comprising:continuously capturing 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;calculating, for each pixel constituting the image, an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured at different times; andaggregating the calculated optical flows in a spatial direction and a time direction and 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an area in an image in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by using difference absolute values of arbitrary two optical flows,dividing the captured image into one or more 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,calculating, for each divided area, a total of difference absolute values of angles of the optical flows and a total of difference absolute values of lengths of the optical flows of the pixels belonging to a corresponding divided area,calculating, for each divided area, an evaluation value of a corresponding divided area by using the total of difference absolute values of the angles and the total of difference absolute values of the lengths, the evaluation value indicating a measure of a possibility that the corresponding divided area is an object area representing part or whole of the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermining an area in an image, in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by comparing the evaluation value of each divided area with a 
<a href="https://en.wikipedia.org/wiki/Threshold_limit_value"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    threshold value
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. An 
<a href="https://en.wikipedia.org/wiki/Object_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method comprising:continuously capturing 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;calculating, for each pixel constituting the image, an optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 between 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured at different times; andaggregating the calculated optical flows in a spatial direction and a time direction and 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 an area in an image in which an object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by using difference absolute values of arbitrary two optical flows,dividing the captured image into one or more 
<a href="https://en.wikipedia.org/wiki/Area"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    areas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,calculating, for each divided area, a total of difference absolute values of angles of the optical flows and a total of difference absolute values of lengths of the optical flows of the pixels belonging to a corresponding divided area,calculating, for each divided area, an evaluation value of a corresponding divided area by using the total of difference absolute values of the angles and the total of difference absolute values of the lengths, the evaluation value indicating a measure of a possibility that the corresponding divided area is an object area representing part or whole of the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermining an area in an image, in which the object to be 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exists, by searching for an area in which the evaluation value of each divided area indicates a maximum in the image.17. The object detection device according to claim 14, further comprising an area corrector to correct the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,wherein the area connection unit is configured tocalculate an image characteristic amount in the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and an image characteristic amount in an area obtained by changing a position and a size of the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 area, and compare the calculated image characteristic amounts, andselect, as a 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 area for the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, any one among the area 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by the object 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the changed area on a basis of a comparison result of the image characteristic amounts._______________OBJECT EXTRACTION FROM VIDEO IMAGES SYSTEM AND METHOD_____20180726_____XMLs/xml/ipa180726.xml_____US-20180211397-A1 : US-15934787 : US-15470477 : US-9959632 : US-15934787 : US-14525181 : US-9639954 : US-15470477_____G06T0007254000 : G06K0009460000 : G06T0007194000 : G06T0007215000 : G06K0009000000A computer implemented method of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method comprising steps a computer is programmed to perform, the steps comprising: receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and extracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences._____d:CROSS-REFERENCE TO RELATED APPLICATIONSThis application is a continuation of U.S. patent application Ser. No. 15/470,477, filed Mar. 27, 2017, which is a continuation of U.S. patent application Ser. No. 14/525,181, filed Oct. 27, 2014, now U.S. Pat. No. 9,639,954, issued May 2, 2017, each of which is hereby incorporated in its entirety including all tables, figures, and claims.FIELD AND BACKGROUND OF THE INVENTIONThe present invention relates to 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and, more particularly, but not exclusively to extracting 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 captured during a sport event.In recent years, the use of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 has been gaining more and more popularity in a variety of fields and industries. Some known 
<a href="https://en.wikipedia.org/wiki/Industrial"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    industrial
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 include, for example, security 
<a href="https://en.wikipedia.org/wiki/Surveillance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    surveillance systems
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, operational 
<a href="https://en.wikipedia.org/wiki/Management_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    management systems
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (say in a 
<a href="https://en.wikipedia.org/wiki/Retail"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    retail industry
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 environment), tactical battlefield systems, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.The 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is an aspect of 
<a href="https://en.wikipedia.org/wiki/Video_content_analysis"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video analysis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.One of the techniques widely used in the fields of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is a technique in which an image's foreground is extracted for further processing, usually for recognition of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest.Generally, an image's foreground is made of regions of the image, which are occupied by 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of interest (humans, cars, text, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.). After a stage of image 
<a href="https://en.wikipedia.org/wiki/Preprocessing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    preprocessing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (which may include image noise removal, 
<a href="https://en.wikipedia.org/wiki/Morphology"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    morphology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based analysis, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.), object 
<a href="https://en.wikipedia.org/wiki/Localization"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    localization
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be required, which object 
<a href="https://en.wikipedia.org/wiki/Localization"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    localization
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may make use of background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is widely used for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (say cars or pedestrians) in videos, from static cameras, the rationale being one of 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from the difference between the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame and a reference 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, also referred to as “background image” or “background 
<a href="https://en.wikipedia.org/wiki/Model"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    model
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
”, which is made of static 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 such as a building or a traffic 
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 positioned at a road intersection.Objection 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is often done if the image in question is a part of a 
<a href="https://en.wikipedia.org/wiki/Streaming_media"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video stream
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Background 
<a href="https://en.wikipedia.org/wiki/Subtraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 provides important cues for numerous 
<a href="https://en.wikipedia.org/wiki/Application"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applications
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in 
<a href="https://en.wikipedia.org/wiki/Computer_vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example surveillance tracking or 
<a href="https://en.wikipedia.org/wiki/Human"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    human
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 poses estimation.SUMMARY OF THE INVENTIONAccording to one aspect of the present invention there is provided a computer implemented method of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method comprising steps a computer is programmed to perform, the steps comprising: receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and extracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.According to a second aspect of the present invention there is provided an apparatus for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the apparatus comprising: a computer, a 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receiver, implemented on the computer, configured to receive a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 deriver, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 receiver, configured to derive a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a difference calculator, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 deriver, configured to calculate a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual video image and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and an object extractor, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with the difference calculator, configured to extract an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.According to a third aspect of the present invention there is provided a non-transitory 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium storing computer executable instructions for performing steps of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the steps comprising: receiving a plurality of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, deriving a plurality of background templates from at least one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, calculating a plurality of differences from an individual one of the received 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, each one of the differences being calculated between the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a respective and different one of the 
<a href="https://en.wikipedia.org/wiki/Background_radiation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background templates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and extracting an object of interest from the individual 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.Unless otherwise defined, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs.The materials, 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and examples provided herein are illustrative only and not intended to be limiting. Implementation of the method and system of the present invention involves performing or completing certain selected tasks or steps manually, automatically, or a combination thereof.Moreover, according to actual instrumentation and equipment of preferred embodiments of the method and system of the present invention, several selected steps could be implemented by hardware or by software on any 
<a href="https://en.wikipedia.org/wiki/Operating_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    operating system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of any firmware or a combination thereof.For example, as hardware, selected steps of the invention could be implemented as a chip or a circuit. As software, selected steps of the invention could be implemented as a plurality of software instructions being executed by a computer using any suitable 
<a href="https://en.wikipedia.org/wiki/Operating_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    operating system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. In any case, selected steps of the method and system of the invention could be described as being performed by a 
<a href="https://en.wikipedia.org/wiki/Data_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data processor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such as a 
<a href="https://en.wikipedia.org/wiki/Computing_platform"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computing platform
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for executing a plurality of instructions.BRIEF DESCRIPTION OF THE DRAWINGSThe invention is herein described, by way of example only, with reference to the accompanying drawings. With specific reference now to the drawings in detail, it is stressed that the particulars shown are by way of example and for purposes of illustrative discussion of the preferred embodiments of the present invention only, and are presented in order to provide what is believed to be the most useful and readily understood description of the principles and conceptual aspects of the invention. The description taken with the drawings making apparent to those skilled in the art how the several forms of the invention may be embodied in practice.In the drawings:FIG. 1 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 schematically illustrating an exemplary apparatus for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIG. 2 is a simplified flowchart schematically illustrating a first exemplary method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIG. 3 is a simplified flowchart schematically illustrating a second exemplary method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIGS. 4A-4H are simplified 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagrams schematically illustrating a first implementation scenario, according to an exemplary embodiment of the present invention.FIG. 4A illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4B illustrates a player who stands in a right position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4C is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It does not include the image of a player.FIG. 4D is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in the 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 4E illustrates a player standing in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 4F illustrates a player who stands next to one or more trees and the sun coming out from behind a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4G is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 4H illustrates a player who stands next to one or more trees, with the sun coming out from behind a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 5 is a simplified flowchart schematically illustrating a third exemplary method for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention.FIGS. 6A-6O are simplified 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 diagrams schematically illustrating a second implementation scenario, according to an exemplary embodiment of the present invention.FIG. 6A illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6B illustrates a player stands in a right position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6C illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.FIG. 6D is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It does not include the image of a player.FIG. 6E is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in the right position.FIG. 6F illustrates a player standing in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6G is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in the right position and a player in the 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6H illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6I illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and the sun.FIG. 6J illustrates a player who stands in a right position next to one or more trees and the sun.FIG. 6K is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It does not include the image of a player.FIG. 6L illustrates a player who stands in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position next to one or more trees and the sun.FIG. 6M illustrates a player who stands in a right position next to one or more trees and the sun.FIG. 6N is a 
<a href="https://en.wikipedia.org/wiki/Template_matching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background template
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 containing one or more trees and a 
<a href="https://en.wikipedia.org/wiki/Cloud"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cloud
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. It also includes the image of a player in a right position and a player in a 
<a href="https://en.wikipedia.org/wiki/Left"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    left
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position.FIG. 6O shows a player standing in a right position.FIG. 7 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 schematically illustrating an exemplary 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium storing computer executable instructions for performing steps of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present invention._____c:1. A computer implemented method of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the method comprising steps a computer is programmed to perform, the steps comprising:receiving a plurality of background templates and at least one image;calculating a plurality of differences for an individual one of the received at least one image, each one of the differences being calculated between the individual image and a respective one of the received background templates; andextracting an object of interest from the individual image, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.2. The method of claim 1, further comprising selecting the rule among a plurality of predefined rules.3. The method of claim 1, further comprising allowing a user to define the rule.4. The method of claim 1, further comprising selecting the rule according to circumstances of capturing of the received at least one image.5. The method of claim 1, further comprising selecting the rule according to a characteristic pertaining to the object of interest.6. The method of claim 1, further comprising selecting the rule according to a characteristic pertaining to a background of the received at least one image.7. The method of claim 1, wherein each one of at least two of the received background templates is a template derived using a respective and different one of a plurality of background 
<a href="https://en.wikipedia.org/wiki/Calculation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    calculation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. The method of claim 1, wherein each one of at least two of the received background templates is a template derived using a respective and at least partially different subset of the received at least one image.9. The method of claim 1, wherein each one of at least two of the received background templates is a template derived using a respective and at least partially less recent subset of the received at least one image.10. The method of claim 1, wherein each one of at least two of the received background templates is a template derived using a respective and different frequency of sampling of the received at least one image.11. The method of claim 1, wherein each one of at least two of the received background templates is a template derived using a respective and different in size subset of the received at least one image.12. The method of claim 1, further comprising updating each one of at least two of the received background templates, with a respective and different update rate.13. Apparatus for object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the apparatus comprising:a computer;a difference calculator, configured to receive a plurality of background templates and at least one image and calculate a plurality of differences for an individual one of the received at least one image, each one of the differences being calculated between the individual image and a respective one of the received background templates; andan object extractor, in 
<a href="https://en.wikipedia.org/wiki/Communication"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    communication
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with said difference calculator, configured to extract an object of interest from the individual image, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences.14. A non-transitory 
<a href="https://en.wikipedia.org/wiki/Machine-readable_medium"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer readable
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 medium storing computer executable instructions for performing steps of object 
<a href="https://en.wikipedia.org/wiki/Extraction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    extraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the steps comprising:receiving a plurality of background templates and at least one image;calculating a plurality of differences for an individual one of the received at least one image, each one of the differences being calculated between the individual image and a respective one of the received background templates; andextracting an object of interest from the individual image, using a rule 
<a href="https://en.wikipedia.org/wiki/Applied_arts"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    applied
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the calculated differences._______________SYSTEM AND METHOD 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 TRACKING MULTIPLE OBJECTS_____20180816_____XMLs/xml/ipa180816.xml_____US-20180232891-A1 : US-15662738 : KR-10-2017-0019427_____G06T0007254000 : G06T0007246000 : G06K0009000000 : G06K0009320000The present invention relates to a system for tracking an object. The system includes an image capturing unit configured to capture a video of a predetermined observation area and output the captured video; and a multi-object tracker configured to output an object-tracking image by tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 within an object image which is generated by extracting the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of image frames obtained from the video obtained from the image capturing unit, wherein the multi-object tracker determines whether occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or hijacking occurs while performing multi-object tracking, and when it is determined that at least one of the occlusion and hijacking occurs, the multi-object tracker outputs the object-tracking image 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing the occurring occlusion or hijacking._____d:CROSS-REFERENCE TO RELATED APPLICATIONThis application claims priority to and the benefit of Korean Patent Application No. 10-2017-0019427, filed on Feb. 13, 2017, the disclosure of which is incorporated herein by reference in its entirety.BACKGROUND1. Field of the InventionThe present invention relates to an object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and more particularly, to a system and method for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. Discussion of Related ArtIn the sports and 
<a href="https://en.wikipedia.org/wiki/Federal_Security_Service"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    security service
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 fields, a service capable of accurately tracking multiple target 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 (e.g., people) and providing information about the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by analyzing 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained through camera tracking on the target objects is provided.In the case where multiple target 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are tracked to provide the information about the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, there may be problems of occlusion among 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and hijacking which causes a target object to be changed (i.e., causes another object to be tracked) due to the similarities between the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Therefore, there is a need for an approach that prevents an object tracking error due to occlusion of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and hijacking that 
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 another target object.SUMMARY OF THE INVENTIONTherefore, the present invention is devised to solve the aforementioned problems, and the objective of the present invention is to provide a system and method for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, which is capable of providing accurate information about a tracked object by handling occlusion of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and hijacking which may occur when multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are tracked simultaneously.In one general aspect, there is provided a system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including: an image capturing unit configured to capture a video of a predetermined observation area and output the captured video; and a multi-object tracker configured to output an object-tracking image by tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 within an object image which is generated by extracting the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of image frames obtained from the video obtained from the image capturing unit, wherein the multi-object tracker determines whether occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or hijacking occurs while performing multi-object tracking, and when it is determined that at least one of the occlusion and the hijacking occurs, the multi-object tracker outputs the object-tracking image 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing the occurring occlusion or hijacking.The multi-object tracker may output a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the hijacking do not occur.When a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be occluded by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object, the multi-object tracker may determine that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs.When it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs, the multi-object tracker may estimate a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and remove 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for a target object from the object image.The multi-object tracker may determine a depth order of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the basis of the estimated bounding boxes and depths of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, recognize at least one of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in front of and behind the target object on the basis of the determined depth order of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and remove the recognized object.When a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be identical to a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object for a predetermined time period, the multi-object tracker may determine that the hijacking occurs.When it is determined that the hijacking occurs, the multi-object tracker may remove an object being actually tracked by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object from the object image so that the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the target object.The multi-object tracker may generate a reference background image by modeling a reference background using a reference background 
<a href="https://en.wikipedia.org/wiki/Video_modeling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    modeling video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained from the image capturing unit and generate the object image by extracting the objects from each of the image frames on the basis of comparison between the reference background image and each of the image frames obtained from a video for object tracking obtained from the image capturing unit.The multi-object tracker may obtain a color difference by comparing colors of the reference background image and each of the image frames, and extract the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of the image frames on the basis of the obtained color difference.When the generated object image is an initial object image, the multi-object tracker may allocate a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to initialize multi-object tracking and perform the multi-object tracking.In another general aspect, there is provided a method of tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including: generating a reference background image by modeling a reference background using a reference background 
<a href="https://en.wikipedia.org/wiki/Video_modeling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    modeling video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained from an image capturing unit; generating an object image by extracting 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of image frames on the basis of comparison between the reference background image and each of the image frames obtained from a video for object tracking obtained from the image capturing unit; and outputting a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image or a 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image according to a result of determination on whether occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or hijacking occurs, while performing multi-object tracking on the basis of the object image.Whether the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs may be determined on the basis of detection of whether a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is occluded by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object.Whether the hijacking occurs may be determined on the basis of detection of whether a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is identical to a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object.The outputting of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image may be performed when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the hijacking do not occur.When it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs, the outputting of the 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image may be performed wherein the object-tracking image may be 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for a target object from the object image by estimating a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.When it is determined that the hijacking occurs, the outputting of the 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image may be performed wherein the object-tracking image may be 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing an object being actually tracked by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object from the object image so that the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the target object.When it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the hijacking occur, the outputting of the 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image may be performed wherein the object-tracking image may be 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for a ta
<a href="https://en.wikipedia.org/wiki/Television_in_Spain"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    rget
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object from the object image by estimating a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and is 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 also by removing an object being actually tracked by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target object from the object image so that the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the target object.The removing of the object other than the target object from the object image by estimating the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include determining a depth order of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the basis of the estimated bounding boxes and depths of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at least one of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in front of and behind the target object on the basis of the determined depth order, and removing the recognized object.The generating of the object image may include obtaining a color difference by comparing colors of the reference background image and each of the image frames and extracting the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of the image frames on the basis of the obtained color difference.When initial multi-object tracking is performed, the performing of the multi-object tracking on the basis of the object image may include allocating a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to initialize the multi-object tracking and then performing the multi-object tracking.BRIEF DESCRIPTION OF THE DRAWINGSThe above and other 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, 
<a href="https://en.wikipedia.org/wiki/Feature"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    features
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and advantages of the present invention will become more apparent to those of ordinary skill in the art by describing exemplary embodiments thereof in detail with reference to the accompanying drawings, in which:FIG. 1 is a diagram illustrating a configuration of a system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to an exemplary embodiment of the present invention;FIG. 2 is a flowchart illustrating operations of the system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the exemplary embodiment of the present invention;FIGS. 3A and 3B are flowcharts illustrating an operation of outputting an object-tracking image performed by the system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the exemplary embodiment of the present invention in detail;FIG. 4A is a picture showing an example of a video input to a multi-object tracker in one embodiment of the present invention;FIG. 4B is a picture showing an example of a reference background image modeled by the multi-object tracker in the embodiment of the present invention;FIG. 4C is a picture showing an example of an object image extracted from the input video by the multi-object tracker in the embodiment of the present invention;FIG. 5 is a picture for describing a method of determining whether hijacking occurs according to an embodiment of the present invention;FIG. 6A is a picture showing an example of an original video input to the multi-object tracker in the embodiment of the present invention;FIG. 6B is a picture showing an image in which hijacking occurs in the embodiment of the present invention;FIG. 6C is a picture showing an image from which the hijacking is removed in the embodiment of the present invention;FIG. 7A shows an example in which occlusion of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs in the embodiment of the present invention;FIG. 7B shows an example in which the occlusion is removed in the embodiment of the present invention;FIG. 8 is a table for comparing center location errors of the system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the embodiment of the present invention and a conventional object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 9 is a table for comparing success rates of the system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the embodiment of the present invention and the conventional object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andFIG. 10 is a table for comparing multi-object tracking times of the system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to the embodiment of the present invention and the conventional object 
<a href="https://en.wikipedia.org/wiki/Tracking_system"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracking system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____c:1. A system for tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, comprising:an image capturing unit configured to capture a video of a predetermined observation area and output the captured video; anda multi-object tracker configured to output an object-tracking image by tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 within an object image which is generated by extracting the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of image frames obtained from the video obtained from the image capturing unit,wherein the multi-object tracker determines whether occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or hijacking occurs while performing multi-object tracking, and when it is determined that at least one of the occlusion and the hijacking occurs, the multi-object tracker outputs the object-tracking image 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing the occurring occlusion or hijacking.2. The system of claim 1, wherein the multi-object tracker outputs a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the hijacking do not occur.3. The system of claim 1, wherein, when a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be occluded by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object, the multi-object tracker determines that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs.4. The system of claim 1, wherein, when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs, the multi-object tracker estimates a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and removes 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for a target object from the object image.5. The system of claim 4, wherein the multi-object tracker determines a depth order of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the basis of the estimated bounding boxes and depths of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, recognizes at least one of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in front of and behind the target object on the basis of the determined depth order of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and removes the recognized object.6. The system of claim 1, wherein, when a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be identical to a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object for a predetermined time period, the multi-object tracker determines that the hijacking occurs.7. The system of claim 1, wherein, when it is determined that the hijacking occurs, the multi-object tracker removes an object being actually tracked by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object from the object image so that the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracks the target object.8. The system of claim 1, wherein the multi-object tracker generates a reference background image by modeling a reference background using a reference background 
<a href="https://en.wikipedia.org/wiki/Video_modeling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    modeling video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained from the image capturing unit and generates the object image by extracting the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of the image frames on the basis of comparison between the reference background image and each of the image frames obtained from a video for object tracking obtained from the image capturing unit.9. The system of claim 8, wherein the multi-object tracker obtains a color difference by comparing colors of the reference background image and each of the image frames, and extracts the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of the image frames on the basis of the obtained color difference.10. The system of claim 1, wherein, when the generated object image is an initial object image, the multi-object tracker allocates a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to initialize multi-object tracking and performs the multi-object tracking.11. A method of tracking multiple 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, comprising:generating a reference background image by modeling a reference background using a reference background 
<a href="https://en.wikipedia.org/wiki/Video_modeling"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    modeling video
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained from an image capturing unit;generating an object image by extracting 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of image frames on the basis of comparison between the reference background image and each of the image frames obtained from a video for object tracking obtained from the image capturing unit; andoutputting a 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image or a 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image according to a result of determination on whether occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or hijacking occurs, while performing multi-object tracking on the basis of the object image.12. The method of claim 11, wherein whether the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs is determined on the basis of detection of whether a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is occluded by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object.13. The method of claim 11, wherein whether the hijacking occurs is determined on the basis of detection of whether a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object is identical to a displacement of a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of another object.14. The method of claim 11, wherein the outputting of the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image is performed when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the hijacking do not occur.15. The method of claim 11, wherein, when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 occurs, the outputting of the 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image is performed wherein the object-tracking image is 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for a target object from the object image by estimating a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. The method of claim 11, wherein, when it is determined that the hijacking occurs, the outputting of the 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image is performed wherein the object-tracking image is 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing an object being actually tracked by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a target object from the object image so that the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the target object.17. The method of claim 11, wherein, when it is determined that the occlusion of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the hijacking occur, the outputting of the 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 object-tracking image is performed wherein the object-tracking image is 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by removing 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for a target object from the object image by estimating a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and is 
<a href="https://en.wikipedia.org/wiki/Correctness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    corrected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 also by removing an object being actually tracked by a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target object from the object image so that the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Track"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    tracks
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the target object.18. The method of claim 15, wherein the removing of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 except for the target object from the object image by estimating the bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and depth of each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes determining a depth order of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the basis of the estimated bounding boxes and depths of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at least one of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in front of and behind the target object on the basis of the determined depth order, and removing the recognized object.19. The method of claim 11, wherein the generating of the object image includes obtaining a color difference by comparing colors of the reference background image and each of the image frames and extracting the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from each of the image frames on the basis of the obtained color difference.20. The method of claim 11, wherein, when initial multi-object tracking is performed, the performing of the multi-object tracking on the basis of the object image includes allocating a bounding 
<a href="https://en.wikipedia.org/wiki/Box"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    box
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to each of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to initialize the multi-object tracking and then performing the multi-object tracking._______________SYSTEM AND METHOD 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 DETECTING MOVING OBJECT IN AN IMAGE_____20180913_____XMLs/xml/ipa180913.xml_____US-20180260964-A1 : US-15917565 : CN-201710137069.2_____G06T0007254000 : G06K0009620000 : G06K0009380000 : G06K0009460000A moving object detection method and apparatus are disclosed. The method may include: obtaining a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; determining a difference of the first image and the second image; performing a binarization operation on the difference of the first image and the second image, to generate a binary image; determining the number of pixels whose values are nonzero in each column of the binary image, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:CROSS-REFERENCE TO RELATED APPLICATIONThis application is based upon and claims priority from Chinese Patent Application No. 201710137069.2, filed on Mar. 9, 2017, the disclosure of which is expressly incorporated herein by reference in its entirety.TECHNICAL FIELDThe present disclosure generally relates to 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 technology, and more specifically to a system and method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image.BACKGROUNDIn the field of 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the use of 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 technology can automatically detect 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 scenes in videos, which can reduce the 
<a href="https://en.wikipedia.org/wiki/Cost"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    cost
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of manual monitoring and increase monitoring efficiency and 
<a href="https://en.wikipedia.org/wiki/Effectiveness"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    effectiveness
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. As the foundat
<a href="https://en.wikipedia.org/wiki/Ion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    ion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Sound_recording_and_reproduction"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recording technology
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and an important component of smart video cameras, 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 technology has been embedded into the camera firmware of an increasing number of smart video cameras.There are three types of conventional 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
: the 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, the inter-frame difference method, and the 
<a href="https://en.wikipedia.org/wiki/Foreground_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method. In the 
<a href="https://en.wikipedia.org/wiki/Optical_flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    optical flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, each pixel point in the image is assigned a velocity vector to form an 
<a href="https://en.wikipedia.org/wiki/Film"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 field; at a given moment of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the points in the image have a one-to-one relationship with the points on the three-dimensional object, and this relationship can be obtained from the projection relationship; a dynamic analysis on the image can be performed based on the characteristics of the 
<a href="https://en.wikipedia.org/wiki/Velocity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    velocity vector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of each pixel point. If no moving object is present in the image, then the optical 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector would change continuously across the entire image area; when a moving object is present in the image, the target and the image background would move relative to one another, so the 
<a href="https://en.wikipedia.org/wiki/Velocity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    velocity vector
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the moving object is inevitably different from the 
<a href="https://en.wikipedia.org/wiki/Velocity"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    velocity
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector of the adjacent background area; thus, the moving object and its location are 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Image difference 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are relatively straightforward and easy to implement. Therefore, these 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 have now become the most widely used to detect moving targets. There are two types of 
<a href="https://en.wikipedia.org/wiki/Image_differencing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image difference
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
: the 
<a href="https://en.wikipedia.org/wiki/Foreground_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method and the inter-frame difference method. The 
<a href="https://en.wikipedia.org/wiki/Foreground_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method compares the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 frame against the background reference model in a series of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to detect moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and its 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 depends on the background modeling technology used. The inter-frame difference method performs a difference operation on two or three adjacent frames in a series of video 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to obtain the contour of a moving target.However, the image difference 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the 
<a href="https://en.wikipedia.org/wiki/Foreground_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    background subtraction
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method and the inter-frame difference method, are highly sensitive to interference 
<a href="https://en.wikipedia.org/wiki/Factor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    factors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that cause changes in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, lighting, plants swinging in the wind, 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. For example, in a night 
<a href="https://en.wikipedia.org/wiki/Vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 environment, a flying insect may lead to changes in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Since conventional 
<a href="https://en.wikipedia.org/wiki/Motion_detection"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion detection
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 algorithms are highly sensitive to interference 
<a href="https://en.wikipedia.org/wiki/Factor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    factors
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that cause changes in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 detection alarm is triggered once a change in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. However, this type of alarm is not desired; in other words, it is a false 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 alarm. Therefore, there is a need to detect and identify moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, for example, flying insects, in a night 
<a href="https://en.wikipedia.org/wiki/Vision"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    vision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 environment to avoid false 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 alarms.The disclosed 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and systems address one or more of the problems listed above.SUMMARYConsistent with one embodiment of the present disclosure, a method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image is provided. The method may include: obtaining a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; determining a difference of the first image and the second image; performing a binarization operation on the difference of the first image and the second image, to generate a binary image; determining the number of pixels whose values are nonzero in each column of the binary image, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Consistent with another embodiment of the present disclosure, an apparatus for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image is provided. The apparatus includes a memory storing instructions. The apparatus also includes a processor configured to execute the instructions to: obtain a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; determine a difference of the first image and the second image; perform a binarization operation on the difference of the first image and the second image, to generate a binary image; determine the number of pixels whose values are nonzero in each column of the binary image, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and determine whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Consistent with 
<a href="https://en.wikipedia.org/wiki/Yet_another"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    yet another
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 embodiment of the present disclosure, a non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is provided. The medium stores instructions that, when executed by a processor, cause the processor to perform a method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image. The method may include: obtaining a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; determining a difference of the first image and the second image; performing a binarization operation on the difference of the first image and the second image, to generate a binary image; determining the number of pixels whose values are nonzero in each column of the binary image, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory only and are not restrictive of the invention, as claimed.DESCRIPTION OF DRAWINGSThe accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments consistent with the present disclosure and, together with the description, serve to explain the principles of the 
<a href="https://en.wikipedia.org/wiki/Pre"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pre
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
sent disclosure.FIG. 1 is a flowchart of a method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image, according to an exemplary embodiment of the present disclosure.FIG. 2 is a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating spatial relationships between pixel p and its adjacent pixels in an erosion operation, according to an exemplary embodiment of the present disclosure.FIG. 3 is a flowchart of a method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image, according to an exemplary embodiment of the present disclosure.FIG. 4 is a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a binary image, according to an exemplary embodiment of the present disclosure.FIG. 5 is a 
<a href="https://en.wikipedia.org/wiki/Schematic"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    schematic diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, according to an exemplary embodiment of the present disclosure.FIG. 6 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a device for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image, according to an exemplary embodiment of the present disclosure.FIG. 7 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a device for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image, according to an exemplary embodiment of the present disclosure.FIG. 8 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device, according to an exemplary embodiment of the present disclosure._____c:1. A method for 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in an image, comprising:obtaining a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determining a difference of the first image and the second image;performing a binarization operation on the difference of the first image and the second image, to generate a binary image;determining, in each column of the binary image, the number of pixels whose values are nonzero, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. The method according to claim 1, wherein determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:determining the number of crests in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the number of crests.3. The method according to claim 2, wherein:a y-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponds to the number of pixels whose values are nonzero in each column of the binary image;an x-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponds to the 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the binary image; anddetermining the number of crests in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:traversing all 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andif the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes a first column whose y-coordinate value is greater than a crest threshold,determining a second column which is separate from the first column by a set distance along the x-axis, andincreasing the number of crests by one when a difference between the y-coordinate value of the first column and a y-coordinate value of the second column is greater than a set difference threshold.4. The method according to claim 3, wherein only one crest is retained within a set range along the x-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The method according to claim 2, wherein determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the number of crests comprises:when the number of crests is less than a minimum number threshold or greater than a maximum number threshold, determining that a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The method according to claim 1, wherein:a y-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponds to the number of pixels whose values are nonzero in each column of the binary image; anddetermining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprises:determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on an effective column ratio, the effective column ratio being a ratio of the number of 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 whose y-coordinate values are greater than a crest threshold to the number of 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 whose y-coordinate values are greater than a noise threshold.7. The method according to claim 6, wherein determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the effective column ratio comprises:when the effective column ratio is less than a ratio threshold, determining that a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.8. The method according to claim 1, wherein determining, in each column of the binary image, the number of pixels whose values are nonzero comprises:performing an erosion operation on the binary image to obtain an eroded image;determining, in the eroded image, the number of pixels whose values are nonzero; andwhen the number of pixels in the eroded image whose values are nonzero is greater than a first set threshold, determining, in each column of the binary image, the number of pixels whose values are nonzero.9. The method according to claim 8, further comprising:when the number of pixels in the eroded image whose values are nonzero is less than or equal to the first set threshold, obtaining new 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.10. The method according to claims 1, wherein:determining the difference of the first image and the second image comprises:subtracting pixel values of the first image by pixel values of the second image, to generate difference values; andgenerating a different image using absolute values of the determined difference values; andperforming a binarization operation on the difference of the first image and the second image comprises:in the difference image, setting pixel values less than a threshold to be zero, and setting pixel values greater than or equal to the threshold to be a preset nonzero value.11. The method according to claims 1, wherein the first image and the second image are two adjacent image frames in an infrared video.12. An apparatus comprising:a memory storing instructions; anda processor configured to execute the instructions to:obtain a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determine a difference of the first image and the second image;perform a binarization operation on the difference of the first image and the second image, to generate a binary image;determine the number of pixels whose values are nonzero in each column of the binary image, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermine whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The apparatus according to claims 12, wherein the processor is further configured to execute the instructions to:determine the number of crests in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermine whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the number of crests.14. The apparatus according to claims 13, wherein:a y-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponds to the number of pixels whose values are nonzero in each column of the binary image;an x-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponds to the 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the binary image; andthe processor is further configured to execute the instructions to:traverse all 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; andif the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 includes a first column whose y-coordinate value is greater than a crest threshold,determine a second column which is separate from the first column by a set distance along the x-axis, andincrease the number of crests by one when a difference between the y-coordinate value of the first column and a y-coordinate value of the second column is greater than a set difference threshold.15. The apparatus according to claims 13, wherein in determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the number of crests, the processor is further configured to execute the instructions to:when the number of crests is less than a minimum number threshold or greater than a maximum number threshold, determine that a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. The apparatus according to claims 12, wherein:a y-axis of the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponds to the number of pixels whose values are nonzero in each column of the binary image; andthe processor is further configured to execute the instructions to:determine whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on an effective column ratio, the effective column ratio being a ratio of the number of 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 whose y-coordinate values are greater than a crest threshold to the number of 
<a href="https://en.wikipedia.org/wiki/Column"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    columns
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 whose y-coordinate values are greater than a noise threshold.17. The apparatus according to claims 16, wherein in determining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the effective column ratio, the processor is further configured to execute the instructions to:when the effective column ratio is less than a ratio threshold, determine that a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.18. The apparatus according to claims 12, wherein the processor is further configured to execute the instructions to:perform an erosion operation on the binary image to obtain an eroded image;determine, in the eroded image, the number of pixels whose values are nonzero; andwhen the number of pixels in the eroded image whose values are nonzero is greater than a first set threshold, determine, in each column of the binary image, the number of pixels whose values are nonzero.19. The apparatus according to claims 18, wherein the processor is further configured to execute the instructions to:when the number of pixels in the eroded image whose values are nonzero is less than or equal to the first set threshold, obtain new 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to generate the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.20. A non-transitory computer-readable 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    storage medium
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 storing instructions that, when executed by a processor, cause the processor to perform a moving object detection method comprising:obtaining a first image and a second image of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;determining a difference of the first image and the second image;performing a binarization operation on the difference of the first image and the second image, to generate a binary image;determining the number of pixels whose values are nonzero in each column of the binary image, to generate a column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anddetermining whether a moving object is present in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the column pixel 
<a href="https://en.wikipedia.org/wiki/Histogram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    histogram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._______________APPARATUS AND METHOD 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 EFFICIENT MOTION ESTIMATION_____20171109_____XMLs/xml/ipa171109.xml_____US-20170323454-A1 : US-15586600 : IN-201641015446_____G06T0007254000 : H04N0019523000 : H04N0019159000 : 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    G06T0003400000
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 : H04N0019139000The architecture shown can perform global 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, local 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and local sub pixel 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in a parallel or in a 
<a href="https://en.wikipedia.org/wiki/Pipeline_burst_cache"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pipelined mode
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. All operations are in a streaming mode without the requirement of external intermediate 
<a href="https://en.wikipedia.org/wiki/Data_storage"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data storage
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:CLAIM OF PRIORITYThis application claims priority under 35 U.S.C 119(e) (1) to Indian Provisional Application No. 20164101546 filed May 4, 2016TECHNICAL FIELD OF THE INVENTIONThe technical field of this invention is image compression.BACKGROUND OF THE INVENTIONIncreasing 
<a href="https://en.wikipedia.org/wiki/Display_resolution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video resolution
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and frame rates, along with large number of searching and matching operations involved in 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 demand very high 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. While high 
<a href="https://en.wikipedia.org/wiki/Performance"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    performance
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 can be achieved by increasing hardware throughput and higher 
<a href="https://en.wikipedia.org/wiki/Clock_rate"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    clock frequency
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, it is important to identify and exploit parallelism present in the algorithm in order to efficiently utilize available hardware resources.The Motion Estimation process involves searching operations which require accessing large amount of reference picture 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 from memory. Memory bandwidth is an expensive resource which often limits the computational parallelism that can be built in hardware. Further, this large 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 traffic from the memory leads to large 
<a href="https://en.wikipedia.org/wiki/Dissipation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    power dissipation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Motion estimation finds best match for each 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Film_frame"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video frame
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 among blocks from previously coded frame (s) (called as reference frames). Block size is typically 16×16 pixels.A widely used metric to define the match is—SAD_(Sum Of Absolute Difference in all the pixel values of 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a reference 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
).The best match information is indicated by the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector: if the 
<a href="https://en.wikipedia.org/wiki/Current"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    current
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 position of a 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 is (16,16) then 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector (4,1) means the best match lies at position (20,17) in the reference frame.The 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vector can also be in fraction 
<a href="https://en.wikipedia.org/wiki/Rasterisation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    pixel precision
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
: half pixel, quarter pixel 
<a href="https://en.wikipedia.org/wiki/ETC"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    etc
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Fractional pixels are calculated by interpolating neighboring integer position pixels.A 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 algorithm would typically consist of these steps:Stage 1: choosing best among a few predictor 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 vectors;Stage 2: 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 around winner of Stage 1;Stage 3, 4: 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 around winner of Stage 2 and stage 3 respectively;Stage 5: sub-pixel 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at interpolated positions.SUMMARY OF THE INVENTIONA parallel 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 architecture is shown that enables efficient utilization of computational resources by making use of the inherent parallelism of the 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 algorithms.BRIEF DESCRIPTION OF THE DRAWINGSThese and other aspects of this invention are illustrated in the drawings, in which:FIG. 1 illustrates the organization of a typical 
<a href="https://en.wikipedia.org/wiki/Digital_signal_processor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    digital signal processor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to which this invention is applicable (
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
);FIG. 2 illustrates details of a very long instruction word 
<a href="https://en.wikipedia.org/wiki/Digital_signal"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    digital signal
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Multi-core_processor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processor core
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 suitable for use in Figure (
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
);FIG. 3 illustrates the pipeline stages of the very long instruction word 
<a href="https://en.wikipedia.org/wiki/Digital_signal"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    digital signal
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Multi-core_processor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processor core
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrated in FIG. 2 (
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
);FIG. 4 illustrates the instruction syntax of the very long instruction word 
<a href="https://en.wikipedia.org/wiki/Digital_signal"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    digital signal
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Multi-core_processor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    processor core
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrated in FIG. 2 (
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
);FIG. 5 illustrates an overview of the 
<a href="https://en.wikipedia.org/wiki/Data_compression"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video encoding
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process of the 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 6 illustrates an overview of the 
<a href="https://en.wikipedia.org/wiki/Video_codec"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    video decoding
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process of the 
<a href="https://en.wikipedia.org/wiki/Prior_art"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    prior art
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 7 illustrates an overview of the 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 engine of this invention; andFIG. 8 illustrates one of the local 
<a href="https://en.wikipedia.org/wiki/Protocol_Buffers"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    buffers
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____c:1. An apparatus for 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 comprising of:a predictor engine connected to a vector SAD engine and a subpel engine;a vector SAD (Sum of Absolute Difference) engine connected to said subpel engine and said predictor engine;a subpel (sub pixel) engine connected to said vector SAD engine, said predictor engine ant to an interpolation 
<a href="https://en.wikipedia.org/wiki/Buffer_solution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    reference buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;a skip engine connected to a skip 
<a href="https://en.wikipedia.org/wiki/Data_buffer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    input buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a, MB (Macro Block) 
<a href="https://en.wikipedia.org/wiki/Buffer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; anda plurality of local 
<a href="https://en.wikipedia.org/wiki/Protocol_Buffers"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    buffers
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. The apparatus of claim 1 operable to execute independent operations 
<a href="https://en.wikipedia.org/wiki/Series_and_parallel_circuits"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    in parallel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.3. The apparatus of claim 1 operable to execute multiple reference frame searches in a pipelined mode.4. The apparatus of claim 1 operable to process a plurality of macro blocks in a pipelined mode.5. The apparatus of claim 1 wherein said local 
<a href="https://en.wikipedia.org/wiki/Protocol_Buffers"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    buffers
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include an interpolation 
<a href="https://en.wikipedia.org/wiki/Buffer_solution"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    reference buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, a macro 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 skip 
<a href="https://en.wikipedia.org/wiki/Buffer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and a macro 
<a href="https://en.wikipedia.org/wiki/Block"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 skip 
<a href="https://en.wikipedia.org/wiki/Data_buffer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    input buffer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. A method of 
<a href="https://en.wikipedia.org/wiki/Motion_estimation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion estimation
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 wherein global 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, local integer 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and local sub-pixel 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 operations are performed 
<a href="https://en.wikipedia.org/wiki/Series_and_parallel_circuits"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    in parallel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.7. The method of claim 6 wherein said global 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, local integer 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and local sub-pixel 
<a href="https://en.wikipedia.org/wiki/Searching"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    search
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 are performed in a pipelined mode._______________IMAGE PROCESSING APPARATUS, IMAGE PROCESSING METHOD, AND IMAGE PROCESSING SYSTEM_____20171228_____XMLs/xml/ipa171228.xml_____US-20170372485-A1 : US-15542685 : JP-2015-082275 : WO-PCT/JP2016/001897-00_____G06T0007254000 : G06K0009000000An 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, including circuitry configured to generate or receive a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. The circuitry is configured to determine a length of time movement of the object is below a predetermined movement threshold. The circuitry is further configured to identify the object as a target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold._____d:CROSS REFERENCE TO RELATED APPLICATIONSThis application claims the benefit of Japanese Priority Patent Application JP 2015-082275 filed Apr. 14, 2015, the entire contents of which are incorporated herein by reference.TECHNICAL FIELDThe present disclosure relates to an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system.BACKGROUND ARTIn related art, technology for 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmenting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a region of an object such as a person of a detection target, within a photographed image, has been variously developed.For example, PTL 1 discloses technology that detects moving bodies within an image photographed by a fish-
<a href="https://en.wikipedia.org/wiki/Eye"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    eye
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 lens camera, and respectively segments circumscribed quadrangle regions of each of the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving bodies. Further, PTL 2 discloses technology that extracts, based on 
<a href="https://en.wikipedia.org/wiki/Lithotomy_position"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    position information
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a partial region extracted with an immediately preceding frame image, and a physical feature amount analyzed from a present frame image, a partial region from each frame image. Further, PTL 3 discloses technology that detects a moving 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a size, an existing time, or a moving speed the largest from among moving bodies extracted from picture 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and segments a region that includes the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.CITATION LISTPatent LiteraturePTL 1: JP 2001-333422APTL 2: JP 2004-334587APTL 3: JP 2014-222825ASUMMARYTechnical ProblemHowever, in the technology disclosed in PTL 1 to PTL3, there will be cases where the position of a segmented region is restricted. For example, in the technology disclosed in PTL 3, when an object determined once to be a detection target continues to be positioned at the same location, the same location will continue to be set for a long time as a segmented region.Accordingly, the present disclosure proposes a new and improved 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system, capable of adaptively determining a segmented region for the length of time that an object of a detection target is stopped.Solution to ProblemAccording to an embodiment of the present disclosure, there is provided an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, including circuitry configured to generate or receive a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. The circuitry is configured to determine a length of time movement of the object is below a predetermined movement threshold. The circuitry is further configured to identify the object as a target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.According to an embodiment of the present disclosure, there is provided a method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object. The method includes generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. A length of time movement of the object is below the predetermined movement threshold is determined by circuitry of the 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus. Further, the method includes identifying, by the circuitry, the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.According to an embodiment of the present disclosure, there is provided a non-transitory computer-readable medium storing instructions which when executed by a computer cause the computer to perform a method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object. The method includes generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. A length of time movement of the object is below the predetermined movement threshold is determined. The method further includes identifying the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.Advantageous Effects of InventionAccording to an embodiment of the present disclosure such as described above, a segmented region can be adaptively determined for the length of time that an object of a detection target is stopped. Note that, the effect described here is not necessarily limited, and may be any of the effects described within the present disclosure.BRIEF DESCRIPTION OF DRAWINGSFIG. 1 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration example of an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system according to an embodiment of the present disclosure.FIG. 2 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows an example of a reduced image 32 generated by a camera 10.FIG. 3 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows an example of a plurality of cropped 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 50 generated from a frame image 30.FIG. 4 is a function 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration of the camera 10 according to a same embodiment.FIG. 5 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a relationship between the frame image 30 and a cropped region 40.FIG. 6 is a function 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration of a monitoring terminal 22 according to a same embodiment.FIG. 7 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a display example of an evaluation standard setting screen according to a same embodiment.FIG. 8 is a function 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration of a region setting unit 104 according to a same embodiment.FIG. 9 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart that shows the operations according to a same embodiment.FIG. 10 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart that shows a part of the operations of a cropped image generation process according to a same embodiment.FIG. 11 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart that shows a part of the operations of a cropped image generation process according to a same embodiment._____c:1. An 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, comprising:circuitry configured togenerate or receive a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object,determine a length of time movement of the object is below a predetermined movement threshold, andidentify the object as a target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.2. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:receive or generate the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the first image and a second image captured before the first image, the object being identified as the target object in the second image,determine whether to continue to identify the object as the target object in the first image based on the determined length of time the movement of the object is below the predetermined movement threshold, andidentify the object as the target object when the circuitry determines to continue to identify the object as the target object in the first image.3. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 2, wherein the circuitry is configured to change the target object from the object to a different object included in the first image when the circuitry determines not to continue identifying the object as the target object.4. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:determine whether the length of time the movement of the object is below the predetermined movement threshold exceeds an upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify the object as the target object when the length of time the movement of the object is below the predetermined movement threshold is less than or equal to the upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:determine whether the length of time the movement of the object is below the predetermined movement threshold exceeds an upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify a different object included in the first image as the target object when the length of the time the movement of the object is below the predetermined movement threshold exceeds the upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, further comprising:an 
<a href="https://en.wikipedia.org/wiki/Image_sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to capture the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,including the first image.7. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, whereinthe target object is a cropping target, andthe circuitry is configured to generate a cropped image by cropping the first image based on a position of the object within the first image when the object is identified as the target object.8. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, whereinthe circuitry is configured to transmit a plurality of image streams,the plurality of image streams includes cropped 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of different portions of each of the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andeach of the different portions corresponds to a different object.9. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 7, wherein the circuitry is configured to:generate a lower resolution version of the first image, andtransmit the cropped image and the lower resolution version of the first image.10. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:identify the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold and a length of time the object is identified as the target object.11. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the predetermined movement threshold corresponds to an amount of movement between successive 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.12. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:set an upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on a 
<a href="https://en.wikipedia.org/wiki/Input/output"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user input
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on a comparison of the length of time the movement of the object is below the predetermined movement threshold and the set upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:set different upper time limits for different 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the first image, in the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify the object as the target object in the first image based on a comparison of the length of time the movement of the object is below the predetermined movement threshold and the upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 set for the first image.14. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:detect a plurality of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 included in the first image, andidentify a subset of the plurality of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as target 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image when a number of the plurality of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exceeds a predetermined maximum number of target 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the predetermined maximum number being greater than 1.15. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:continue to identify the object as the target object in subsequent successive 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the object and captured after the first image, until the length of time the movement of the object is below the predetermined movement threshold exceeds an 
<a href="https://en.wikipedia.org/wiki/Limit_inferior_and_limit_superior"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    upper limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:determine a plurality of cropped regions of the first image, each of the cropped 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a different target object, anddetermine whether a first one of the plurality of cropped regions overlaps with a second one of the plurality of cropped regions.17. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 16, wherein the circuitry is configured to:determine that the first one of the plurality of cropped regions overlaps with the second one of the plurality of cropped regions when an area of an overlapping region for the first one of the plurality of cropped regions and the second one of the plurality of cropped regions exceeds a first predetermined overlap threshold or a distance between the centers of the first one of the plurality of cropped regions and the second one of the plurality of cropped regions exceeds a second predetermined overlap threshold.18. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the length of time the movement of the object is below the predetermined movement threshold indicates a length of time the object has stopped.19. A method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object, the method comprising:generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object;determining, by circuitry of the 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, a length of time movement of the object is below the predetermined movement threshold, andidentifying, by the circuitry, the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.20. A non-transitory computer-readable medium storing instructions which when executed by a computer cause the computer to perform a method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object, the method comprising:generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object;determining, a length of time movement of the object is below the predetermined movement threshold, andidentifying the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold._______________METHODS OF AND APPARATUSES 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 RECOGNIZING MOTION OF OBJECTS, AND ASSOCIATED SYSTEMS_____20171228_____XMLs/xml/ipa171228.xml_____US-20170372486-A1 : US-15636751 : KR-10-2012-0120883 : US-14064639 : US-9715740 : US-15636751_____G06T0007254000A method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may include periodically obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using an image capturing device, wherein the second resolution is higher than the first resolution; determining a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object; periodically obtaining tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or analyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:CROSS-REFERENCE TO RELATED APPLICATION(S)This application is a continuation of U.S. application Ser. No. 14/064,639, filed on Oct. 28, 2013, which claims priority from Korean Patent Application No. 10-2012-0120883, filed on Oct. 30, 2012, in the Korean Intellectual Property Office (KIPO), the entire contents of each of which are incorporated herein by reference.BACKGROUND1. FieldSome example embodiments may relate generally to processing of image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Some example embodiments may relate to 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of and/or apparatuses for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. Description of Related ArtA two-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to obtain two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to recognize a shape and/or a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object. Particularly the technology for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a user is developed to support a 
<a href="https://en.wikipedia.org/wiki/User_interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the 
<a href="https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_–_Motion_Picture_Drama"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include color image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or black and 
<a href="https://en.wikipedia.org/wiki/Black_and_white"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    white image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Alternatively a 
<a href="https://en.wikipedia.org/wiki/Range_imaging"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to obtain depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to recognize the shape and/or the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the object. The depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the 
<a href="https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_–_Motion_Picture_Drama"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include information of a distance to the object from the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In general, the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be provided with relatively a higher resolution, but it is difficult to distinguish the object from the background based on the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during the 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process for the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 recognition. The depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be provided with relatively a lower resolution and thus it is difficult to discern the 
<a href="https://en.wikipedia.org/wiki/Complex"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complex
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 shape of the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during the 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process for the 
<a href="https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_–_Motion_Picture_Drama"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.SUMMARYSome example embodiments of the inventive concept may provide 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, capable of discerning the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 efficiently based on depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Some example embodiments of the inventive concept may provide apparatuses for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, capable of discerning the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 efficiently based on depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Some example embodiments of the inventive concept may provide systems adopting the 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or apparatuses of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise periodically obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using an image capturing device, wherein the second resolution is higher than the first resolution; determining a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object; periodically obtaining tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or analyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, periodically obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may comprise providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame with a first frame period using depth pixels of the first resolution; and/or providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame with a second frame period using color pixels of the second resolution.In some example embodiments, the method may further comprise synchronizing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be matched with each other, when the first frame period is different from the second frame period.In some example embodiments, the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may be provided with the first frame period or the second frame period.In some example embodiments, periodically obtaining the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise extracting region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the frame; and/or providing the region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution as the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, periodically obtaining the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise extracting region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the frame; extracting region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the frame; compensating for the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution using the region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution to generate region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution; and/or providing the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution as the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, the depth pixels and the color pixels may be arranged in a common pixel array.In some example embodiments, the depth pixels and the color pixels may be arranged respectively in distinct pixel arrays that are spaced apart from each other.In some example embodiments, periodically obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may comprise periodically providing raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame using time-of-flight (TOF) depth pixels, the TOF depth pixels operating in response to a plurality of demodulation signals having different phases from each other; and/or calculating the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution based on the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, calculating the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution by combining every M bits of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where M is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer equal to or greater than two and/or providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution by combining every N bits of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where N is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer equal to or smaller than M.In some example embodiments, the demodulation signals may have phase difference of 0, 90, 180 and 270 degrees, respectively, with respect to 
<a href="https://en.wikipedia.org/wiki/Transmission"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    transmission
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 radiated from the image capturing device.In some example embodiments, providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise providing one bit value of the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on four bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the four bit values respectively corresponding to the four demodulation signals having the phase difference of 0, 90, 180 and 270 degrees, respectively.In some example embodiments, providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise providing one bit value of the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by summing two bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the two bit values respectively corresponding to the two demodulation signals having the phase differences of 0 and 180 degrees; and/or providing another bit value of the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by summing other two bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the other two bit values respectively corresponding to the two demodulation signals having the phase differences of 90 and 270 degrees.In some example embodiments, periodically obtaining the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise extracting region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the frame; extracting region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the frame; compensating for the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution using the region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution to generate region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution; and/or providing the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution as the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, determining the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may comprise determining coordinates of a center point of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region in the frame; and/or determining a size of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region in the frame.In some example embodiments, the method may further comprise upgrading the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region according to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target object.In some example embodiments, upgrading the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may comprise 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a change of a position of the target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or changing coordinates of a center point of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region in the frame based on the change of the position of the target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, upgrading the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may comprise 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a change of distance to the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; decreasing a size of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region when the distance to the target object increases; and/or increasing the size of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region when the distance to the target object decreases.In some example embodiments, an apparatus for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise an image capturing device configured to periodically provide depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the second resolution is higher than the first resolution; a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker configured to determine a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object, and configured to periodically provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or a 
<a href="https://en.wikipedia.org/wiki/Mass_spectrometry"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion analyzer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to analyze the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, the image capturing device may comprise a pixel array in which depth pixels of the first resolution and color pixels of the second resolution are alternatively arranged, the depth pixels providing the depth data with a first frame period, and the color pixels providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a second frame period.In some example embodiments, the image capturing device may comprise a first pixel array in which depth pixels of the first resolution are arranged, the depth pixels providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a first frame period; and/or a second pixel array in which color pixels of the second resolution are arranged, the color pixels providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a second frame period.In some example embodiments, the image capturing device may comprise a pixel array in which time-of-flight (TOF) depth pixels are arranged, the TOF depth pixels operating in response to a plurality of demodulation signals having different phases from each other to periodically provide raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame.In some example embodiments, the demodulation signals may have phase difference of 0, 90, 180, and 270 degrees, respectively, with respect to 
<a href="https://en.wikipedia.org/wiki/Transmission"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    transmission
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 radiated from the image capturing device, and/or one bit value of the depth data may be provided based on four bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the four bit values respectively corresponding to the four demodulation signals having the phase difference of 0, 90, 180, and 270 degrees, respectively.In some example embodiments, a system may comprise an image capturing device configured to periodically provide depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution corresponding to a frame of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution corresponding to the frame, wherein the second resolution is higher than the first resolution; a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker configured to determine a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of the frame and the portion includes the target object, and configured to periodically provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; a 
<a href="https://en.wikipedia.org/wiki/Mass_spectrometry"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion analyzer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to 
<a href="https://en.wikipedia.org/wiki/Potential"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    analyze motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and/or a 
<a href="https://en.wikipedia.org/wiki/Remote_control"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    control device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to generate an event corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on an analysis result of the 
<a href="https://en.wikipedia.org/wiki/Mass_spectrometry"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion analyzer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, the system may be a 
<a href="https://en.wikipedia.org/wiki/User_interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system that operates by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a user. The target object may include a 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the user or a portion of the 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the user.In some example embodiments, an apparatus for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise a first device configured to provide depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that includes the object at a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at a second resolution; a second device configured to determine a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and configured to provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or a third device configured to analyze the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The second resolution may be higher than the first resolution. The 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may correspond to a portion of a frame. The portion of the frame may include the object.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array. The 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array may be configured to output depth information.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a color pixel array. The color pixel array may be configured to output color information.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array and a color pixel array. The 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array may be configured to output depth information. The color pixel array may be configured to output color information.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a pixel array. The pixel array may be configured to output depth information, color information, or depth and color information.In some example embodiments, a method for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; obtaining two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; recognizing the object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; tracking the object using a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region to provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution; and/or analyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The second resolution may be higher than the first resolution.In some example embodiments, obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise using a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array of a sensing unit to output depth information.In some example embodiments, obtaining the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise using a color pixel array of a sensing unit to output color information.In some example embodiments, obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise using a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array of a sensing unit to output depth information and/or obtaining the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise using a color pixel array of the sensing unit to output color information.In some example embodiments, obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise using a pixel array of a sensing unit to output depth information and/or obtaining the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise using the pixel array of the sensing unit to output color information.BRIEF DESCRIPTION OF THE DRAWINGSThe above and/or other aspects and advantages will become more apparent and more readily appreciated from the following detailed description of example embodiments, taken in conjunction with the accompanying drawings, in which:FIG. 1 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 2 is a diagram illustrating an example of using a system according to some example embodiments of the inventive concept;FIG. 3 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a system according to some example embodiments of the inventive concept;FIG. 4 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of an image capturing device in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIG. 5 is a diagram illustrating an example of a sensing unit in the image capturing device of FIG. 4;FIG. 6 is a diagram illustrating an example of a pixel array in the sensing unit of FIG. 5;FIG. 7 is a diagram illustrating a frame of an example depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained by an image capturing device;FIG. 8 is a diagram illustrating a frame of an example two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained by an image capturing device;FIG. 9 is a diagram illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region determined according to some example embodiments of the inventive concept;FIG. 10 is a diagram illustrating an example of a sensing unit in the image capturing device of FIG. 4;FIGS. 11A and 11B are diagrams illustrating example pixel arrays in the sensing unit of FIG. 10;FIGS. 12A, 12B, 12C, and 12D are circuit diagrams illustrating some example unit pixels in a pixel array;FIG. 13 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 14 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIGS. 15A, 15B, and 15C are diagrams illustrating example operations of a synchronizer in the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker of FIG. 14;FIG. 16 is a diagram for describing tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 provided by the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker of FIG. 14;FIGS. 17A and 17B are diagrams for describing a method of upgrading a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region according to some example embodiments of the inventive concept;FIG. 18 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 19 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIG. 20 is a diagram for describing tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 provided by the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker of FIG. 19;FIG. 21 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 22 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIG. 23 is a diagram illustrating an example of a pixel array included in a 
<a href="https://en.wikipedia.org/wiki/Range_imaging"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 24 is a 
<a href="https://en.wikipedia.org/wiki/Circuit_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    circuit diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating example time-of-flight (TOF) depth pixels in the pixel array of FIG. 23;FIG. 25 is a 
<a href="https://en.wikipedia.org/wiki/Timing_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    timing diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an operation of the TOF pixels of FIG. 24;FIG. 26 is a diagram illustrating an example combination for providing depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 27 is a diagram for describing a method of calculating two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained using depth pixels;FIGS. 28A and 28B are diagrams example combinations for providing two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 29 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a camera including a three-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to some example embodiments of the inventive concept;FIG. 30 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept; andFIG. 31 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 employable in the computing system of FIG. 30 according to some example embodiments of the inventive concept._____c:1. A method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object, the method comprising:periodically obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using an image capturing device, wherein the second resolution is higher than the first resolution;determining a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object;periodically obtaining tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; andanalyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._______________IMAGE PROCESSING APPARATUS, IMAGE PROCESSING METHOD, AND IMAGE PROCESSING SYSTEM_____20171228_____XMLs/xml/ipa171228.xml_____US-20170372485-A1 : US-15542685 : JP-2015-082275 : WO-PCT/JP2016/001897-00_____G06T0007254000 : G06K0009000000An 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, including circuitry configured to generate or receive a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. The circuitry is configured to determine a length of time movement of the object is below a predetermined movement threshold. The circuitry is further configured to identify the object as a target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold._____d:CROSS REFERENCE TO RELATED APPLICATIONSThis application claims the benefit of Japanese Priority Patent Application JP 2015-082275 filed Apr. 14, 2015, the entire contents of which are incorporated herein by reference.TECHNICAL FIELDThe present disclosure relates to an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system.BACKGROUND ARTIn related art, technology for 
<a href="https://en.wikipedia.org/wiki/Market_segmentation"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    segmenting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a region of an object such as a person of a detection target, within a photographed image, has been variously developed.For example, PTL 1 discloses technology that detects moving bodies within an image photographed by a fish-
<a href="https://en.wikipedia.org/wiki/Eye"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    eye
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 lens camera, and respectively segments circumscribed quadrangle regions of each of the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving bodies. Further, PTL 2 discloses technology that extracts, based on 
<a href="https://en.wikipedia.org/wiki/Lithotomy_position"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    position information
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a partial region extracted with an immediately preceding frame image, and a physical feature amount analyzed from a present frame image, a partial region from each frame image. Further, PTL 3 discloses technology that detects a moving 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a size, an existing time, or a moving speed the largest from among moving bodies extracted from picture 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, and segments a region that includes the 
<a href="https://en.wikipedia.org/wiki/Music_Detected"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detected
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 moving 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.CITATION LISTPatent LiteraturePTL 1: JP 2001-333422APTL 2: JP 2004-334587APTL 3: JP 2014-222825ASUMMARYTechnical ProblemHowever, in the technology disclosed in PTL 1 to PTL3, there will be cases where the position of a segmented region is restricted. For example, in the technology disclosed in PTL 3, when an object determined once to be a detection target continues to be positioned at the same location, the same location will continue to be set for a long time as a segmented region.Accordingly, the present disclosure proposes a new and improved 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 method, and 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system, capable of adaptively determining a segmented region for the length of time that an object of a detection target is stopped.Solution to ProblemAccording to an embodiment of the present disclosure, there is provided an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, including circuitry configured to generate or receive a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. The circuitry is configured to determine a length of time movement of the object is below a predetermined movement threshold. The circuitry is further configured to identify the object as a target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.According to an embodiment of the present disclosure, there is provided a method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object. The method includes generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. A length of time movement of the object is below the predetermined movement threshold is determined by circuitry of the 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus. Further, the method includes identifying, by the circuitry, the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.According to an embodiment of the present disclosure, there is provided a non-transitory computer-readable medium storing instructions which when executed by a computer cause the computer to perform a method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object. The method includes generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object. A length of time movement of the object is below the predetermined movement threshold is determined. The method further includes identifying the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.Advantageous Effects of InventionAccording to an embodiment of the present disclosure such as described above, a segmented region can be adaptively determined for the length of time that an object of a detection target is stopped. Note that, the effect described here is not necessarily limited, and may be any of the effects described within the present disclosure.BRIEF DESCRIPTION OF DRAWINGSFIG. 1 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration example of an 
<a href="https://en.wikipedia.org/wiki/Digital_image_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system according to an embodiment of the present disclosure.FIG. 2 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows an example of a reduced image 32 generated by a camera 10.FIG. 3 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows an example of a plurality of cropped 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 50 generated from a frame image 30.FIG. 4 is a function 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration of the camera 10 according to a same embodiment.FIG. 5 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a relationship between the frame image 30 and a cropped region 40.FIG. 6 is a function 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration of a monitoring terminal 22 according to a same embodiment.FIG. 7 is an 
<a href="https://en.wikipedia.org/wiki/Diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    explanatory diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a display example of an evaluation standard setting screen according to a same embodiment.FIG. 8 is a function 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that shows a configuration of a region setting unit 104 according to a same embodiment.FIG. 9 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart that shows the operations according to a same embodiment.FIG. 10 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart that shows a part of the operations of a cropped image generation process according to a same embodiment.FIG. 11 is a 
<a href="https://en.wikipedia.org/wiki/Flow"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    flow
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 chart that shows a part of the operations of a cropped image generation process according to a same embodiment._____c:1. An 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, comprising:circuitry configured togenerate or receive a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object,determine a length of time movement of the object is below a predetermined movement threshold, andidentify the object as a target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.2. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:receive or generate the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the first image and a second image captured before the first image, the object being identified as the target object in the second image,determine whether to continue to identify the object as the target object in the first image based on the determined length of time the movement of the object is below the predetermined movement threshold, andidentify the object as the target object when the circuitry determines to continue to identify the object as the target object in the first image.3. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 2, wherein the circuitry is configured to change the target object from the object to a different object included in the first image when the circuitry determines not to continue identifying the object as the target object.4. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:determine whether the length of time the movement of the object is below the predetermined movement threshold exceeds an upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify the object as the target object when the length of time the movement of the object is below the predetermined movement threshold is less than or equal to the upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.5. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:determine whether the length of time the movement of the object is below the predetermined movement threshold exceeds an upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify a different object included in the first image as the target object when the length of the time the movement of the object is below the predetermined movement threshold exceeds the upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.6. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, further comprising:an 
<a href="https://en.wikipedia.org/wiki/Image_sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to capture the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
,including the first image.7. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, whereinthe target object is a cropping target, andthe circuitry is configured to generate a cropped image by cropping the first image based on a position of the object within the first image when the object is identified as the target object.8. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, whereinthe circuitry is configured to transmit a plurality of image streams,the plurality of image streams includes cropped 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of different portions of each of the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andeach of the different portions corresponds to a different object.9. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 7, wherein the circuitry is configured to:generate a lower resolution version of the first image, andtransmit the cropped image and the lower resolution version of the first image.10. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:identify the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold and a length of time the object is identified as the target object.11. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the predetermined movement threshold corresponds to an amount of movement between successive 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.12. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:set an upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on a 
<a href="https://en.wikipedia.org/wiki/Input/output"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user input
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on a comparison of the length of time the movement of the object is below the predetermined movement threshold and the set upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.13. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:set different upper time limits for different 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the first image, in the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, andidentify the object as the target object in the first image based on a comparison of the length of time the movement of the object is below the predetermined movement threshold and the upper 
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 set for the first image.14. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:detect a plurality of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 included in the first image, andidentify a subset of the plurality of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 as target 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 in the first image when a number of the plurality of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 exceeds a predetermined maximum number of target 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the predetermined maximum number being greater than 1.15. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:continue to identify the object as the target object in subsequent successive 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, including the object and captured after the first image, until the length of time the movement of the object is below the predetermined movement threshold exceeds an 
<a href="https://en.wikipedia.org/wiki/Limit_inferior_and_limit_superior"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    upper limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Time_limit"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    time limit
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.16. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the circuitry is configured to:determine a plurality of cropped regions of the first image, each of the cropped 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to a different target object, anddetermine whether a first one of the plurality of cropped regions overlaps with a second one of the plurality of cropped regions.17. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 16, wherein the circuitry is configured to:determine that the first one of the plurality of cropped regions overlaps with the second one of the plurality of cropped regions when an area of an overlapping region for the first one of the plurality of cropped regions and the second one of the plurality of cropped regions exceeds a first predetermined overlap threshold or a distance between the centers of the first one of the plurality of cropped regions and the second one of the plurality of cropped regions exceeds a second predetermined overlap threshold.18. The 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus according to claim 1, wherein the length of time the movement of the object is below the predetermined movement threshold indicates a length of time the object has stopped.19. A method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object, the method comprising:generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object;determining, by circuitry of the 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus, a length of time movement of the object is below the predetermined movement threshold, andidentifying, by the circuitry, the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold.20. A non-transitory computer-readable medium storing instructions which when executed by a computer cause the computer to perform a method of an 
<a href="https://en.wikipedia.org/wiki/Information_processing"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    information processing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 apparatus for identifying a target object, the method comprising:generating or receiving a first image of a sequence of 
<a href="https://en.wikipedia.org/wiki/Image"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    images
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including an object;determining, a length of time movement of the object is below the predetermined movement threshold, andidentifying the object as the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the determined length of time the movement of the object is below the predetermined movement threshold._______________METHODS OF AND APPARATUSES 
<a href="https://en.wikipedia.org/wiki/For"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    FOR
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 RECOGNIZING MOTION OF OBJECTS, AND ASSOCIATED SYSTEMS_____20171228_____XMLs/xml/ipa171228.xml_____US-20170372486-A1 : US-15636751 : KR-10-2012-0120883 : US-14064639 : US-9715740 : US-15636751_____G06T0007254000A method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may include periodically obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using an image capturing device, wherein the second resolution is higher than the first resolution; determining a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object; periodically obtaining tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or analyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
._____d:CROSS-REFERENCE TO RELATED APPLICATION(S)This application is a continuation of U.S. application Ser. No. 14/064,639, filed on Oct. 28, 2013, which claims priority from Korean Patent Application No. 10-2012-0120883, filed on Oct. 30, 2012, in the Korean Intellectual Property Office (KIPO), the entire contents of each of which are incorporated herein by reference.BACKGROUND1. FieldSome example embodiments may relate generally to processing of image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. Some example embodiments may relate to 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of and/or apparatuses for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.2. Description of Related ArtA two-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to obtain two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to recognize a shape and/or a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object. Particularly the technology for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a user is developed to support a 
<a href="https://en.wikipedia.org/wiki/User_interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the 
<a href="https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_–_Motion_Picture_Drama"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include color image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 or black and 
<a href="https://en.wikipedia.org/wiki/Black_and_white"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    white image
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Alternatively a 
<a href="https://en.wikipedia.org/wiki/Range_imaging"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to obtain depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be used to recognize the shape and/or the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the object. The depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the 
<a href="https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_–_Motion_Picture_Drama"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may include information of a distance to the object from the 
<a href="https://en.wikipedia.org/wiki/Sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In general, the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be provided with relatively a higher resolution, but it is difficult to distinguish the object from the background based on the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during the 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process for the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 recognition. The depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may be provided with relatively a lower resolution and thus it is difficult to discern the 
<a href="https://en.wikipedia.org/wiki/Complex"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    complex
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 shape of the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 during the 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 process for the 
<a href="https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_–_Motion_Picture_Drama"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognition
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.SUMMARYSome example embodiments of the inventive concept may provide 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, capable of discerning the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 efficiently based on depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Some example embodiments of the inventive concept may provide apparatuses for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, capable of discerning the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 efficiently based on depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.Some example embodiments of the inventive concept may provide systems adopting the 
<a href="https://en.wikipedia.org/wiki/Method"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    methods
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or apparatuses of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    objects
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise periodically obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using an image capturing device, wherein the second resolution is higher than the first resolution; determining a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object; periodically obtaining tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or analyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, periodically obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may comprise providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame with a first frame period using depth pixels of the first resolution; and/or providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame with a second frame period using color pixels of the second resolution.In some example embodiments, the method may further comprise synchronizing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 to be matched with each other, when the first frame period is different from the second frame period.In some example embodiments, the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may be provided with the first frame period or the second frame period.In some example embodiments, periodically obtaining the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise extracting region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the frame; and/or providing the region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution as the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, periodically obtaining the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise extracting region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the frame; extracting region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the frame; compensating for the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution using the region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution to generate region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution; and/or providing the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution as the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, the depth pixels and the color pixels may be arranged in a common pixel array.In some example embodiments, the depth pixels and the color pixels may be arranged respectively in distinct pixel arrays that are spaced apart from each other.In some example embodiments, periodically obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 may comprise periodically providing raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame using time-of-flight (TOF) depth pixels, the TOF depth pixels operating in response to a plurality of demodulation signals having different phases from each other; and/or calculating the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution based on the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, calculating the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution and the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution by combining every M bits of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where M is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer equal to or greater than two and/or providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution by combining every N bits of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, where N is a 
<a href="https://en.wikipedia.org/wiki/Positive"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    positive
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 integer equal to or smaller than M.In some example embodiments, the demodulation signals may have phase difference of 0, 90, 180 and 270 degrees, respectively, with respect to 
<a href="https://en.wikipedia.org/wiki/Transmission"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    transmission
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 radiated from the image capturing device.In some example embodiments, providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise providing one bit value of the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on four bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the four bit values respectively corresponding to the four demodulation signals having the phase difference of 0, 90, 180 and 270 degrees, respectively.In some example embodiments, providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise providing one bit value of the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by summing two bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the two bit values respectively corresponding to the two demodulation signals having the phase differences of 0 and 180 degrees; and/or providing another bit value of the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 by summing other two bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the other two bit values respectively corresponding to the two demodulation signals having the phase differences of 90 and 270 degrees.In some example embodiments, periodically obtaining the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise extracting region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution corresponding to the frame; extracting region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region from the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the frame; compensating for the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution using the region image 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution to generate region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution; and/or providing the region depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution as the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, determining the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may comprise determining coordinates of a center point of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region in the frame; and/or determining a size of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region in the frame.In some example embodiments, the method may further comprise upgrading the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region according to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target object.In some example embodiments, upgrading the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may comprise 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a change of a position of the target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and/or changing coordinates of a center point of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region in the frame based on the change of the position of the target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, upgrading the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may comprise 
<a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    detecting
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a change of distance to the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; decreasing a size of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region when the distance to the target object increases; and/or increasing the size of the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region when the distance to the target object decreases.In some example embodiments, an apparatus for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise an image capturing device configured to periodically provide depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, wherein the second resolution is higher than the first resolution; a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker configured to determine a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object, and configured to periodically provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or a 
<a href="https://en.wikipedia.org/wiki/Mass_spectrometry"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion analyzer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to analyze the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, the image capturing device may comprise a pixel array in which depth pixels of the first resolution and color pixels of the second resolution are alternatively arranged, the depth pixels providing the depth data with a first frame period, and the color pixels providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a second frame period.In some example embodiments, the image capturing device may comprise a first pixel array in which depth pixels of the first resolution are arranged, the depth pixels providing the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a first frame period; and/or a second pixel array in which color pixels of the second resolution are arranged, the color pixels providing the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 with a second frame period.In some example embodiments, the image capturing device may comprise a pixel array in which time-of-flight (TOF) depth pixels are arranged, the TOF depth pixels operating in response to a plurality of demodulation signals having different phases from each other to periodically provide raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 corresponding to the frame.In some example embodiments, the demodulation signals may have phase difference of 0, 90, 180, and 270 degrees, respectively, with respect to 
<a href="https://en.wikipedia.org/wiki/Transmission"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    transmission
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Light"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    light
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 radiated from the image capturing device, and/or one bit value of the depth data may be provided based on four bit values of the raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, the four bit values respectively corresponding to the four demodulation signals having the phase difference of 0, 90, 180, and 270 degrees, respectively.In some example embodiments, a system may comprise an image capturing device configured to periodically provide depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution corresponding to a frame of a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution corresponding to the frame, wherein the second resolution is higher than the first resolution; a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker configured to determine a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of the frame and the portion includes the target object, and configured to periodically provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; a 
<a href="https://en.wikipedia.org/wiki/Mass_spectrometry"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion analyzer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to 
<a href="https://en.wikipedia.org/wiki/Potential"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    analyze motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; and/or a 
<a href="https://en.wikipedia.org/wiki/Remote_control"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    control device
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 configured to generate an event corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on an analysis result of the 
<a href="https://en.wikipedia.org/wiki/Mass_spectrometry"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion analyzer
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.In some example embodiments, the system may be a 
<a href="https://en.wikipedia.org/wiki/User_interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    user interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 system that operates by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a user. The target object may include a 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the user or a portion of the 
<a href="https://en.wikipedia.org/wiki/Body"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    body
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the user.In some example embodiments, an apparatus for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise a first device configured to provide depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 that includes the object at a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 for the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 at a second resolution; a second device configured to determine a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 and configured to provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; and/or a third device configured to analyze the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The second resolution may be higher than the first resolution. The 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region may correspond to a portion of a frame. The portion of the frame may include the object.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array. The 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array may be configured to output depth information.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a color pixel array. The color pixel array may be configured to output color information.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array and a color pixel array. The 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array may be configured to output depth information. The color pixel array may be configured to output color information.In some example embodiments, the first device may comprise a sensing unit. The sensing unit may comprise a pixel array. The pixel array may be configured to output depth information, color information, or depth and color information.In some example embodiments, a method for 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object may comprise obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; obtaining two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; recognizing the object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
; tracking the object using a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region to provide tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution; and/or analyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
. The second resolution may be higher than the first resolution.In some example embodiments, obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise using a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array of a sensing unit to output depth information.In some example embodiments, obtaining the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise using a color pixel array of a sensing unit to output color information.In some example embodiments, obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise using a 
<a href="https://en.wikipedia.org/wiki/Color_depth"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth pixel
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 array of a sensing unit to output depth information and/or obtaining the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise using a color pixel array of the sensing unit to output color information.In some example embodiments, obtaining the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the first resolution may comprise using a pixel array of a sensing unit to output depth information and/or obtaining the two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution may comprise using the pixel array of the sensing unit to output color information.BRIEF DESCRIPTION OF THE DRAWINGSThe above and/or other aspects and advantages will become more apparent and more readily appreciated from the following detailed description of example embodiments, taken in conjunction with the accompanying drawings, in which:FIG. 1 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 2 is a diagram illustrating an example of using a system according to some example embodiments of the inventive concept;FIG. 3 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating a system according to some example embodiments of the inventive concept;FIG. 4 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of an image capturing device in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIG. 5 is a diagram illustrating an example of a sensing unit in the image capturing device of FIG. 4;FIG. 6 is a diagram illustrating an example of a pixel array in the sensing unit of FIG. 5;FIG. 7 is a diagram illustrating a frame of an example depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained by an image capturing device;FIG. 8 is a diagram illustrating a frame of an example two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained by an image capturing device;FIG. 9 is a diagram illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region determined according to some example embodiments of the inventive concept;FIG. 10 is a diagram illustrating an example of a sensing unit in the image capturing device of FIG. 4;FIGS. 11A and 11B are diagrams illustrating example pixel arrays in the sensing unit of FIG. 10;FIGS. 12A, 12B, 12C, and 12D are circuit diagrams illustrating some example unit pixels in a pixel array;FIG. 13 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 14 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIGS. 15A, 15B, and 15C are diagrams illustrating example operations of a synchronizer in the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker of FIG. 14;FIG. 16 is a diagram for describing tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 provided by the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker of FIG. 14;FIGS. 17A and 17B are diagrams for describing a method of upgrading a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region according to some example embodiments of the inventive concept;FIG. 18 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 19 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIG. 20 is a diagram for describing tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 provided by the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker of FIG. 19;FIG. 21 is a flowchart illustrating a method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object according to some example embodiments of the inventive concept;FIG. 22 is a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an example of a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 region tracker in a 
<a href="https://en.wikipedia.org/wiki/Québécois_nation_motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept;FIG. 23 is a diagram illustrating an example of a pixel array included in a 
<a href="https://en.wikipedia.org/wiki/Range_imaging"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    depth sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 24 is a 
<a href="https://en.wikipedia.org/wiki/Circuit_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    circuit diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating example time-of-flight (TOF) depth pixels in the pixel array of FIG. 23;FIG. 25 is a 
<a href="https://en.wikipedia.org/wiki/Timing_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    timing diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 illustrating an operation of the TOF pixels of FIG. 24;FIG. 26 is a diagram illustrating an example combination for providing depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 27 is a diagram for describing a method of calculating two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on raw 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 obtained using depth pixels;FIGS. 28A and 28B are diagrams example combinations for providing two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
;FIG. 29 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a camera including a three-dimensional 
<a href="https://en.wikipedia.org/wiki/Image_sensor"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    image sensor
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 according to some example embodiments of the inventive concept;FIG. 30 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a 
<a href="https://en.wikipedia.org/wiki/Computer"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    computer system
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 including a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 device according to some example embodiments of the inventive concept; andFIG. 31 illustrates a 
<a href="https://en.wikipedia.org/wiki/Block_diagram"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    block diagram
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of 
<a href="https://en.wikipedia.org/wiki/Interface"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    interface
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 employable in the computing system of FIG. 30 according to some example embodiments of the inventive concept._____c:1. A method of 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of an object, the method comprising:periodically obtaining depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a first resolution and two-dimensional 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of a second resolution with respect to a 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 using an image capturing device, wherein the second resolution is higher than the first resolution;determining a 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region by 
<a href="https://en.wikipedia.org/wiki/Recall_(memory)"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    recognizing
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 a target object in the 
<a href="https://en.wikipedia.org/wiki/Scene"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    scene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 based on the depth 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
, such that the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region corresponds to a portion of a frame and the portion includes the target object;periodically obtaining tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the second resolution corresponding to the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 tracking region; andanalyzing the 
<a href="https://en.wikipedia.org/wiki/Motion"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    motion
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 of the target 
<a href="https://en.wikipedia.org/wiki/Object-based_language"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    object based
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
 on the tracking region 
<a href="https://en.wikipedia.org/wiki/Data"><mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    data
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">TERM</span>
</mark></a>
.</div>
</figure>
</body>
</html>