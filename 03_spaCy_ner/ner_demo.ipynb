{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import wikipedia\n",
    "import warnings\n",
    "import urllib \n",
    "import time\n",
    "import json\n",
    "import sqlite3\n",
    "import requests\n",
    "import mwparserfromhell\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import wikitextparser as wtp\n",
    "\n",
    "from spacy import displacy\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from wasabi import msg\n",
    "from collections import defaultdict   \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Term:\n",
    "    \"\"\"Class of term\"\"\"\n",
    "    def __init__(self, term_name, title, summary):\n",
    "        self.term_name = term_name\n",
    "        self.title = title\n",
    "        self.summary = summary\n",
    "        \n",
    "    @property\n",
    "    def title(self):\n",
    "        return '{}'.format(self.title)\n",
    "    \n",
    "    @property\n",
    "    def summary(self):\n",
    "        return '{}'.format(self.summary)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Term({}: {}, {})\".format(self.term_name, self.title, self.summary)\n",
    "    \n",
    "    \n",
    "    \n",
    "def insert_term(term):\n",
    "    with conn:\n",
    "        cursor.execute(\"INSERT INTO data VALUES (:term_name, :title, :summary)\", \n",
    "                       {'term_name':term.term_name, 'title': term.title, 'summary':term.summary})\n",
    "\n",
    "        \n",
    "def remove_term_by_termname(termname):\n",
    "    with conn:\n",
    "        cursor.execute(\"DELETE from data WHERE term_name = :term_name\",\n",
    "                      {'term_name':termname})\n",
    "\n",
    "        \n",
    "def remove_term_by_title(title):\n",
    "    with conn:\n",
    "        cursor.execute(\"DELETE from data WHERE title = :title\",{'title':title}) \n",
    "\n",
    "\n",
    "def update_summary(term_name, summary):\n",
    "    with conn:\n",
    "        cursor.execute(\"\"\"UPDATE data SET summary = :summary\n",
    "                        WHERE term_name = :term_name\"\"\",\n",
    "                       {'term_name':term_name, 'summary': summary})\n",
    "\n",
    "        \n",
    "def update_title(term_name, title):\n",
    "    with conn:\n",
    "        cursor.execute(\"\"\"UPDATE data SET title = :title\n",
    "                        WHERE term_name = :term_name\"\"\",\n",
    "                       {'term_name':term_name, 'title': title})        \n",
    "        \n",
    "\n",
    "def get_term_by_termname(termname):\n",
    "    cursor.execute(\"SELECT * FROM data WHERE term_name= :term_name\", {'term_name': termname})\n",
    "    return cursor.fetchone()        \n",
    "\n",
    "\n",
    "def get_terms_by_title(title):\n",
    "    cursor.execute(\"SELECT * FROM data WHERE title= :title\", {'title': title})\n",
    "    return cursor.fetchall()\n",
    "\n",
    "\n",
    "\n",
    "def find_wiki_title(term):\n",
    "    \"\"\"\n",
    "    Using the wikipedia API to find the corresponding page title\n",
    "    \"\"\"\n",
    "    title = wikipedia.search(term)\n",
    "    if title:\n",
    "        return title[0]\n",
    "\n",
    "\n",
    "def find_wiki_summary(term):\n",
    "    \"\"\"\n",
    "    Using the wikipedia API to find the corresponding wikipedia abstract (the first paragraph of the wikipedia page)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return wikipedia.summary(term).split('.')[0] + '.'\n",
    "    # if it is a ambiguous term, the function will return None as value of summary\n",
    "    except wikipedia.exceptions.WikipediaException:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def parse(title, API_URL):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"rvlimit\": 1,\n",
    "        \"titles\": title,\n",
    "        \"format\": \"json\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"redirects\" : 1\n",
    "    }\n",
    "    headers = {\"User-Agent\": \"My-Bot-Name/1.0\"}\n",
    "    req = requests.get(API_URL, headers=headers, params=params)\n",
    "    res = req.json()\n",
    "    revision = res[\"query\"][\"pages\"][0]['revisions'][0]\n",
    "    text = revision[\"slots\"][\"main\"][\"content\"]\n",
    "    return mwparserfromhell.parse(text)\n",
    "\n",
    "\n",
    "def is_plural_or_initialism(ret1):\n",
    "    for template in ['plural of', 'initialism of', 'present participle of', 'alternative spelling of']:\n",
    "        match = re.match(f'^{template}', ret1)\n",
    "        if match: return ret1[match.end()+1:]\n",
    "\n",
    "\n",
    "def get_description_wiktionary(term):\n",
    "    term = term.lower()\n",
    "    try:\n",
    "        wikicode = parse(term, \"https://en.wiktionary.org/w/api.php\")\n",
    "        parsed = wtp.parse(str(wikicode))\n",
    "\n",
    "        for sec in parsed.sections:\n",
    "            if sec.title in ['Noun', 'Proper noun'] :\n",
    "                break\n",
    "        description = sec.get_lists()[0].items[0]\n",
    "        \n",
    "        templates = wtp.parse(description).templates\n",
    "        ret1 = []\n",
    "        while templates:\n",
    "            temp = templates.pop(0)\n",
    "            if 'lb' in temp.string:\n",
    "                ret1.append('('+temp.arguments[1].string[1:]+') ')\n",
    "            elif 'defdate' in temp.string:\n",
    "                pass\n",
    "            else:\n",
    "                ret1.append(temp.string.replace('|en|', ' ').strip(\"{\").strip(\"}\").replace('[','').replace(']',''))\n",
    "        ret1 = ' '.join(ret1) \n",
    "        \n",
    "        # check if it is the plural or the initialism of another term\n",
    "        check = is_plural_or_initialism(ret1)\n",
    "        if check: \n",
    "            return get_description_wiktionary(check)\n",
    "        \n",
    "        ret2 = wtp.parse(description).plain_text().strip() \n",
    "        try:\n",
    "            if ret2[-1] == ':': ret2 = ret2[:-1]\n",
    "            return ret1 + ret2\n",
    "        except IndexError:\n",
    "            return ret1    \n",
    "    \n",
    "    except KeyError:\n",
    "        return\n",
    "\n",
    "\n",
    "def get_description_wikipedia(term):              \n",
    "    try:\n",
    "        wikicode = parse(term, \"https://en.wikipedia.org/w/api.php\")\n",
    "        templates = wikicode.filter_templates()    \n",
    "        flag = 0\n",
    "        for temp in templates:\n",
    "            if temp.name in ['short description', 'Short description']:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag:\n",
    "            return str(temp.get(1))\n",
    "    except KeyError or ValueError:\n",
    "        return   \n",
    "     \n",
    "to_remove = ['conductive material forms electrodes',\n",
    "             'successful detection',\n",
    "             'smaller ratio',\n",
    "             'successful watermark detection',\n",
    "             'unsupervised',\n",
    "             'detected',\n",
    "             'K',\n",
    "             'm=2Ap',\n",
    "             'knowledge of K=(KS',\n",
    "             'depth log2(N',\n",
    "             'images N',\n",
    "             'cm2',\n",
    "             'K.\\n',\n",
    "             'quantum code C;<br/',\n",
    "             'codeword c(M',\n",
    "             'by-letter encryption U(KS',\n",
    "             'priority ranks'\n",
    "            ]\n",
    "        \n",
    "# def text_to_html(text, nlp): # gives the html under BeatifulSoup format\n",
    "#     doc = nlp(text)\n",
    "\n",
    "#     html = displacy.render(doc, style=\"ent\", options={\"ents\": [\"TERM\"]}, jupyter=False, page=True)\n",
    "#     soup = BeautifulSoup(html)\n",
    "#     marks =  soup.find_all('mark')\n",
    "#     url = ''\n",
    "    \n",
    "#     for mark in tqdm(marks):\n",
    "#         try:\n",
    "#             term = mark.get_text(strip=True,separator=', ').split(', ')[0] # get the term annotated\n",
    "#             if term in to_remove: continue\n",
    "            \n",
    "#             wiki_info = DICT_PAGE_TITLE[term] # get wikipedia pagetitle and summary from json file\n",
    "#             url = f'https://en.wikipedia.org/wiki/{\"_\".join(wiki_info[\"title\"].split())}' \n",
    "#             summary = wiki_info['summary']\n",
    "            \n",
    "#         except KeyError:\n",
    "#             wiki_title = find_wiki_title(term)  \n",
    "            \n",
    "#             if wiki_title:\n",
    "#                 url = f'https://en.wikipedia.org/wiki/{\"_\".join(wiki_title.split())}' \n",
    "#                 wiki_summary = find_wiki_summary(wiki_title)\n",
    "#                 DICT_PAGE_TITLE.update({term:{'title':wiki_title, 'summary': wiki_summary}})\n",
    "                    \n",
    "#         link = soup.new_tag('a', href=url) # create the html tag for link       \n",
    "#         mark.wrap(link) #add html tag <a> (the one to make links) to around our annotated word\n",
    "#     return soup\n",
    "\n",
    "\n",
    "def text_to_json(text, nlp): # gives the ner results in json format\n",
    "    \n",
    "    dict_position = defaultdict(list)\n",
    "    dict_position_trigger = defaultdict(list)\n",
    "    dict_res = {}\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'TERM':    \n",
    "            term = ent.text\n",
    "            try:\n",
    "                while (term[-1] in ['.','_', ';', '\\n', ' '] or term[0] == '.') and ent.end_char>0 and (not term.isupper() or (term.isupper() and len(term)<=4)) :\n",
    "                    ent.end_char -= 1\n",
    "                    term = term[:-1]  \n",
    "                if(term in to_remove): continue\n",
    "                dict_position[term].append((ent.start_char, ent.end_char))\n",
    "            except IndexError: # single character term\n",
    "                continue         \n",
    "            \n",
    "        else: # if it is a trigger word\n",
    "            dict_position_trigger[ent.text].append((ent.start_char, ent.end_char))          \n",
    "            \n",
    "    dict_position = dict(dict_position)\n",
    "    \n",
    "    msg.info(\"Analysing errors...\")\n",
    "    for error, pos_l in tqdm(dict_position_trigger.items()): # only for ERROR\n",
    "        dict_res.update({error: {'label': 'ERROR', 'position': pos_l}})\n",
    "    msg.good(\"Done!\")\n",
    "    \n",
    "    msg.info(\"Analysing terms...\")\n",
    "    cnt = 0\n",
    "    for term, pos_l in tqdm(dict_position.items()): # only for TERM\n",
    "\n",
    "        wiki_info = get_term_by_termname(term) # get wikipedia pagetitle and summary from database\n",
    "        if wiki_info: # if exists in database\n",
    "            url = f'https://en.wikipedia.org/wiki/{\"_\".join(wiki_info[1].split())}' \n",
    "            wiki_summary = wiki_info[2] \n",
    "\n",
    "        else:   \n",
    "            print(term)\n",
    "            wiki_title = find_wiki_title(term)  \n",
    "            # find summary  \n",
    "            try:\n",
    "                ## witionary\n",
    "                wiki_summary = get_description_wiktionary(term)\n",
    "                if not wiki_summary or '|' in wiki_summary:\n",
    "                    ## wikipedia brief summary\n",
    "                    wiki_summary = get_description_wikipedia(term)\n",
    "                if (not wiki_summary) and wiki_title:                  \n",
    "                    if not wiki_summary:\n",
    "                        wiki_summary = get_description_wiktionary(wiki_title)\n",
    "                    if not wiki_summary:\n",
    "                        wiki_summary = get_description_wikipedia(wiki_title)\n",
    "                    if not wiki_summary: ## wikipedia page abstract\n",
    "                        wiki_summary = find_wiki_summary(wiki_title)             \n",
    "            except KeyError: # for terms of ERROR\n",
    "                continue\n",
    "                \n",
    "            # find wiki title\n",
    "            if wiki_title:\n",
    "                url = f'https://en.wikipedia.org/wiki/{\"_\".join(wiki_title.split())}' \n",
    "                # insert new term into database   \n",
    "                print(Term(term, wiki_title, wiki_summary))\n",
    "                insert_term(Term(term, wiki_title, wiki_summary))\n",
    "                \n",
    "            else: # returns the wikipedia main page\n",
    "                url = f'https://www.wikipedia.org'\n",
    "                insert_term(Term(term, None, None))\n",
    "                           \n",
    "            cnt += 1\n",
    "\n",
    "        dict_res.update({term:{'label': 'TERM', 'position': pos_l,'wikilink': url,'summary': wiki_summary}})\n",
    "    msg.good(\"Done!\")\n",
    "    \n",
    "    # update the database data if there is new term recognised \n",
    "    if cnt:\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        msg.good(f\"Found wikipedia information for {cnt} new terms.\")\n",
    "            \n",
    "    return dict_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./wiki_info.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./claims.txt', encoding = 'utf-8', mode='r') as f:\n",
    "    claims = f.read().replace('<p>', '').replace('</p>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(r\"../03_spaCy_ner/output/G_2018/model-last/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open('./demo.html', 'w', encoding=\"utf-8\").write(str(text_to_html(claims,nlp))) #create file with html data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 66576.25it/s]\n",
      " 38%|███▊      | 247/653 [00:00<00:00, 2466.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Analysing errors...\u001b[0m\n",
      "\u001b[38;5;2m✔ Done!\u001b[0m\n",
      "\u001b[38;5;4mℹ Analysing terms...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:00<00:00, 3165.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Done!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# save results\n",
    "with open('demo.json', \"w\") as f: \n",
    "    json.dump(text_to_json(claims, nlp), f, indent = 4) # test with the first patent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base')",
   "language": "python",
   "name": "python37464bitbase5e3e771f486c4f06aa164a453e60de03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
