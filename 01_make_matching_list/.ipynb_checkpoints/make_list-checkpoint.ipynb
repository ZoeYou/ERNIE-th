{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from wasabi import msg\n",
    "from os import listdir\n",
    "from tqdm import tqdm \n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "pd.set_option('max_row',5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters \n",
    "\n",
    "INPUT_DIR = './Datasets/orig/'\n",
    "REMOVE_LABEL = ['university','person','researcher','country','location','scientist']\n",
    "ONLY_MWE = False\n",
    "LIST_TO_CONCATE = './wikidump_terms.txt'\n",
    "\n",
    "WIKI_TITLE_DICT = './page_titles.txt' # wikipedia redirect page title\n",
    "WIKI_TITLE_SEARCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing ./Datasets/orig/annotation_df_scienceie.csv...\n",
      "\u001b[38;5;2mâœ” There is no label to remove.\u001b[0m\n",
      "\n",
      "\n",
      "Preprocessing ./Datasets/orig/.DS_Store...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "./Datasets/orig/.DS_Store is not in a good format. ['term', 'label', 'dataset']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-70bce527f191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m          \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{file} is not in a good format. ['term', 'label', 'dataset']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# check annotation type and remove those that are not a term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ./Datasets/orig/.DS_Store is not in a good format. ['term', 'label', 'dataset']"
     ]
    }
   ],
   "source": [
    "# read files \n",
    "files = [join(INPUT_DIR, f) for f in listdir(INPUT_DIR) if isfile(join(INPUT_DIR, f))]\n",
    "\n",
    "remove_dfs = pd.DataFrame([], columns=['term', 'annotation', 'df'])\n",
    "dfs = pd.DataFrame([], columns=['term', 'annotation', 'df'])\n",
    "\n",
    "for file in files:\n",
    "    msg.text(f\"Preprocessing {file}...\")\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    \n",
    "    if df.shape[1] != 3:\n",
    "         raise ValueError(f\"{file} is not in a good format. ['term', 'label', 'dataset']\")\n",
    "    \n",
    "    # check annotation type and remove those that are not a term\n",
    "    annotations = df.iloc[:,1].unique()\n",
    "    to_remove = [ann for ann in annotations if ann in REMOVE_LABEL]\n",
    "    \n",
    "    if to_remove == []: \n",
    "        msg.good(\"There is no label to remove.\")     \n",
    "    else:\n",
    "        for label in to_remove:\n",
    "            msg.info(f\"Removing terms with label {label} from {file}:\")\n",
    "            \n",
    "            remove_df = df[df.annotation==label]\n",
    "            df = df.drop(remove_df.index, axis=0)\n",
    "            remove_dfs = remove_dfs.append(remove_df,sort=False)\n",
    "             \n",
    "            print('\\n'.join(remove_df.term.values))\n",
    "    \n",
    "    # whether to keep only Multi-word expressions\n",
    "    if ONLY_MWE:\n",
    "        msg.info(f\"Removing from single tokens from {file}:\")\n",
    "        \n",
    "        single_tokens = [term for term in df.term.values if ' ' not in term]\n",
    "        remove_df = df[df.term.isin(single_tokens)]\n",
    "        df = df.drop(remove_df.index, axis=0)\n",
    "        remove_dfs = remove_dfs.append(remove_df,sort=False)\n",
    "        \n",
    "        print('\\n'.join(single_tokens))   \n",
    "        \n",
    "    dfs = dfs.append(df,sort=False)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIST_TO_CONCATE:\n",
    "    with open(LIST_TO_CONCATE) as f:\n",
    "        mwes = [x.strip() for x in f.readlines()]\n",
    "    \n",
    "    # remove duplicate\n",
    "    mwes = list(set(mwes) - set(dfs.term.values))        \n",
    "        \n",
    "    df = pd.DataFrame(mwes, columns=['term'])\n",
    "    dfs = dfs.append(df,sort=False).fillna(value={'annotation': 'TECH', 'df': 'wikidump'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WIKI_TITLE_DICT:\n",
    "    wiki_title_dict = pd.read_csv(WIKI_TITLE_DICT, delimiter='\\t', header=None, index_col=0).to_dict()[1]\n",
    "    dfs['wiki_title'] = dfs['term'].map(wiki_title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WIKI_TITLE_SEARCH:\n",
    "    # search for wiki page title that are not in the original dict (723836)\n",
    "    import urllib \n",
    "    import requests \n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    def find_wiki_title(term):\n",
    "        encoded_term = urllib.parse.quote(term)       \n",
    "        \n",
    "        url = f'https://en.wikipedia.org/w/api.php?action=query&redirects=true&titles={encoded_term}&format=json'\n",
    "        json_response = requests.get(url).json()\n",
    "        \n",
    "        query = json_response.get('query')\n",
    "        if query: \n",
    "            pages = query.get('pages')\n",
    "            if pages:\n",
    "                pageid = list(pages.keys())[0]\n",
    "                if pageid =='-1':\n",
    "                    return None \n",
    "                else:\n",
    "                    info = pages.get(pageid)\n",
    "                    if info:\n",
    "                        title = info.get('title')\n",
    "                        return title \n",
    "        \n",
    "\n",
    "            \n",
    "    # add wikititle for each term\n",
    "    for term in tqdm(dfs[dfs.wiki_title.isna()].term.values):\n",
    "        wiki_title = find_wiki_title(term)\n",
    "        if wiki_title:\n",
    "            wiki_title_dict.update({term:wiki_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new dictionary (original file with 1718334 rows)\n",
    "pd.DataFrame([(k,v) for k,v in wiki_title_dict.items()]).to_csv(WIKI_TITLE_DICT, header=None, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "dfs['wiki_title'] = dfs['term'].map(wiki_title_dict)\n",
    "dfs.to_csv (r'./matching_list.csv', index = False, header=True)\n",
    "\n",
    "remove_dfs.to_csv (r'./removed_terms.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read all original csv \n",
    "# 2. check their types \n",
    "# 3. return type list \n",
    "# 4. whether to keep MWEs and remove single tokens \n",
    "# 5. if other list txt file, we can concatenate it "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
